{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f0eb391-59bc-4489-81f3-dc0a3c2b27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "#!pip install spacy\n",
    "import gensim\n",
    "import xml.etree.cElementTree as ET\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "843e756d-b62e-4878-b9f5-9797f12d165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_lg')\n",
    "#!python -m spacy download en_core_web_lg \n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff3ddc32-d55a-453d-980f-2bc18af32630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737db7ac-c826-452c-9fc2-1c535c962dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = paths = ['./data/Laptop_Train_v2.xml',\n",
    "         './data/Restaurants_Train_v2.xml']\n",
    "\n",
    "def parse_one_file(path):\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()  \n",
    "\n",
    "    data = []\n",
    "    polarity_set = set()\n",
    "    for sentence in root.findall('sentence'): # use xPat to find all the <sentence> tags\n",
    "        text = sentence.find('text').text     # in each 'sentence', find the <text> tag\n",
    "        aTerms = sentence.find('aspectTerms') # also, in each 'sentence', find all the <aspectTerms> tags\n",
    "        if aTerms is not None:\n",
    "            for aTerm in aTerms.findall('aspectTerm'): # find all the <aspectTerm> tag\n",
    "                term = aTerm.get('term') # in each of the <aspectTerm> tag, get the 'term' attribute\n",
    "\n",
    "                data.append([text, term]) # put these into the list to prepare for the dataframe\n",
    "        else:\n",
    "            #print(text)\n",
    "            pass\n",
    "\n",
    "    # check how many different unique polarity values\n",
    "    return polarity_set, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51b8efa7-eade-41d0-9d72-06dfee2a20e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>pot of boiling water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>meats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>Each table has a pot of boiling water sunken i...</td>\n",
       "      <td>glass noodles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6051 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence                aspect\n",
       "0     I charge it at night and skip taking the cord ...                  cord\n",
       "1     I charge it at night and skip taking the cord ...          battery life\n",
       "2     The tech guy then said the service center does...        service center\n",
       "3     The tech guy then said the service center does...          \"sales\" team\n",
       "4     The tech guy then said the service center does...              tech guy\n",
       "...                                                 ...                   ...\n",
       "6046  Each table has a pot of boiling water sunken i...  pot of boiling water\n",
       "6047  Each table has a pot of boiling water sunken i...                 meats\n",
       "6048  Each table has a pot of boiling water sunken i...            vegetables\n",
       "6049  Each table has a pot of boiling water sunken i...                  rice\n",
       "6050  Each table has a pot of boiling water sunken i...         glass noodles\n",
       "\n",
       "[6051 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = []\n",
    "for path in paths:\n",
    "    polarity_set, data = parse_one_file(path)\n",
    "    #print('The polarities in {} are {}'.format(path, polarity_set))\n",
    "    final_data.extend(data)\n",
    "df = pd.DataFrame(final_data)\n",
    "df = df.rename(columns={0: \"sentence\", 1: \"aspect\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ddcaa9c-ca9d-42e3-a2f4-187c6cf18f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037fb7a3-67f8-427a-a7ab-c474351a5f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_extract_candidate_aspect(text):\n",
    "    tokens = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punc = string.punctuation\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word not in stop_words and word not in punc:\n",
    "            tokens.append(word.lower())\n",
    "            \n",
    "    candidate_terms = []\n",
    "    \n",
    "    for token in nlp(' '.join(tokens)):\n",
    "        if token.tag_ == 'NN' and len(token)>2: # token must be noun\n",
    "            candidate_terms.append(token.lemma_)\n",
    "            \n",
    "    return candidate_terms\n",
    "\n",
    "\n",
    "train[\"candidate aspect\"] = train.apply(lambda r: tokenize_and_extract_candidate_aspect(r['sentence']), axis=1)\n",
    "test[\"candidate aspect\"] = test.apply(lambda r: tokenize_and_extract_candidate_aspect(r['sentence']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecdd65e0-b7ba-4c53-8333-7164cfec7b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6051"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
