{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b65612a8-a2eb-4c3c-92ab-24df1651c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Need to use a delay between page scrapes in order to limit getting blocked by Yelp\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74c00e02-e28e-460f-b523-38e027996036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTER SEARCH TERMS BELOW:\n",
    "cuisine_type = \"\"\n",
    "location = \"Singapore\"\n",
    "\n",
    "#Generate URL based on search terms\n",
    "base_url = \"https://www.yelp.com\"\n",
    "search_url = f\"{base_url}/search?find_desc={cuisine_type}&find_loc={location}\"\n",
    "\n",
    "#Or manually set search_url by copying directly from Yelp Page if desired\n",
    "#search_url = \"https://www.yelp.com/search?find_desc=burger&find_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6779bbdd-b66c-42bf-89c9-e1432a8eb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_container_class = \"lemon--div__373c0__1mboc attribute__373c0__1hPI_ display--inline-block__373c0__2de_K u-space-r1 border-color--default__373c0__2oFDT\"\n",
    "price_range_class = \"lemon--span__373c0__3997G text__373c0__2pB8f priceRange__373c0__2DY87 text-color--normal__373c0__K_MKN text-align--left__373c0__2pnx_ text-bullet--after__373c0__1ZHaA\"\n",
    "review_count_class = \"lemon--span__373c0__3997G text__373c0__2pB8f reviewCount__373c0__2r4xT text-color--mid__373c0__3G312 text-align--left__373c0__2pnx_\"\n",
    "next_page_class = \"lemon--a__373c0__IEZFH link__373c0__29943 next-link navigation-button__373c0__1D3Ug link-color--blue-dark__373c0__1mhJo link-size--default__373c0__1skgq\"\n",
    "search_result_class = \"container__09f24__mpR8_ hoverable__09f24__wQ_on margin-t3__09f24__riq4X margin-b3__09f24__l9v5d padding-t3__09f24__TMrIW padding-r3__09f24__eaF7p padding-b3__09f24__S8R2d padding-l3__09f24__IOjKY border--top__09f24__exYYb border--right__09f24__X7Tln border--bottom__09f24___mg5X border--left__09f24__DMOkM border-color--default__09f24__NPAKY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09eaf3c7-92a7-4b7c-b9c5-8520637bc4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1, 9 results https://www.yelp.com/search?find_desc=&find_loc=Singapore\n",
      "10 businesses scraped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.yelp.com/biz/gardens-by-the-bay-singapore-3',\n",
       "  'name': 'Gardens By The Bay',\n",
       "  'biz_id': 'gardens-by-the-bay-singapore-3',\n",
       "  'category': ['Botanical Gardens'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/qT8KatwbuJJvqrRJP4gmzw/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/singapore-botanic-gardens-singapore-5',\n",
       "  'name': 'Singapore Botanic Gardens',\n",
       "  'biz_id': 'singapore-botanic-gardens-singapore-5',\n",
       "  'category': ['Botanical Gardens'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/k_j7-pjkx6V3mL2nj3Un0w/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/tian-tian-hainanese-chicken-rice-singapore-7',\n",
       "  'name': 'Tian Tian Hainanese Chicken Rice',\n",
       "  'biz_id': 'tian-tian-hainanese-chicken-rice-singapore-7',\n",
       "  'category': ['Hainan', 'Chicken Shop'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/p295N0p6K52CzkmBOxx73w/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/singapore-zoo-singapore-2',\n",
       "  'name': 'Singapore Zoo',\n",
       "  'biz_id': 'singapore-zoo-singapore-2',\n",
       "  'category': ['Zoos'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/am-xDxGrZMg-WldeFo8Y-Q/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/cloud-forest-singapore',\n",
       "  'name': 'Cloud Forest',\n",
       "  'biz_id': 'cloud-forest-singapore',\n",
       "  'category': ['Botanical Gardens'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/gewBg98dtHlodx06B7TnQQ/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/din-tai-fung-singapore-5',\n",
       "  'name': 'Din Tai Fung',\n",
       "  'biz_id': 'din-tai-fung-singapore-5',\n",
       "  'category': ['Taiwanese', 'Dim Sum', 'Dumplings'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/EO_cYnmChREUrhqKHTzSiw/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/song-fa-bak-kut-teh-singapore-11',\n",
       "  'name': 'Song Fa Bak Kut Teh',\n",
       "  'biz_id': 'song-fa-bak-kut-teh-singapore-11',\n",
       "  'category': ['Singaporean', 'Chinese'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/cgE6mZ8dNeuazbEK4ipZLA/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/tolidos-espresso-nook-singapore-3',\n",
       "  'name': 'Tolidoâ€™s Espresso Nook',\n",
       "  'biz_id': 'tolidos-espresso-nook-singapore-3',\n",
       "  'category': ['Breakfast & Brunch', 'Coffee & Tea'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/40D0vX8qEoBwKFSplvDOHA/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/jumbo-seafood-singapore-4',\n",
       "  'name': 'Jumbo Seafood',\n",
       "  'biz_id': 'jumbo-seafood-singapore-4',\n",
       "  'category': ['Seafood'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/85hCRe6TJh0e670IadHemA/348s.jpg'},\n",
       " {'url': 'https://www.yelp.com/biz/two-men-bagel-house-singapore',\n",
       "  'name': 'Two Men Bagel House',\n",
       "  'biz_id': 'two-men-bagel-house-singapore',\n",
       "  'category': ['Bagels', 'Breakfast & Brunch', 'Sandwiches'],\n",
       "  'image_shown': 'https://s3-media0.fl.yelpcdn.com/bphoto/nCgemKkniM0LYD5mSQMb_g/348s.jpg'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_page_url = search_url\n",
    "page_counter = 1\n",
    "business_list = []\n",
    "\n",
    "#Run continuously until there is no longer a \"next page\" url found.\n",
    "while next_page_url:\n",
    "    #Request HTML page and load into Beautiful Soup object\n",
    "    request = requests.get(next_page_url)\n",
    "    soup = BeautifulSoup(request.content,'html.parser')\n",
    "    \n",
    "    #Find search results container on page.\n",
    "    search_results = soup.findAll(\"div\", class_=search_result_class)\n",
    "    print(f\"Page {page_counter}, {len(search_results)-1} results {next_page_url}\")\n",
    "    result_counter = 1\n",
    "\n",
    "    #Loop through search results and store information for each business\n",
    "    for search_result in search_results:\n",
    "        business_info = {}\n",
    "        try:\n",
    "            business_name_url = search_result.findAll('a', href=True)[1]\n",
    "            business_info['url'] = f\"https://www.yelp.com{business_name_url['href']}\"\n",
    "            business_info['name'] = business_name_url['name']\n",
    "            business_info['biz_id'] = business_name_url['href'].split('/biz/')[1].split('?')[0]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            business_info['address'] = search_result.find('address').text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            business_info['category'] = [category.text for category in search_result.findAll(\"a\",attrs={\"role\":\"link\"})]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            business_info['star_rating'] = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", \n",
    "                                                      search_result.find(\n",
    "                                                          class_=star_container_class).find('div')['aria-label'] )[0] )\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            business_info['price_range'] = search_result.find(class_=price_range_class).text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            business_info['num_reviews'] = int(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\",\n",
    "                                                      search_result.find(\n",
    "                                                          class_=review_count_class).text )[0] )\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            business_info['image_shown'] = search_result.find('img')['src']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Append business information for each search result to a list containing all businesses.\n",
    "        if business_info:\n",
    "            business_list.append(business_info)\n",
    "            \n",
    "        result_counter+=1\n",
    "    \n",
    "    #Set url for next page. If not found, break out of loop.\n",
    "    if soup.find(class_=next_page_class):\n",
    "        next_page_url = base_url + soup.find(class_=next_page_class)['href']\n",
    "        page_counter+=1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    #Random delay between 2 and 20 seconds to prevent getting blocked\n",
    "    sleep(np.random.randint(2,20))\n",
    "\n",
    "print(len(business_list), \"businesses scraped\")\n",
    "business_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da83553-3458-4596-8b3e-d243838c747e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['num_reviews']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19356/3946691309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbusiness_info_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbusiness_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Drop businesses with no reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbusiness_info_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_reviews'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#Drop duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbusiness_info_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbusiness_info_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbusiness_info_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiz_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   5951\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5952\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5953\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5954\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['num_reviews']"
     ]
    }
   ],
   "source": [
    "business_info_df = pd.DataFrame(business_list)\n",
    "#Drop businesses with no reviews\n",
    "business_info_df.dropna(subset=['num_reviews'], inplace=True)\n",
    "#Drop duplicates\n",
    "business_info_df.drop(business_info_df[business_info_df.biz_id.duplicated(keep='first')].index, inplace=True)\n",
    "print(len(business_info_df))\n",
    "business_info_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc669ae-d3b0-443f-8730-a9ac429c9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN UP CATEGORY VALUES - remove parenthesis\n",
    "business_info_categories = []\n",
    "for category in business_info_df.category:\n",
    "    cat_list = []\n",
    "    for cat in category:\n",
    "        cat = cat.replace('(',' ')\n",
    "        cat = cat.replace(')',' ')\n",
    "        cat = re.sub(' +',' ', cat).strip()\n",
    "        cat_list.append(cat)\n",
    "    business_info_categories.append(cat_list)\n",
    "business_info_df.category = business_info_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d037d-274d-478a-a28a-f5dc4f6b7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN UP BUSINESS NAMES\n",
    "business_names = []\n",
    "for name in business_info_df.name:\n",
    "    name = name.replace('Ã¢\\x80\\x99',\"\\'\")\n",
    "    business_names.append(name)\n",
    "business_info_df.name = business_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abcf61-e9d9-42b4-841a-893a0e77cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(business_name, business_index, yelp_business_url, verbose=False):\n",
    "    \"\"\"\n",
    "    This function will iterate through all of the review pages for a particular business and\n",
    "    return a list populated with all reviews found.\n",
    "    \n",
    "    INPUTS:\n",
    "    business_name     = The name of the business. It is contained in the results list records.\n",
    "    business_index    = The business index (unique identifier). It is contained in the results records.\n",
    "    yelp_business_url = The URL for the starting page of reviews for the business.\n",
    "    verbose           = Summary info is always printed, but with verbose validation of each page is printed.\n",
    "    \n",
    "    OUTPUT:\n",
    "    List of reviews. Each review is a dictionary containing desired review information.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Class names used in Yelp Review pages.\n",
    "    #There are two flavors of page design that yelp uses\n",
    "    search_result_class_v1 = \"lemon--li__373c0__1r9wz u-space-b3 u-padding-b3 border--bottom__373c0__uPbXS border-color--default__373c0__2oFDT\"\n",
    "    search_result_class_v2 = \"review review--with-sidebar\"\n",
    "    \n",
    "    #Set starting page (first page of reviews)\n",
    "    next_page_url = yelp_business_url\n",
    "\n",
    "    reviews_list = []\n",
    "    page_counter=1\n",
    "\n",
    "    #Continue to loop through review pages until there is no longer a \"next\" link at the bottom.\n",
    "    while next_page_url:\n",
    "        if verbose:\n",
    "            #Print the page url being parsed\n",
    "            print(f\"Page {page_counter}, {next_page_url}\")\n",
    "\n",
    "        #Request html for page and load into BeautifulSoup object.\n",
    "        request = requests.get(next_page_url)\n",
    "        soup = BeautifulSoup(request.content,'html.parser')\n",
    "        \n",
    "        #Check which version of the page is being used. If neither is found, print error message.\n",
    "        if len(soup.findAll(class_=search_result_class_v1))!=0:\n",
    "            reviews_list.extend(get_reviews_page_v1(soup,business_name,business_index,verbose))\n",
    "        elif len(soup.findAll(class_=search_result_class_v2))!=0:\n",
    "            reviews_list.extend(get_reviews_page_v2(soup,business_name,business_index,verbose))\n",
    "        else:\n",
    "            print(\"Could not parse page: \", next_page_url)\n",
    "        \n",
    "        #Check for \"next\" page link - update next_page_url if found.\n",
    "        #Break from while loop if there is no next page.\n",
    "        if soup.find(\"link\", attrs={'rel':'next'}):\n",
    "            next_page_url = soup.find(\"link\", attrs={'rel':'next'})['href']\n",
    "            page_counter+=1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #Random delay between 1 and 4 seconds to prevent getting blocked\n",
    "        sleep(np.random.randint(1,3))\n",
    "    \n",
    "    return reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7df97-a8be-4c44-968d-5be5fd337e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_page_v1(soup, business_name, business_index, verbose=False):\n",
    "    \"\"\"\n",
    "    This function will extract reviews information from the BeautifulSoup object representing\n",
    "    version 1 of a Yelp review page.\n",
    "    \n",
    "    INPUTS:\n",
    "    soup           = BeautifulSoup object to traverse.\n",
    "    business_name  = The name of the business. It is contained in the results list records.\n",
    "    business_index = The business index (unique identifier). It is contained in the results records.\n",
    "    verbose        = If True, print status of review extraction.\n",
    "    \n",
    "    OUTPUT:\n",
    "    List of reviews. Each review is a dictionary containing desired review information.\n",
    "    \"\"\"\n",
    "    search_result_class = \"lemon--li__373c0__1r9wz u-space-b3 u-padding-b3 border--bottom__373c0__uPbXS border-color--default__373c0__2oFDT\"\n",
    "    star_container_class = \"lemon--div__373c0__1mboc arrange-unit__373c0__1piwO border-color--default__373c0__2oFDT\"\n",
    "    date_class = \"lemon--span__373c0__3997G text__373c0__2pB8f text-color--mid__373c0__3G312 text-align--left__373c0__2pnx_\"\n",
    "    pic_class = \"lemon--span__373c0__3997G photo-box-grid-item__373c0__2kFqV display--inline__373c0__1DbOG u-space-r2 u-space-b2 border-color--default__373c0__2oFDT\"\n",
    "    pic_url_class = \"lemon--img__373c0__3GQUb photo-box-img__373c0__O0tbt\"\n",
    "    \n",
    "    #Get each review block\n",
    "    reviews = soup.findAll(class_=search_result_class)\n",
    "    reviews_list=[]\n",
    "    skipped_review_counter=0\n",
    "    #Loop through each review and pull out pertinent information. Put into list of dictionaries.\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            review_info = {}\n",
    "            review_info[\"business_name\"] = business_name\n",
    "            review_info[\"business_index\"] = business_index\n",
    "            review_info[\"date\"] = review.find(class_=date_class).text.strip()\n",
    "            #review_info[\"review\"] = review.find(\"span\", attrs={\"class\": \"lemon--span__373c0__3997G\", \"lang\": \"en\"}).text\n",
    "            review_info[\"review\"] = review.find(attrs={\"lang\": \"en\"}).text\n",
    "            review_info['star_rating'] = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", \n",
    "                           review.find(class_=star_container_class).find('div')['aria-label'] )[0] )\n",
    "            review_info[\"pic_count\"] = len(review.find_all(class_=pic_class))\n",
    "            review_info[\"pic_urls\"] = [obj['src'] for obj in review.findAll(class_=pic_url_class)]\n",
    "\n",
    "            #Sometimes the user id is not being found\n",
    "            try:\n",
    "                review_info[\"user_id\"] = review.find('a')['href'].split('userid=')[1]\n",
    "            except:\n",
    "                None\n",
    "\n",
    "            reviews_list.append(review_info)\n",
    "        except:\n",
    "            skipped_review_counter+=1\n",
    "            \n",
    "    if verbose:\n",
    "        if skipped_review_counter!=0:\n",
    "            print(f\"Skipped {skipped_review_counter} reviews\")\n",
    "\n",
    "    return(reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e276d1-c551-4a37-b961-7c5ae8d6718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_page_v2(soup, business_name, business_index, verbose=False):\n",
    "    \"\"\"\n",
    "    This function will extract reviews information from the BeautifulSoup object representing\n",
    "    version 2 of a Yelp review page.\n",
    "    \n",
    "    INPUTS:\n",
    "    soup           = BeautifulSoup object to traverse.\n",
    "    business_name  = The name of the business. It is contained in the results list records.\n",
    "    business_index = The business index (unique identifier). It is contained in the results records.\n",
    "    verbose        = If True, print status of review extraction.\n",
    "    \n",
    "    OUTPUT:\n",
    "    List of reviews. Each review is a dictionary containing desired review information.\n",
    "    \"\"\"\n",
    "    \n",
    "    search_result_class = \"review review--with-sidebar\"\n",
    "    star_container_class = \"biz-rating__stars\"\n",
    "    date_class = \"rating-qualifier\"\n",
    "    review_photo_box_class = \"photo-box-grid clearfix js-content-expandable lightbox-media-parent\"\n",
    "    \n",
    "    #Get each review block\n",
    "    reviews = soup.findAll(class_=search_result_class)\n",
    "    reviews_list=[]\n",
    "    skipped_review_counter=0\n",
    "    #Loop through each review and pull out pertinent information. Put into list of dictionaries.\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            review_info = {}\n",
    "            review_info[\"business_name\"] = business_name\n",
    "            review_info[\"business_index\"] = business_index\n",
    "            review_info[\"date\"] = review.find(class_=date_class).text.strip()\n",
    "            review_info[\"review\"] = review.find(attrs={\"lang\": \"en\"}).text\n",
    "            review_info['star_rating'] = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", \n",
    "                           review.find(class_=star_container_class).find('div')['title'])[0] )\n",
    "            try:\n",
    "                pic_line_items = review.find(class_=review_photo_box_class).findAll('li')\n",
    "                review_info[\"pic_count\"] = len(pic_line_items)\n",
    "                review_info[\"pic_urls\"] = [obj.find('img')['src'] for obj in pic_line_items]\n",
    "            except:\n",
    "                review_info[\"pic_count\"] = 0\n",
    "                review_info[\"pic_urls\"] = []\n",
    "\n",
    "            #Sometimes the user id is not being found\n",
    "            try:\n",
    "                review_info[\"user_id\"] = review.find('a')['href'].split('userid=')[1]\n",
    "            except:\n",
    "                None\n",
    "\n",
    "            reviews_list.append(review_info)\n",
    "        except:\n",
    "            skipped_review_counter+=1\n",
    "\n",
    "    if verbose:\n",
    "        if skipped_review_counter!=0:\n",
    "            print(f\"Skipped {skipped_review_counter} reviews\")\n",
    "            \n",
    "    return(reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac5575-f1f0-4446-a444-d6f7e00f7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING SCRAPER FOR A SINGLE BUSINESS\n",
    "index_num = 4\n",
    "business_url = business_info_df.url[index_num]\n",
    "business_name = business_info_df.name[index_num]\n",
    "business_index = business_info_df.biz_id[index_num]\n",
    "\n",
    "reviews_df = pd.DataFrame(get_reviews(business_name,business_index, business_url,verbose=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
