{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b33beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c73eec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/restaurants_laptop_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1706bfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>food</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>food</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text aspect_term  from   to  \\\n",
       "0               But the staff was so horrible to us.       staff     8   13   \n",
       "1  To be completely fair, the only redeeming fact...        food    57   61   \n",
       "2  The food is uniformly exceptional, with a very...        food     4    8   \n",
       "3  The food is uniformly exceptional, with a very...     kitchen    55   62   \n",
       "4  The food is uniformly exceptional, with a very...        menu   141  145   \n",
       "\n",
       "   polarity  \n",
       "0        -1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "all_texts = df['text'].unique()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a83952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def found_aspect_start_terms(curr_idx, aspect_terms):\n",
    "#     for term in aspect_terms:\n",
    "#         if curr_idx == term['from']:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# def found_aspect_end_terms(curr_idx, aspect_terms):\n",
    "#     for term in aspect_terms:\n",
    "#         if curr_idx >= term['to']:\n",
    "#             aspect_terms.remove(term)\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# def construct_sentence_aspect_group(text, aspect_terms):\n",
    "#     ret_token_list = []\n",
    "#     ret_tag_list = []\n",
    "    \n",
    "# #     print(text)\n",
    "# #     print(aspect_terms)\n",
    "    \n",
    "#     state = \"NOT_AT\"\n",
    "    \n",
    "#     at_token = \"\"\n",
    "#     nat_token = \"\"\n",
    "#     for i in range(len(text)):\n",
    "#         if state == \"NOT_AT\":\n",
    "#             if text[i] == \" \":\n",
    "#                 if len(nat_token.strip()) > 0:\n",
    "#                     ret_token_list.append(nat_token)\n",
    "#                     ret_tag_list.append(\"NAT\")\n",
    "#                     nat_token = \"\"\n",
    "#             elif found_aspect_start_terms(i, aspect_terms):\n",
    "#                 if len(nat_token.strip()) > 0:\n",
    "#                     ret_token_list.append(nat_token)\n",
    "#                     ret_tag_list.append(\"NAT\")\n",
    "#                     nat_token = \"\"                    \n",
    "#                 at_token = text[i]\n",
    "#                 state = \"IN_AT\"\n",
    "#             else:\n",
    "#                 nat_token += text[i]\n",
    "#         elif state == \"IN_AT\":\n",
    "#             if text[i] == \" \":\n",
    "#                 if len(at_token.strip()) > 0:\n",
    "#                     ret_token_list.append(at_token)\n",
    "#                     ret_tag_list.append(\"AT\")\n",
    "#                     at_token = \"\"\n",
    "#             elif found_aspect_end_terms(i, aspect_terms):\n",
    "#                 if len(at_token.strip()) > 0:\n",
    "#                     ret_token_list.append(at_token)\n",
    "#                     ret_tag_list.append(\"AT\")\n",
    "#                     at_token = \"\"                    \n",
    "#                 nat_token = text[i]\n",
    "#                 state = \"NOT_AT\"\n",
    "#             else:\n",
    "#                 at_token += text[i]\n",
    "    \n",
    "#     if len(nat_token.strip()) > 0:\n",
    "#         ret_token_list.append(nat_token)\n",
    "#         ret_tag_list.append(\"NAT\")\n",
    "#     if len(at_token.strip()) > 0:\n",
    "#         ret_token_list.append(at_token)\n",
    "#         ret_tag_list.append(\"AT\")\n",
    "    \n",
    "            \n",
    "#     return ret_token_list, ret_tag_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06114f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.'], ['The', 'tech', 'guy', 'then', 'said', 'the', 'service', 'center', 'does', 'not', 'do', '1-to-1', 'exchange', 'and', 'I', 'have', 'to', 'direct', 'my', 'concern', 'to', 'the', '\"sales\"', 'team', ',', 'which', 'is', 'the', 'retail', 'shop', 'which', 'I', 'bought', 'my', 'netbook', 'from.']]\n",
      "[['NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'AT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'AT', 'AT', 'NAT'], ['NAT', 'AT', 'AT', 'NAT', 'NAT', 'NAT', 'AT', 'AT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'AT', 'AT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT', 'NAT']]\n"
     ]
    }
   ],
   "source": [
    "# curr_text = \"\"\n",
    "# curr_aspect_terms = []\n",
    "# sentences = []\n",
    "# aspect_tags = []\n",
    "# i = 0\n",
    "# for row in zip(df['text'], df['aspect_term'], df['from'], df['to'], df['polarity']):\n",
    "#     if curr_text != row[0]:\n",
    "#         l_s, l_at = construct_sentence_aspect_group(curr_text, curr_aspect_terms)\n",
    "#         if len(l_s) > 0:\n",
    "#             sentences.append(l_s)\n",
    "#             aspect_tags.append(l_at)\n",
    "#         curr_text = row[0]\n",
    "#         curr_aspect_terms = [{\n",
    "#             \"term\": row[1],\n",
    "#             \"from\": row[2],\n",
    "#             \"to\": row[3],\n",
    "#             \"polarity\": row[4]\n",
    "#         }]\n",
    "#     else:\n",
    "#         curr_aspect_terms.append({\n",
    "#             \"term\": row[1],\n",
    "#             \"from\": row[2],\n",
    "#             \"to\": row[3],\n",
    "#             \"polarity\": row[4]\n",
    "#         })\n",
    "# #     i += 1\n",
    "# #     if i > 3:\n",
    "# #         break\n",
    "\n",
    "# print(sentences[:2])\n",
    "# print(aspect_tags[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c67183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_aspect_term_dict = dict()\n",
    "\n",
    "for row in zip(df['text'], df['aspect_term'], df['from'], df['to'], df['polarity']):\n",
    "    sentence = row[0]\n",
    "    aspect_term = {\n",
    "        'aspect_term': row[1],\n",
    "        'from': row[2],\n",
    "        'to': row[3],\n",
    "        'polarity': row[4]\n",
    "    }\n",
    "    if sentence in sentence_aspect_term_dict:\n",
    "        sentence_aspect_term_dict[sentence].append(aspect_term)\n",
    "    else:\n",
    "        sentence_aspect_term_dict[sentence] = [aspect_term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0812f426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect_term': 'staff', 'from': 8, 'to': 13, 'polarity': -1}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_aspect_term_dict)\n",
    "sentence_aspect_term_dict[list(sentence_aspect_term_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32deba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# col1_sentence_num = []\n",
    "# col2_sentence_token_list = []\n",
    "# col3_POS_list = []\n",
    "# col4_AT_tag_list = []\n",
    "# col5_polarity_list = []\n",
    "\n",
    "final_data = []\n",
    "\n",
    "num = 1\n",
    "for sentence, aspect_terms in sentence_aspect_term_dict.items():\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    data = []\n",
    "#     sentence_num = []\n",
    "#     token_list = []\n",
    "#     POS_list = []\n",
    "#     AT_tag_list = []\n",
    "#     polarity_list = []\n",
    "    \n",
    "    curr_idx = 0\n",
    "    AT_tag = \"NAT\"\n",
    "    polarity = 0\n",
    "    for w in doc:\n",
    "#         sentence_num.append('s_' + str(num))\n",
    "#         token_list.append(w.text)\n",
    "#         POS_list.append(w.pos_)\n",
    "        \n",
    "        # check if the current word is an aspect term\n",
    "        # first get the current index\n",
    "        curr_idx = sentence.find(w.text, curr_idx)\n",
    "#         print('w: {}; curr_idx: {}'.format(w, curr_idx))\n",
    "        \n",
    "        # second, check if the current index matches any of the aspect term\n",
    "        AT_tag = \"NAT\"\n",
    "        polarity = 0\n",
    "        for t in aspect_terms:\n",
    "            if t['from'] <= curr_idx and curr_idx < t['to']: # the curr_idx is within this aspect term range\n",
    "                AT_tag = \"AT\"\n",
    "                polarity = t['polarity']\n",
    "#                 aspect_terms.remove(t)\n",
    "                break\n",
    "#         AT_tag_list.append(AT_tag)\n",
    "#         polarity_list.append(polarity)\n",
    "        \n",
    "        data.append(('s_'+str(num), w.text, w.pos_, AT_tag, polarity))\n",
    "        \n",
    "        curr_idx += len(w)\n",
    "    \n",
    "#     col1_sentence_num.extend(sentence_num)\n",
    "#     col2_sentence_token_list.extend(token_list)\n",
    "#     col3_POS_list.extend(POS_list)\n",
    "#     col4_AT_tag_list.extend(AT_tag_list)\n",
    "#     col5_polarity_list.extend(polarity_list)\n",
    "    \n",
    "    final_data.extend(data)\n",
    "    \n",
    "    num += 1\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e07c59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s_1', 'But', 'CCONJ', 'NAT', 0),\n",
       " ('s_1', 'the', 'DET', 'NAT', 0),\n",
       " ('s_1', 'staff', 'NOUN', 'AT', -1),\n",
       " ('s_1', 'was', 'AUX', 'NAT', 0),\n",
       " ('s_1', 'so', 'ADV', 'NAT', 0),\n",
       " ('s_1', 'horrible', 'ADJ', 'NAT', 0),\n",
       " ('s_1', 'to', 'ADP', 'NAT', 0),\n",
       " ('s_1', 'us', 'PRON', 'NAT', 0),\n",
       " ('s_1', '.', 'PUNCT', 'NAT', 0),\n",
       " ('s_2', 'To', 'PART', 'NAT', 0),\n",
       " ('s_2', 'be', 'AUX', 'NAT', 0),\n",
       " ('s_2', 'completely', 'ADV', 'NAT', 0),\n",
       " ('s_2', 'fair', 'ADJ', 'NAT', 0),\n",
       " ('s_2', ',', 'PUNCT', 'NAT', 0),\n",
       " ('s_2', 'the', 'DET', 'NAT', 0),\n",
       " ('s_2', 'only', 'ADJ', 'NAT', 0),\n",
       " ('s_2', 'redeeming', 'VERB', 'NAT', 0),\n",
       " ('s_2', 'factor', 'NOUN', 'NAT', 0),\n",
       " ('s_2', 'was', 'AUX', 'NAT', 0),\n",
       " ('s_2', 'the', 'DET', 'NAT', 0),\n",
       " ('s_2', 'food', 'NOUN', 'AT', 1),\n",
       " ('s_2', ',', 'PUNCT', 'NAT', 0),\n",
       " ('s_2', 'which', 'PRON', 'NAT', 0),\n",
       " ('s_2', 'was', 'AUX', 'NAT', 0),\n",
       " ('s_2', 'above', 'ADP', 'NAT', 0),\n",
       " ('s_2', 'average', 'ADJ', 'NAT', 0),\n",
       " ('s_2', ',', 'PUNCT', 'NAT', 0),\n",
       " ('s_2', 'but', 'CCONJ', 'NAT', 0),\n",
       " ('s_2', 'could', 'AUX', 'NAT', 0),\n",
       " ('s_2', \"n't\", 'PART', 'NAT', 0),\n",
       " ('s_2', 'make', 'VERB', 'NAT', 0),\n",
       " ('s_2', 'up', 'ADP', 'NAT', 0),\n",
       " ('s_2', 'for', 'ADP', 'NAT', 0),\n",
       " ('s_2', 'all', 'DET', 'NAT', 0),\n",
       " ('s_2', 'the', 'DET', 'NAT', 0),\n",
       " ('s_2', 'other', 'ADJ', 'NAT', 0),\n",
       " ('s_2', 'deficiencies', 'NOUN', 'NAT', 0),\n",
       " ('s_2', 'of', 'ADP', 'NAT', 0),\n",
       " ('s_2', 'Teodora', 'PROPN', 'NAT', 0),\n",
       " ('s_2', '.', 'PUNCT', 'NAT', 0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e8b2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_data, columns=['num', 'text', 'pos', 'aspect_tag', 'polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e53dbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to csv\n",
    "df.to_csv('data/restaurants_laptop_train_with_pos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56304566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5968bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
