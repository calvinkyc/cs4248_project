{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d01f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6791950",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 8\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99bf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of aspect tags: 2\n",
      "num of polarity tags: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '../data/restaurants_laptop_train_with_pos_task2.csv'\n",
    "# MODEL_PATH = \"model.task2.no_clean.bin\"\n",
    "path = '../data/restaurants_laptop_train_with_pos_task2_cleaned.csv'\n",
    "MODEL_PATH = \"model.task2.cleaned.bin\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "aspect_df = df[df.aspect_tag == \"AT\"]\n",
    "polarity_unique_values = aspect_df.polarity.unique()\n",
    "\n",
    "# df = df[:200]\n",
    "\n",
    "# replace all -1 to 2 since pytorch cannot handle negative\n",
    "# so, 2 now means negative polarity\n",
    "df.polarity = df.polarity.replace(-1,2)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
    "\n",
    "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
    "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
    "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
    "\n",
    "# polarity_unique_values = df.polarity.unique()\n",
    "\n",
    "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
    "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
    "\n",
    "np.where(encoder.classes_ == \"AT\")[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5cd4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>aspect_tag</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_1</td>\n",
       "      <td>charge</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_1</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_1</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_1</td>\n",
       "      <td>night</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56572</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56573</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>rice</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56574</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56575</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>glass</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56576</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>noodles</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56577 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          num     text    pos  aspect_tag  polarity\n",
       "0         s_1        I   PRON           1         0\n",
       "1         s_1   charge   VERB           1         0\n",
       "2         s_1       it   PRON           1         0\n",
       "3         s_1       at    ADP           1         0\n",
       "4         s_1    night   NOUN           1         0\n",
       "...       ...      ...    ...         ...       ...\n",
       "56572  s_3501      and  CCONJ           1         0\n",
       "56573  s_3501     rice   NOUN           0         0\n",
       "56574  s_3501      and  CCONJ           1         0\n",
       "56575  s_3501    glass   NOUN           0         0\n",
       "56576  s_3501  noodles   NOUN           0         0\n",
       "\n",
       "[56577 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abf5a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['However', 'the', 'multi', '-', 'touch', 'gestures', 'and', 'large', 'tracking', 'area', 'make', 'having', 'an', 'external', 'mouse', 'unnecessary', 'unless', 'you', \"'re\", 'gaming']\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(sentences[idx])\n",
    "print(aspect_tags[idx])\n",
    "print(polarity_tags[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af348a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            data[k] = to_device(v, device)\n",
    "        return data\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739a3984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "NUM_POLARITY_TAGS = len(polarity_unique_values)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b65241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTagDataset(Dataset):\n",
    "    def __init__(self, tokenizer, sentences, aspect_tags, polarity_tags, aspect_term_tag, \n",
    "                 max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.aspect_tags = aspect_tags\n",
    "        self.polarity_tags = polarity_tags\n",
    "        self.aspect_term_tag = aspect_term_tag\n",
    "        self.max_length = max_length\n",
    "        self.special_token = -100\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]  # Get a sentence\n",
    "        aspect_tags = self.aspect_tags[idx]  # Get the corresponding aspect tags\n",
    "        polarity_tags = self.polarity_tags[idx]\n",
    "\n",
    "        sentence_encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            is_split_into_words=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        word_ids = sentence_encoding.word_ids(batch_index=0)\n",
    "        polarity_tags_encoding = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                polarity_tags_encoding.append(self.special_token)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                if aspect_tags[word_idx] == self.aspect_term_tag:\n",
    "                    polarity_tags_encoding.append(polarity_tags[word_idx])\n",
    "                else:\n",
    "                    polarity_tags_encoding.append(self.special_token)\n",
    "            else:\n",
    "                polarity_tags_encoding.append(self.special_token)\n",
    "            previous_word_idx = word_idx\n",
    "        polarity_tags_encoding = torch.LongTensor(polarity_tags_encoding)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": sentence_encoding[\"input_ids\"][0],\n",
    "            \"attention_mask\": sentence_encoding[\"attention_mask\"][0],\n",
    "            \"token_type_ids\": sentence_encoding[\"token_type_ids\"][0],\n",
    "            \"polarity_tags\": polarity_tags_encoding,\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad052c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, target, mask, num_labels):\n",
    "    cel = nn.CrossEntropyLoss()\n",
    "    masking = mask.view(-1) == 1\n",
    "    pred = output.view(-1, num_labels)\n",
    "    true = torch.where(masking, target.view(-1), \n",
    "                       torch.tensor(cel.ignore_index).type_as(target))\n",
    "    \n",
    "    loss = cel(pred, true)\n",
    "    return loss\n",
    "\n",
    "class PolarityExtractionModel(nn.Module):\n",
    "    def __init__(self, num_polarity_tags, num_vocab):\n",
    "        super(PolarityExtractionModel, self).__init__()\n",
    "        self.num_polarity_tags = num_polarity_tags\n",
    "        self.bert_model = transformers.BertModel.from_pretrained(\"bert-base-cased\")        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        # self.bert.config.hidden_size is 768\n",
    "        self.fc = nn.Linear(self.bert_model.config.hidden_size, self.num_polarity_tags)\n",
    "        # if the number of vocab has been increased, then need to add the new vector \n",
    "        # at the end of the embedding matrix\n",
    "        self.bert_model.resize_token_embeddings(num_vocab)\n",
    "                \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, polarity_tags):\n",
    "        out, _ = self.bert_model(input_ids, attention_mask = attention_mask, \n",
    "                                 token_type_ids = token_type_ids, return_dict=False)\n",
    "        \n",
    "        pol_out = self.dropout(out)\n",
    "        pol_out = self.fc(pol_out)\n",
    "        \n",
    "        loss_pol = loss_fn(pol_out, polarity_tags, attention_mask, self.num_polarity_tags)\n",
    "        \n",
    "        s = nn.Softmax(dim=2)\n",
    "        \n",
    "        pol_out = s(pol_out)\n",
    "        \n",
    "        return pol_out, loss_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e888395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(pred_tags, true_tags):\n",
    "    if isinstance(pred_tags, list):\n",
    "        pred_tags = torch.cat(pred_tags, 0)\n",
    "        true_tags = torch.cat(true_tags, 0)\n",
    "    pred_tags = pred_tags[true_tags!=-100]\n",
    "    true_tags = true_tags[true_tags!=-100]\n",
    "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
    "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
    "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
    "\n",
    "    return acc, f1, cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883d3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2800,), (701,), (2800,), (701,), (2800,), (701,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_sentences, test_sentences, \n",
    " train_aspect_tags, test_aspect_tags, \n",
    " train_polarity_tags, test_polarity_tags) = model_selection.train_test_split(\n",
    "    sentences, aspect_tags, polarity_tags, random_state = 42, test_size = TEST_SIZE)\n",
    "\n",
    "train_sentences.shape, test_sentences.shape, train_aspect_tags.shape, test_aspect_tags.shape, train_polarity_tags.shape, test_polarity_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52bef269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'had', 'it', 'months', 'when', 'my', 'disc', 'drive', 'refused', 'to', 'open']\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(train_sentences[idx])\n",
    "print(train_aspect_tags[idx])\n",
    "print(train_polarity_tags[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d5b8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=train_sentences, \n",
    "                                   aspect_tags=train_aspect_tags,\n",
    "                                   polarity_tags=train_polarity_tags,\n",
    "                                   aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE), device)    \n",
    "\n",
    "test_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=test_sentences, \n",
    "                                  aspect_tags=test_aspect_tags,\n",
    "                                  polarity_tags=test_polarity_tags,\n",
    "                                  aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "test_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=TEST_BATCH_SIZE), device)   \n",
    "\n",
    "model = to_device(PolarityExtractionModel(num_polarity_tags = NUM_POLARITY_TAGS,\n",
    "                                          num_vocab = len(tokenizer)), device)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa1753e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:44<00:00,  1.98it/s]\n",
      "100%|██████████| 88/88 [00:04<00:00, 19.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.80754; Valid Loss: 0.60772\n",
      "Polarity Train acc: 63.18%; Valid acc: 75.10%\n",
      "Polarity Train f1: 61.67%; Valid f1: 73.69%\n",
      "Polarity Train cm:\n",
      " [[ 921  864   99]\n",
      " [ 326 3149  113]\n",
      " [ 337  743  189]]\n",
      "Polarity Valid cm:\n",
      " [[358  73  27]\n",
      " [ 62 851  41]\n",
      " [105 138 136]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:45<00:00,  1.94it/s]\n",
      "100%|██████████| 88/88 [00:04<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.44945; Valid Loss: 0.63232\n",
      "Polarity Train acc: 81.74%; Valid acc: 77.50%\n",
      "Polarity Train f1: 81.73%; Valid f1: 78.00%\n",
      "Polarity Train cm:\n",
      " [[1573  160  151]\n",
      " [ 163 3259  166]\n",
      " [ 311  280  678]]\n",
      "Polarity Valid cm:\n",
      " [[356  45  57]\n",
      " [ 55 817  82]\n",
      " [ 73  91 215]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:46<00:00,  1.91it/s]\n",
      "100%|██████████| 88/88 [00:04<00:00, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.29077; Valid Loss: 0.64085\n",
      "Polarity Train acc: 89.11%; Valid acc: 77.16%\n",
      "Polarity Train f1: 89.20%; Valid f1: 77.16%\n",
      "Polarity Train cm:\n",
      " [[1723   53  108]\n",
      " [  85 3388  115]\n",
      " [ 209  164  896]]\n",
      "Polarity Valid cm:\n",
      " [[331  78  49]\n",
      " [ 39 856  59]\n",
      " [ 60 124 195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_train_steps = int(len(train_sentences) / TRAIN_BATCH_SIZE * NUM_EPOCHS)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=num_train_steps)\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": list(),\n",
    "    \"polarity_train_acc\": list(),\n",
    "    \"valid_loss\": list(),\n",
    "    \"polarity_valid_acc\": list(),\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    train_f1 = []\n",
    "    test_f1 = []\n",
    "\n",
    "    model.train()\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    for data in tqdm(train_data_loader, total=len(train_data_loader)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_polarity_tags, loss = model(**data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        final_pred_polarity_tags.append(torch.argmax(pred_polarity_tags, dim=2))\n",
    "        final_true_polarity_tags.append(data['polarity_tags'])\n",
    "        \n",
    "#         print(pred_polarity_tags)\n",
    "#         print(data['polarity_tags'])\n",
    "\n",
    "    polarity_train_acc, polarity_train_f1, polarity_train_cm = cal_acc(final_pred_polarity_tags, \n",
    "                                                                       final_true_polarity_tags)\n",
    "        \n",
    "    model.eval()\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "        pred_polarity_tags, loss = model(**data)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "        final_pred_polarity_tags.append(torch.argmax(pred_polarity_tags, dim=2))\n",
    "        final_true_polarity_tags.append(data['polarity_tags'])\n",
    "\n",
    "    polarity_test_acc, polarity_test_f1, polarity_test_cm = cal_acc(final_pred_polarity_tags, \n",
    "                                                                    final_true_polarity_tags)\n",
    "\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
    "        \n",
    "    print(\"Train Loss: {:.5f}; Valid Loss: {:.5f}\".format(avg_train_loss, avg_test_loss))\n",
    "    print(\"Polarity Train acc: {:.2f}%; Valid acc: {:.2f}%\".format(\n",
    "        polarity_train_acc*100, polarity_test_acc*100))\n",
    "    print(\"Polarity Train f1: {:.2f}%; Valid f1: {:.2f}%\".format(\n",
    "        polarity_train_f1*100, polarity_test_f1*100))\n",
    "    print(\"Polarity Train cm:\\n {}\".format(np.flip(polarity_train_cm)))\n",
    "    print(\"Polarity Valid cm:\\n {}\".format(np.flip(polarity_test_cm)))\n",
    "    \n",
    "    if avg_test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        best_loss = avg_test_loss    \n",
    "        \n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['valid_loss'].append(avg_test_loss)\n",
    "    history['polarity_train_acc'].append(polarity_train_acc.cpu().numpy())\n",
    "    history['polarity_valid_acc'].append(polarity_test_acc.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac026d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
    "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0.6, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea406efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: model.task2.cleaned.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:04<00:00, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.67      0.36      0.47       379\n",
      "    Positive       0.80      0.89      0.84       954\n",
      "    Negative       0.68      0.78      0.73       458\n",
      "\n",
      "    accuracy                           0.75      1791\n",
      "   macro avg       0.72      0.68      0.68      1791\n",
      "weighted avg       0.74      0.75      0.73      1791\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_classification_report(test_data_loader, model, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)   \n",
    "    \n",
    "    model.eval()\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "            pred_polarity_tags, loss = model(**data)\n",
    "            \n",
    "            final_pred_polarity_tags.extend(torch.argmax(pred_polarity_tags, dim=2))\n",
    "            final_true_polarity_tags.extend(data['polarity_tags'])\n",
    "            \n",
    "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
    "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
    "    \n",
    "    # Remove the special -100 tokens \n",
    "    final_pred_polarity_tags = final_pred_polarity_tags[final_true_polarity_tags!=-100]\n",
    "    final_true_polarity_tags = final_true_polarity_tags[final_true_polarity_tags!=-100]\n",
    "        \n",
    "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
    "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
    "    \n",
    "get_classification_report(test_data_loader, model, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a71c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(test_dataset, test_data_loader, model, num=5, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num):\n",
    "            \n",
    "            data = next(iter(test_data_loader))\n",
    "            \n",
    "            pred_polarity_tags, _ = model(**data)\n",
    "            \n",
    "            \n",
    "            input_ids = data['input_ids']\n",
    "            pred_polarity_tags = torch.argmax(pred_polarity_tags, dim=2)\n",
    "            true_polarity_tags = data['polarity_tags']\n",
    "            mask = data['attention_mask']\n",
    "            \n",
    "            # Randomly pick a test data from this batch\n",
    "            #\n",
    "            rng = np.random.default_rng()\n",
    "            idx = rng.integers(low=0, high=pred_polarity_tags.shape[0],size=1)[0]\n",
    "#             idx = np.random.randint(0,pred_aspect_tags.shape[0],size=1)[0]\n",
    "\n",
    "            ids_array = input_ids[idx].cpu().numpy()\n",
    "            pred_polarity_array = pred_polarity_tags[idx].cpu().numpy()\n",
    "            true_polarity_array = true_polarity_tags[idx].cpu().numpy()\n",
    "            mask_array = mask[idx].cpu().numpy()\n",
    "\n",
    "            # Remove the padding as we do not want to print them\n",
    "            #\n",
    "            mask_array = np.logical_not(mask_array)\n",
    "\n",
    "            # Only print the unpadded portion\n",
    "            ids_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, ids_array))\n",
    "            pred_polarity_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                         pred_polarity_array))\n",
    "            true_polarity_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                         true_polarity_array))\n",
    "            \n",
    "            polarity_pred = pred_polarity_unpadded[true_polarity_unpadded!=-100]\n",
    "            polarity_true = true_polarity_unpadded[true_polarity_unpadded!=-100]\n",
    "            \n",
    "            polarity_acc = np.sum(polarity_pred == polarity_true) / len(polarity_pred)\n",
    "            \n",
    "            # Remove begin and end\n",
    "            ids_unpadded = ids_unpadded[1:-1]\n",
    "            pred_polarity_unpadded = pred_polarity_unpadded[1:-1]\n",
    "            true_polarity_unpadded = true_polarity_unpadded[1:-1]\n",
    "            \n",
    "            # let's replace 2 back to -1 for presentation\n",
    "            pred_polarity_unpadded = np.where(pred_polarity_unpadded == 2, -1, \n",
    "                                              pred_polarity_unpadded)\n",
    "            true_polarity_unpadded = np.where(true_polarity_unpadded == 2, -1, \n",
    "                                              true_polarity_unpadded)\n",
    "            \n",
    "            orig_sentence = np.array(tokenizer.convert_ids_to_tokens(ids_unpadded))\n",
    "            \n",
    "#             pred_polarity_unpadded = pred_polarity_unpadded[aspect_tag_indices]\n",
    "#             true_polarity_unpadded = true_polarity_unpadded[aspect_tag_indices]\n",
    "\n",
    "            print(\"Polarity Acc: {:.2f}%\".format(polarity_acc*100))\n",
    "            print(\"Predicted Polarity:\")\n",
    "            print(pred_polarity_unpadded)\n",
    "            print(\"True Polarity:\")\n",
    "            print(true_polarity_unpadded)\n",
    "            print(\"Sentence:\")\n",
    "            print(orig_sentence)   \n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67842c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: model.task2.cleaned.bin\n",
      "Polarity Acc: 100.00%\n",
      "Predicted Polarity:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True Polarity:\n",
      "[-100    1 -100 -100    1    1 -100    1    1 -100 -100    1 -100 -100]\n",
      "Sentence:\n",
      "['Best' 'drums' '##tick' '##s' 'over' 'rice' 'and' 'sour' 's' '##pic'\n",
      " '##y' 'soup' 'in' 'town']\n",
      "\n",
      "Polarity Acc: 100.00%\n",
      "Predicted Polarity:\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "True Polarity:\n",
      "[-100 -100 -100 -100 -100 -100    1 -100 -100 -100]\n",
      "Sentence:\n",
      "['He' 'takes' 'real' 'pride' 'in' 'his' 'food' 'and' 'his' 'business']\n",
      "\n",
      "Polarity Acc: 0.00%\n",
      "Predicted Polarity:\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
      "True Polarity:\n",
      "[-100 -100 -100 -100 -100 -100    0 -100 -100 -100 -100    0 -100    0\n",
      " -100 -100]\n",
      "Sentence:\n",
      "['We' 'got' 'in' 'line' 'and' 'were' 'served' 'while' 'in' 'line' 'a'\n",
      " 'ban' '##nan' 'f' '##rit' '##ter']\n",
      "\n",
      "Polarity Acc: 50.00%\n",
      "Predicted Polarity:\n",
      "[-1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "True Polarity:\n",
      "[-100    0    0 -100 -100 -100 -100   -1 -100 -100   -1 -100 -100 -100]\n",
      "Sentence:\n",
      "['The' 'menu' 'choices' 'are' 'similar' 'but' 'the' 'taste' 'lacked'\n",
      " 'more' 'flavor' 'than' 'it' 'looked']\n",
      "\n",
      "Polarity Acc: 100.00%\n",
      "Predicted Polarity:\n",
      "[-1  1  1  1  0  1  1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "True Polarity:\n",
      "[-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100   -1 -100 -100 -100 -100   -1   -1 -100\n",
      " -100 -100 -100 -100 -100]\n",
      "Sentence:\n",
      "['They' 'sent' 'out' 'the' 'box' 'right' 'away' 'for' 'me' 'to' 'send'\n",
      " 'in' 'my' 'computer' 'they' 'paid' 'post' '##age' 'and' 'what' '##not'\n",
      " 'but' 'when' 'I' 'got' 'my' 'computer' 'back' 'it' 'still' 'was' 'n' \"'\"\n",
      " 't' 'running' 'right' 'and' 'now' 'my' 'CD' 'drive' 'was' 'n' \"'\" 't'\n",
      " 'reading' 'anything']\n",
      "\n",
      "Polarity Acc: 100.00%\n",
      "Predicted Polarity:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True Polarity:\n",
      "[-100    1 -100 -100    1    1 -100    1    1 -100 -100    1 -100 -100]\n",
      "Sentence:\n",
      "['Best' 'drums' '##tick' '##s' 'over' 'rice' 'and' 'sour' 's' '##pic'\n",
      " '##y' 'soup' 'in' 'town']\n",
      "\n",
      "Polarity Acc: 0.00%\n",
      "Predicted Polarity:\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
      "True Polarity:\n",
      "[-100 -100 -100 -100 -100 -100    0 -100 -100 -100 -100    0 -100    0\n",
      " -100 -100]\n",
      "Sentence:\n",
      "['We' 'got' 'in' 'line' 'and' 'were' 'served' 'while' 'in' 'line' 'a'\n",
      " 'ban' '##nan' 'f' '##rit' '##ter']\n",
      "\n",
      "Polarity Acc: 100.00%\n",
      "Predicted Polarity:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True Polarity:\n",
      "[-100    1 -100 -100    1    1 -100    1    1 -100 -100    1 -100 -100]\n",
      "Sentence:\n",
      "['Best' 'drums' '##tick' '##s' 'over' 'rice' 'and' 'sour' 's' '##pic'\n",
      " '##y' 'soup' 'in' 'town']\n",
      "\n",
      "Polarity Acc: 100.00%\n",
      "Predicted Polarity:\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "True Polarity:\n",
      "[-100   -1 -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      "Sentence:\n",
      "['The' 'screen' 'almost' 'looked' 'like' 'a' 'bar' '##code' 'when' 'it'\n",
      " 'froze']\n",
      "\n",
      "Polarity Acc: 100.00%\n",
      "Predicted Polarity:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True Polarity:\n",
      "[-100    1 -100 -100    1    1 -100    1    1 -100 -100    1 -100 -100]\n",
      "Sentence:\n",
      "['Best' 'drums' '##tick' '##s' 'over' 'rice' 'and' 'sour' 's' '##pic'\n",
      " '##y' 'soup' 'in' 'town']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_test(test_dataset, test_data_loader, model, num=10, model_path=MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b24aac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Raw Data\n",
      "*** input_ids\n",
      "tensor([  101,  1109,  4382,  1110,  1843,  1105,  1136,  1304,  8394,  1105,\n",
      "         1173,  1128,  1138,  3205,  4204, 10825,  1113,  1128,  4518,  1128,\n",
      "         1107,  1103,  4997,  1609,  1936,  3634,  1111, 18679,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "*** polarity_tags\n",
      "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100,    2,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])\n",
      "\n",
      "['[CLS]' 'The' 'restaurant' 'is' 'dark' 'and' 'not' 'very' 'attractive'\n",
      " 'and' 'then' 'you' 'have' 'spot' 'lights' 'shining' 'on' 'you' 'putting'\n",
      " 'you' 'in' 'the' 'worst' 'light' 'possible' 'reaching' 'for' 'sunglasses'\n",
      " '[SEP]']\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "def test_dataset(idx=0):\n",
    "\n",
    "\n",
    "    train_dataset = SentenceTagDataset(tokenizer=tokenizer,\n",
    "                                       sentences=train_sentences,\n",
    "                                       aspect_tags=train_aspect_tags,\n",
    "                                       polarity_tags=train_polarity_tags,\n",
    "                                       aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "\n",
    "    train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=32), device)    \n",
    "\n",
    "    data = train_dataset[idx]\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = np.logical_not(data['attention_mask'])\n",
    "#     aspect_tags = data['aspect_tags']\n",
    "    polarity_tags = data['polarity_tags']\n",
    "    \n",
    "    print(\"*** Raw Data\")\n",
    "    print(\"*** input_ids\")\n",
    "    print(input_ids)\n",
    "#     print(\"*** aspect_tags\")\n",
    "#     print(aspect_tags)\n",
    "    print(\"*** polarity_tags\")\n",
    "    print(polarity_tags)\n",
    "    print()\n",
    "    \n",
    "    input_ids = np.ma.compressed(np.ma.masked_where(attention_mask, input_ids))\n",
    "#     aspect_tags = np.ma.compressed(np.ma.masked_where(attention_mask, aspect_tags))\n",
    "    polarity_tags = np.ma.compressed(np.ma.masked_where(attention_mask, polarity_tags))\n",
    "    \n",
    "#     input_ids = input_ids[(input_ids!=101) & (input_ids!=102)]\n",
    "    \n",
    "#     aspect_tags = np.where(aspect_tags==-100, 1, aspect_tags)\n",
    "#     polarity_tags = np.where(polarity_tags==-100, 0, polarity_tags)\n",
    "    \n",
    "#     aspect_tags = aspect_tags[aspect_tags!=-100]\n",
    "    polarity_tags = polarity_tags[polarity_tags!=-100]\n",
    "    \n",
    "    orig_sentence = np.array(train_dataset.tokenizer.convert_ids_to_tokens(input_ids))\n",
    "#     decoded_aspect_tags = encoder.inverse_transform(aspect_tags)\n",
    "    \n",
    "#     aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "    \n",
    "    print(orig_sentence)\n",
    "#     print(decoded_aspect_tags)  \n",
    "    print(polarity_tags)  \n",
    "    \n",
    "#     print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "\n",
    "test_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b0500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
