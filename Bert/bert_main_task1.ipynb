{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d01f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e4e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_EPOCHS = 5\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 8\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99bf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of aspect tags: 2\n",
      "The aspect term encoded numeric is: 0\n"
     ]
    }
   ],
   "source": [
    "path = '../Dataset/data/restaurants_laptop_train_with_pos_task1.csv'\n",
    "MODEL_PATH = \"model.task1.no_clean.bin\"\n",
    "\n",
    "# path = '../Dataset/data/restaurants_laptop_train_with_pos_task1_cleaned.csv'\n",
    "# MODEL_PATH = \"model.task1.cleaned.bin\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
    "\n",
    "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
    "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
    "\n",
    "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
    "\n",
    "print('The aspect term encoded numeric is: {}'.format(np.where(encoder.classes_ == \"AT\")[0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b5cd4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>aspect_tag</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_1</td>\n",
       "      <td>charge</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_1</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_1</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_1</td>\n",
       "      <td>night</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64486</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>rice</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64487</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64488</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>glass</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64489</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>noodles</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64490</th>\n",
       "      <td>s_3501</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64491 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          num     text    pos  aspect_tag  polarity\n",
       "0         s_1        I   PRON           1         0\n",
       "1         s_1   charge   VERB           1         0\n",
       "2         s_1       it   PRON           1         0\n",
       "3         s_1       at    ADP           1         0\n",
       "4         s_1    night   NOUN           1         0\n",
       "...       ...      ...    ...         ...       ...\n",
       "64486  s_3501     rice   NOUN           0         0\n",
       "64487  s_3501      and  CCONJ           1         0\n",
       "64488  s_3501    glass   NOUN           0         0\n",
       "64489  s_3501  noodles   NOUN           0         0\n",
       "64490  s_3501        .  PUNCT           1         0\n",
       "\n",
       "[64491 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abf5a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['(', 'The', 'iBook', 'backup', 'also', 'uses', 'a', 'firewire', 'connection', ')', '.']\n",
      "Labels: [1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "idx = 49\n",
    "print(\"Tokens: {}\".format(sentences[idx]))\n",
    "print(\"Labels: {}\".format(aspect_tags[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21ab0cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['I', 'had', '3', 'months', 'when', 'the', 'ports', 'started', 'going', 'out', '.']\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "5\n",
      "['It', 'is', 'super', 'easy', 'to', 'use', '.']\n",
      "[1, 1, 1, 1, 1, 0, 1]\n",
      "6\n",
      "['Many', 'of', 'my', 'classmates', 'computers', 'hard', 'drives', 'crashed', '.']\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "12\n",
      "['The', 'speakers', 'on', 'it', 'are', 'useless', 'too', '.']\n",
      "[1, 0, 1, 1, 1, 1, 1, 1]\n",
      "47\n",
      "['It', 'is', 'sleek', 'and', 'lightweight', 'and', 'charges', 'quickly', 'when', 'needed', '.']\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "49\n",
      "['(', 'The', 'iBook', 'backup', 'also', 'uses', 'a', 'firewire', 'connection', ')', '.']\n",
      "[1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1]\n",
      "51\n",
      "['Also', 'the', 'display', 'is', 'exceptional', '!']\n",
      "[1, 1, 0, 1, 1, 1]\n",
      "64\n",
      "['company', 'provides', 'UPS', 'shipping', ',', 'fast', ',', 'great', '!']\n",
      "[1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "69\n",
      "['Great', 'product', ',', 'very', 'easy', 'to', 'use', 'and', 'great', 'graphics', '.']\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1]\n",
      "78\n",
      "['Disappointing', 'for', 'such', 'a', 'lovely', 'screen', 'and', 'at', 'a', 'reasonable', 'price']\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(10):\n",
    "    for j in range(s,len(sentences)):\n",
    "        if len(sentences[j]) < 12:\n",
    "            print(j)\n",
    "            print(sentences[j])\n",
    "            print(aspect_tags[j])\n",
    "            s = j+1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af348a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            data[k] = to_device(v, device)\n",
    "        return data\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739a3984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "\n",
    "NUM_ASPECT_TAGS = len(encoder.classes_)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b65241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTagDataset(Dataset):\n",
    "    def __init__(self, tokenizer, sentences, aspect_tags, aspect_term_tag, \n",
    "                 max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.aspect_tags = aspect_tags\n",
    "        self.aspect_term_tag = aspect_term_tag\n",
    "        self.max_length = max_length\n",
    "        self.special_token = -100\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]  # Get a sentence\n",
    "        aspect_tags = self.aspect_tags[idx]  # Get the corresponding aspect tags\n",
    "\n",
    "        sentence_encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            is_split_into_words=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        word_ids = sentence_encoding.word_ids(batch_index=0)\n",
    "        aspect_tags_encoding = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                aspect_tags_encoding.append(aspect_tags[word_idx])\n",
    "            else:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "            previous_word_idx = word_idx\n",
    "        aspect_tags_encoding = torch.LongTensor(aspect_tags_encoding)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": sentence_encoding[\"input_ids\"][0],\n",
    "            \"attention_mask\": sentence_encoding[\"attention_mask\"][0],\n",
    "            \"token_type_ids\": sentence_encoding[\"token_type_ids\"][0],\n",
    "            \"aspect_tags\": aspect_tags_encoding,\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad052c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, target, mask, num_labels):\n",
    "    cel = nn.CrossEntropyLoss()\n",
    "    masking = mask.view(-1) == 1\n",
    "    pred = output.view(-1, num_labels)\n",
    "    true = torch.where(masking, target.view(-1), \n",
    "                       torch.tensor(cel.ignore_index).type_as(target))\n",
    "    \n",
    "    loss = cel(pred, true)\n",
    "    return loss\n",
    "\n",
    "class AspectExtractionModel(nn.Module):\n",
    "    def __init__(self, num_aspect_tags, num_vocab):\n",
    "        super(AspectExtractionModel, self).__init__()\n",
    "        self.num_aspect_tags = num_aspect_tags\n",
    "        self.bert_model = transformers.BertModel.from_pretrained(\"bert-base-cased\")        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(768, self.num_aspect_tags)\n",
    "        # if the number of vocab has been increased, then need to add the new vector \n",
    "        # at the end of the embedding matrix\n",
    "        self.bert_model.resize_token_embeddings(num_vocab)\n",
    "                \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, aspect_tags):\n",
    "        out, pool_out = self.bert_model(input_ids, attention_mask = attention_mask, \n",
    "                                 token_type_ids = token_type_ids, return_dict=False)\n",
    "        \n",
    "        tag_out = self.dropout(out)\n",
    "        tag_out = self.fc(tag_out)\n",
    "        \n",
    "        loss_tag = loss_fn(tag_out, aspect_tags, attention_mask, self.num_aspect_tags)\n",
    "        \n",
    "        s = nn.Softmax(dim=2)\n",
    "        \n",
    "        tag_out = s(tag_out)\n",
    "        \n",
    "        return tag_out, loss_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e888395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(pred_tags, true_tags):\n",
    "    if isinstance(pred_tags, list):\n",
    "        pred_tags = torch.cat(pred_tags, 0)\n",
    "        true_tags = torch.cat(true_tags, 0)\n",
    "    pred_tags = pred_tags[true_tags!=-100]\n",
    "    true_tags = true_tags[true_tags!=-100]\n",
    "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
    "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
    "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
    "\n",
    "    return acc, f1, cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883d3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2800,), (701,), (2800,), (701,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_sentences, test_sentences, \n",
    " train_aspect_tags, test_aspect_tags) = model_selection.train_test_split(\n",
    "    sentences, aspect_tags, random_state = 42, test_size = TEST_SIZE)\n",
    "\n",
    "train_sentences.shape, test_sentences.shape, train_aspect_tags.shape, test_aspect_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52bef269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'had', 'it', 'four', 'months', 'when', 'my', 'disc', 'drive', 'refused', 'to', 'open', '.']\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(train_sentences[idx])\n",
    "print(train_aspect_tags[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d5b8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=train_sentences, \n",
    "                                   aspect_tags=train_aspect_tags,\n",
    "                                   aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE), device)    \n",
    "\n",
    "test_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=test_sentences, \n",
    "                                  aspect_tags=test_aspect_tags,\n",
    "                                  aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "test_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=TEST_BATCH_SIZE), device)   \n",
    "\n",
    "model = to_device(AspectExtractionModel(num_aspect_tags = NUM_ASPECT_TAGS, \n",
    "                                        num_vocab = len(tokenizer)), device)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa1753e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:46<00:00,  1.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.17708; Valid Loss: 0.09507\n",
      "Aspect Train acc: 92.04%; Valid acc: 96.12%\n",
      "Aspect Train f1: 91.87%; Valid f1: 96.16%\n",
      "Aspect Train cm:\n",
      " [[42785  1720]\n",
      " [ 2379  4599]]\n",
      "Aspect Valid cm:\n",
      " [[10733   296]\n",
      " [  204  1641]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:47<00:00,  1.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06815; Valid Loss: 0.09098\n",
      "Aspect Train acc: 97.40%; Valid acc: 96.67%\n",
      "Aspect Train f1: 97.40%; Valid f1: 96.71%\n",
      "Aspect Train cm:\n",
      " [[43831   674]\n",
      " [  664  6314]]\n",
      "Aspect Valid cm:\n",
      " [[10754   275]\n",
      " [  154  1691]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:48<00:00,  1.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03774; Valid Loss: 0.10000\n",
      "Aspect Train acc: 98.62%; Valid acc: 96.81%\n",
      "Aspect Train f1: 98.62%; Valid f1: 96.85%\n",
      "Aspect Train cm:\n",
      " [[44133   372]\n",
      " [  340  6638]]\n",
      "Aspect Valid cm:\n",
      " [[10769   260]\n",
      " [  151  1694]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:49<00:00,  1.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02263; Valid Loss: 0.10844\n",
      "Aspect Train acc: 99.25%; Valid acc: 97.02%\n",
      "Aspect Train f1: 99.25%; Valid f1: 97.01%\n",
      "Aspect Train cm:\n",
      " [[44297   208]\n",
      " [  180  6798]]\n",
      "Aspect Valid cm:\n",
      " [[10846   183]\n",
      " [  201  1644]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:49<00:00,  1.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01678; Valid Loss: 0.11095\n",
      "Aspect Train acc: 99.47%; Valid acc: 96.86%\n",
      "Aspect Train f1: 99.47%; Valid f1: 96.88%\n",
      "Aspect Train cm:\n",
      " [[44357   148]\n",
      " [  124  6854]]\n",
      "Aspect Valid cm:\n",
      " [[10798   231]\n",
      " [  173  1672]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_train_steps = int(len(train_sentences) / TRAIN_BATCH_SIZE * NUM_EPOCHS)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=num_train_steps)\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": list(),\n",
    "    \"aspact_train_acc\": list(),\n",
    "    \"valid_loss\": list(),\n",
    "    \"aspact_valid_acc\": list(),\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    train_f1 = []\n",
    "    test_f1 = []\n",
    "\n",
    "    model.train()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    for data in tqdm(train_data_loader, total=len(train_data_loader)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_aspect_tags, loss = model(**data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "        \n",
    "    aspect_train_acc, aspect_train_f1, aspect_train_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                                 final_true_aspect_tags)\n",
    "\n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "        pred_aspect_tags, loss = model(**data)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "\n",
    "    aspect_test_acc, aspect_test_f1, aspect_test_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                              final_true_aspect_tags)\n",
    "\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
    "        \n",
    "    print(\"Train Loss: {:.5f}; Valid Loss: {:.5f}\".format(avg_train_loss, avg_test_loss))\n",
    "    print(\"Aspect Train acc: {:.2f}%; Valid acc: {:.2f}%\".format(\n",
    "        aspect_train_acc*100, aspect_test_acc*100))\n",
    "    print(\"Aspect Train f1: {:.2f}%; Valid f1: {:.2f}%\".format(\n",
    "        aspect_train_f1*100, aspect_test_f1*100))\n",
    "    print(\"Aspect Train cm:\\n {}\".format(np.flip(aspect_train_cm)))\n",
    "    print(\"Aspect Valid cm:\\n {}\".format(np.flip(aspect_test_cm)))\n",
    "    print()\n",
    "    \n",
    "    if avg_test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        best_loss = avg_test_loss    \n",
    "        \n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['aspact_train_acc'].append(aspect_train_acc.cpu().numpy())\n",
    "    history['valid_loss'].append(avg_test_loss)\n",
    "    history['aspact_valid_acc'].append(aspect_test_acc.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac026d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['aspact_train_acc'], label='train accuracy')\n",
    "plt.plot(history['aspact_valid_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea406efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: model.task1.no_clean.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AT       0.86      0.92      0.89      1845\n",
      "         NAT       0.99      0.98      0.98     11029\n",
      "\n",
      "    accuracy                           0.97     12874\n",
      "   macro avg       0.92      0.95      0.93     12874\n",
      "weighted avg       0.97      0.97      0.97     12874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_classification_report(test_data_loader, model, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)   \n",
    "    \n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "            pred_aspect_tags, loss = model(**data)\n",
    "            \n",
    "            final_pred_aspect_tags.extend(torch.argmax(pred_aspect_tags, dim=2))\n",
    "            final_true_aspect_tags.extend(data['aspect_tags'])\n",
    "            \n",
    "    final_pred_aspect_tags = torch.stack(final_pred_aspect_tags).cpu()\n",
    "    final_true_aspect_tags = torch.stack(final_true_aspect_tags).cpu()\n",
    "    \n",
    "    # Remove the special -100 tokens \n",
    "    final_pred_aspect_tags = final_pred_aspect_tags[final_true_aspect_tags!=-100]\n",
    "    final_true_aspect_tags = final_true_aspect_tags[final_true_aspect_tags!=-100]\n",
    "        \n",
    "    print(classification_report(final_true_aspect_tags, final_pred_aspect_tags, \n",
    "                                target_names=encoder.classes_))\n",
    "    \n",
    "get_classification_report(test_data_loader, model, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a71c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(test_dataset, test_data_loader, model, num=5, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num):\n",
    "            \n",
    "            data = next(iter(test_data_loader))\n",
    "            \n",
    "            pred_aspect_tags, _ = model(**data)\n",
    "            \n",
    "            \n",
    "            input_ids = data['input_ids']\n",
    "            pred_aspect_tags = torch.argmax(pred_aspect_tags, dim=2)\n",
    "            true_aspect_tags = data['aspect_tags']\n",
    "            mask = data['attention_mask']\n",
    "            \n",
    "            # Randomly pick a test data from this batch\n",
    "            #\n",
    "            rng = np.random.default_rng()\n",
    "            idx = rng.integers(low=0, high=pred_aspect_tags.shape[0],size=1)[0]\n",
    "\n",
    "            ids_array = input_ids[idx].cpu().numpy()\n",
    "            pred_aspect_array = pred_aspect_tags[idx].cpu().numpy()\n",
    "            true_aspect_array = true_aspect_tags[idx].cpu().numpy()\n",
    "            mask_array = mask[idx].cpu().numpy()\n",
    "\n",
    "            # Remove the padding as we do not want to print them\n",
    "            #\n",
    "            mask_array = np.logical_not(mask_array)\n",
    "\n",
    "            # Only print the unpadded portion\n",
    "            ids_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, ids_array))\n",
    "            pred_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       pred_aspect_array))\n",
    "            true_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       true_aspect_array))\n",
    "            \n",
    "            aspect_pred = pred_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            aspect_true = true_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            \n",
    "            aspect_acc = np.sum(aspect_pred == aspect_true) / len(aspect_pred)\n",
    "            \n",
    "            # Remove begin and end\n",
    "            ids_unpadded = ids_unpadded[1:-1]\n",
    "            pred_aspect_unpadded = pred_aspect_unpadded[1:-1]\n",
    "            true_aspect_unpadded = true_aspect_unpadded[1:-1]\n",
    "            \n",
    "            true_aspect_unpadded = np.where(true_aspect_unpadded==-100, 1, true_aspect_unpadded)\n",
    "\n",
    "            orig_sentence = np.array(tokenizer.convert_ids_to_tokens(ids_unpadded))\n",
    "            decoded_aspect_tags = encoder.inverse_transform(true_aspect_unpadded)\n",
    "            aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "            \n",
    "            print(\"Aspect Acc: {:.2f}%\".format(aspect_acc*100))\n",
    "            print(\"Predicted Aspect:\")\n",
    "            print(encoder.inverse_transform(pred_aspect_unpadded))\n",
    "            print(\"True Aspect:\")\n",
    "            print(decoded_aspect_tags)\n",
    "            print(\"Sentence:\")\n",
    "            print(orig_sentence)   \n",
    "            print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67842c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: model.task1.no_clean.bin\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'AT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['Some' 'problems' 'can' 'be' 'fixed' 'if' 'you' 'purchase' 'new'\n",
      " 'software' ',' 'but' 'there' 'is' 'no' 'g' '##ua' '##rent' '##ee' '.']\n",
      "Aspect Terms: ['software']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'AT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['Some' 'problems' 'can' 'be' 'fixed' 'if' 'you' 'purchase' 'new'\n",
      " 'software' ',' 'but' 'there' 'is' 'no' 'g' '##ua' '##rent' '##ee' '.']\n",
      "Aspect Terms: ['software']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'AT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['Some' 'problems' 'can' 'be' 'fixed' 'if' 'you' 'purchase' 'new'\n",
      " 'software' ',' 'but' 'there' 'is' 'no' 'g' '##ua' '##rent' '##ee' '.']\n",
      "Aspect Terms: ['software']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['The' 'menu' 'choices' 'are' 'similar' 'but' 'the' 'taste' 'lacked'\n",
      " 'more' 'flavor' 'than' 'it' 'looked' '.']\n",
      "Aspect Terms: ['menu' 'choices' 'taste' 'flavor']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'AT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['Really' 'though' ',' 'where' \"'\" 's' 'the' 'season' '##ing' '?']\n",
      "Aspect Terms: ['season']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['The' 'menu' 'choices' 'are' 'similar' 'but' 'the' 'taste' 'lacked'\n",
      " 'more' 'flavor' 'than' 'it' 'looked' '.']\n",
      "Aspect Terms: ['menu' 'choices' 'taste' 'flavor']\n",
      "\n",
      "Aspect Acc: 90.91%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['He' 'takes' 'real' 'pride' 'in' 'his' 'food' 'and' 'his' 'business' '.']\n",
      "Aspect Terms: ['food']\n",
      "\n",
      "Aspect Acc: 90.91%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['The' 'screen' 'almost' 'looked' 'like' 'a' 'bar' '##code' 'when' 'it'\n",
      " 'froze' '.']\n",
      "Aspect Terms: ['screen']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['The' 'menu' 'choices' 'are' 'similar' 'but' 'the' 'taste' 'lacked'\n",
      " 'more' 'flavor' 'than' 'it' 'looked' '.']\n",
      "Aspect Terms: ['menu' 'choices' 'taste' 'flavor']\n",
      "\n",
      "Aspect Acc: 90.91%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['He' 'takes' 'real' 'pride' 'in' 'his' 'food' 'and' 'his' 'business' '.']\n",
      "Aspect Terms: ['food']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_test(test_dataset, test_data_loader, model, num=10, model_path=MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b24aac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Raw Data\n",
      "*** input_ids\n",
      "tensor([  101,  1109,  4382,  1110,  1843,  1105,  1136,  1304,  8394,  1105,\n",
      "         1173,  1128,  1138,  3205,  4204, 10825,  1113,  1128,  4518,  1128,\n",
      "         1107,  1103,  4997,  1609,  1936,   117,  3634,  1111, 18679,   119,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "*** aspect_tags\n",
      "tensor([-100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    0,    0,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])\n",
      "\n",
      "['[CLS]' 'The' 'restaurant' 'is' 'dark' 'and' 'not' 'very' 'attractive'\n",
      " 'and' 'then' 'you' 'have' 'spot' 'lights' 'shining' 'on' 'you' 'putting'\n",
      " 'you' 'in' 'the' 'worst' 'light' 'possible' ',' 'reaching' 'for'\n",
      " 'sunglasses' '.' '[SEP]']\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT'\n",
      " 'NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Aspect Terms: ['spot' 'lights']\n"
     ]
    }
   ],
   "source": [
    "def test_dataset(idx=0):\n",
    "\n",
    "\n",
    "    train_dataset = SentenceTagDataset(tokenizer=tokenizer,\n",
    "                                       sentences=train_sentences,\n",
    "                                       aspect_tags=train_aspect_tags,\n",
    "#                                        polarity_tags=train_polarity_tags,\n",
    "                                       aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "\n",
    "    train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=32), device)    \n",
    "\n",
    "    data = train_dataset[idx]\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = np.logical_not(data['attention_mask'])\n",
    "    aspect_tags = data['aspect_tags']\n",
    "    \n",
    "    print(\"*** Raw Data\")\n",
    "    print(\"*** input_ids\")\n",
    "    print(input_ids)\n",
    "    print(\"*** aspect_tags\")\n",
    "    print(aspect_tags)\n",
    "    print()\n",
    "    \n",
    "    input_ids = np.ma.compressed(np.ma.masked_where(attention_mask, input_ids))\n",
    "    aspect_tags = np.ma.compressed(np.ma.masked_where(attention_mask, aspect_tags))\n",
    "    \n",
    "    aspect_tags = np.where(aspect_tags==-100, 1, aspect_tags)\n",
    "    \n",
    "    orig_sentence = np.array(train_dataset.tokenizer.convert_ids_to_tokens(input_ids))\n",
    "    decoded_aspect_tags = encoder.inverse_transform(aspect_tags)\n",
    "    \n",
    "    aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "    \n",
    "    print(orig_sentence)\n",
    "    print(decoded_aspect_tags)  \n",
    "    \n",
    "    print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "\n",
    "test_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b0500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
