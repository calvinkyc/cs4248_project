{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d01f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8e4e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_EPOCHS = 5\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 8\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b99bf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of aspect tags: 2\n",
      "The aspect term encoded numeric is: 0\n"
     ]
    }
   ],
   "source": [
    "# path = '../data/restaurants_laptop_train_with_pos_task1.csv'\n",
    "# MODEL_PATH = \"model.task1.no_clean.bin\"\n",
    "\n",
    "path = '../data/restaurants_laptop_train_with_pos_task1_cleaned.csv'\n",
    "MODEL_PATH = \"model.task1.cleaned.bin\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df[:200]\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
    "\n",
    "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
    "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
    "\n",
    "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
    "\n",
    "print('The aspect term encoded numeric is: {}'.format(np.where(encoder.classes_ == \"AT\")[0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b5cd4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>aspect_tag</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_1</td>\n",
       "      <td>charge</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_1</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_1</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_1</td>\n",
       "      <td>night</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>s_9</td>\n",
       "      <td>never</td>\n",
       "      <td>ADV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>s_9</td>\n",
       "      <td>know</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>s_9</td>\n",
       "      <td>about</td>\n",
       "      <td>ADP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>s_9</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>s_9</td>\n",
       "      <td>razor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num    text   pos  aspect_tag  polarity\n",
       "0    s_1       I  PRON           1         0\n",
       "1    s_1  charge  VERB           1         0\n",
       "2    s_1      it  PRON           1         0\n",
       "3    s_1      at   ADP           1         0\n",
       "4    s_1   night  NOUN           1         0\n",
       "..   ...     ...   ...         ...       ...\n",
       "195  s_9   never   ADV           1         0\n",
       "196  s_9    know  VERB           1         0\n",
       "197  s_9   about   ADP           1         0\n",
       "198  s_9     the   DET           1         0\n",
       "199  s_9   razor  NOUN           1         0\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7abf5a06",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 49 is out of bounds for axis 0 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22096/2872259458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m49\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tokens: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Labels: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maspect_tags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 49 is out of bounds for axis 0 with size 9"
     ]
    }
   ],
   "source": [
    "idx = 49\n",
    "print(\"Tokens: {}\".format(sentences[idx]))\n",
    "print(\"Labels: {}\".format(aspect_tags[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ab0cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['Great', 'laptop', 'that', 'offers', 'many', 'great', 'features']\n",
      "[1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(10):\n",
    "    for j in range(s,len(sentences)):\n",
    "        if len(sentences[j]) < 12:\n",
    "            print(j)\n",
    "            print(sentences[j])\n",
    "            print(aspect_tags[j])\n",
    "            s = j+1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4af348a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            data[k] = to_device(v, device)\n",
    "        return data\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "739a3984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "\n",
    "NUM_ASPECT_TAGS = len(encoder.classes_)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7b65241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTagDataset(Dataset):\n",
    "    def __init__(self, tokenizer, sentences, aspect_tags, aspect_term_tag, \n",
    "                 max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.aspect_tags = aspect_tags\n",
    "        self.aspect_term_tag = aspect_term_tag\n",
    "        self.max_length = max_length\n",
    "        self.special_token = -100\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]  # Get a sentence\n",
    "        aspect_tags = self.aspect_tags[idx]  # Get the corresponding aspect tags\n",
    "\n",
    "        sentence_encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            is_split_into_words=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        word_ids = sentence_encoding.word_ids(batch_index=0)\n",
    "        aspect_tags_encoding = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                aspect_tags_encoding.append(aspect_tags[word_idx])\n",
    "            else:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "            previous_word_idx = word_idx\n",
    "        aspect_tags_encoding = torch.LongTensor(aspect_tags_encoding)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": sentence_encoding[\"input_ids\"][0],\n",
    "            \"attention_mask\": sentence_encoding[\"attention_mask\"][0],\n",
    "            \"token_type_ids\": sentence_encoding[\"token_type_ids\"][0],\n",
    "            \"aspect_tags\": aspect_tags_encoding,\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad052c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, target, mask, num_labels):\n",
    "    cel = nn.CrossEntropyLoss()\n",
    "    masking = mask.view(-1) == 1\n",
    "    pred = output.view(-1, num_labels)\n",
    "    true = torch.where(masking, target.view(-1), \n",
    "                       torch.tensor(cel.ignore_index).type_as(target))\n",
    "    \n",
    "    loss = cel(pred, true)\n",
    "    return loss\n",
    "\n",
    "class AspectExtractionModel(nn.Module):\n",
    "    def __init__(self, num_aspect_tags, num_vocab):\n",
    "        super(AspectExtractionModel, self).__init__()\n",
    "        self.num_aspect_tags = num_aspect_tags\n",
    "        self.bert_model = transformers.BertModel.from_pretrained(\"bert-base-cased\")        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(768, self.num_aspect_tags)\n",
    "        # if the number of vocab has been increased, then need to add the new vector \n",
    "        # at the end of the embedding matrix\n",
    "        self.bert_model.resize_token_embeddings(num_vocab)\n",
    "                \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, aspect_tags):\n",
    "        out, pool_out = self.bert_model(input_ids, attention_mask = attention_mask, \n",
    "                                 token_type_ids = token_type_ids, return_dict=False)\n",
    "        \n",
    "        tag_out = self.dropout(out)\n",
    "        tag_out = self.fc(tag_out)\n",
    "        \n",
    "        loss_tag = loss_fn(tag_out, aspect_tags, attention_mask, self.num_aspect_tags)\n",
    "        \n",
    "        s = nn.Softmax(dim=2)\n",
    "        \n",
    "        tag_out = s(tag_out)\n",
    "        \n",
    "        return tag_out, loss_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e888395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(pred_tags, true_tags):\n",
    "    if isinstance(pred_tags, list):\n",
    "        pred_tags = torch.cat(pred_tags, 0)\n",
    "        true_tags = torch.cat(true_tags, 0)\n",
    "    pred_tags = pred_tags[true_tags!=-100]\n",
    "    true_tags = true_tags[true_tags!=-100]\n",
    "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
    "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
    "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
    "\n",
    "    return acc, f1, cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "883d3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7,), (2,), (7,), (2,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_sentences, test_sentences, \n",
    " train_aspect_tags, test_aspect_tags) = model_selection.train_test_split(\n",
    "    sentences, aspect_tags, random_state = 42, test_size = TEST_SIZE)\n",
    "\n",
    "train_sentences.shape, test_sentences.shape, train_aspect_tags.shape, test_aspect_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52bef269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'the', 'shop', 'these', 'MacBooks', 'are', 'encased', 'in', 'a', 'soft', 'rubber', 'enclosure', 'so', 'you', 'will', 'never', 'know', 'about', 'the', 'razor']\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(train_sentences[idx])\n",
    "print(train_aspect_tags[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d5b8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=train_sentences, \n",
    "                                   aspect_tags=train_aspect_tags,\n",
    "                                   aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE), device)    \n",
    "\n",
    "test_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=test_sentences, \n",
    "                                  aspect_tags=test_aspect_tags,\n",
    "                                  aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "test_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=TEST_BATCH_SIZE), device)   \n",
    "\n",
    "model = to_device(AspectExtractionModel(num_aspect_tags = NUM_ASPECT_TAGS, \n",
    "                                        num_vocab = len(tokenizer)), device)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfa1753e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:44<00:00,  1.97it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 19.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.18820; Valid Loss: 0.10141\n",
      "Aspect Train acc: 91.89%; Valid acc: 95.95%\n",
      "Aspect Train f1: 91.58%; Valid f1: 95.97%\n",
      "Aspect Train cm:\n",
      " [[36994  1261]\n",
      " [ 2400  4490]]\n",
      "Aspect Valid cm:\n",
      " [[9221  254]\n",
      " [ 204 1622]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:45<00:00,  1.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07602; Valid Loss: 0.09370\n",
      "Aspect Train acc: 97.10%; Valid acc: 96.35%\n",
      "Aspect Train f1: 97.10%; Valid f1: 96.35%\n",
      "Aspect Train cm:\n",
      " [[37591   664]\n",
      " [  646  6244]]\n",
      "Aspect Valid cm:\n",
      " [[9265  210]\n",
      " [ 203 1623]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:46<00:00,  1.89it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.04186; Valid Loss: 0.10571\n",
      "Aspect Train acc: 98.49%; Valid acc: 96.41%\n",
      "Aspect Train f1: 98.49%; Valid f1: 96.45%\n",
      "Aspect Train cm:\n",
      " [[37910   345]\n",
      " [  338  6552]]\n",
      "Aspect Valid cm:\n",
      " [[9218  257]\n",
      " [ 149 1677]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:46<00:00,  1.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02429; Valid Loss: 0.11624\n",
      "Aspect Train acc: 99.16%; Valid acc: 96.68%\n",
      "Aspect Train f1: 99.16%; Valid f1: 96.67%\n",
      "Aspect Train cm:\n",
      " [[38060   195]\n",
      " [  184  6706]]\n",
      "Aspect Valid cm:\n",
      " [[9298  177]\n",
      " [ 198 1628]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:47<00:00,  1.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01779; Valid Loss: 0.11734\n",
      "Aspect Train acc: 99.36%; Valid acc: 96.68%\n",
      "Aspect Train f1: 99.36%; Valid f1: 96.69%\n",
      "Aspect Train cm:\n",
      " [[38096   159]\n",
      " [  132  6758]]\n",
      "Aspect Valid cm:\n",
      " [[9282  193]\n",
      " [ 182 1644]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_train_steps = int(len(train_sentences) / TRAIN_BATCH_SIZE * NUM_EPOCHS)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=num_train_steps)\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": list(),\n",
    "    \"aspact_train_acc\": list(),\n",
    "    \"valid_loss\": list(),\n",
    "    \"aspact_valid_acc\": list(),\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    train_f1 = []\n",
    "    test_f1 = []\n",
    "\n",
    "    model.train()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    for data in tqdm(train_data_loader, total=len(train_data_loader)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_aspect_tags, loss = model(**data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "        \n",
    "    aspect_train_acc, aspect_train_f1, aspect_train_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                                 final_true_aspect_tags)\n",
    "\n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "        pred_aspect_tags, loss = model(**data)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "\n",
    "    aspect_test_acc, aspect_test_f1, aspect_test_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                              final_true_aspect_tags)\n",
    "\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
    "        \n",
    "    print(\"Train Loss: {:.5f}; Valid Loss: {:.5f}\".format(avg_train_loss, avg_test_loss))\n",
    "    print(\"Aspect Train acc: {:.2f}%; Valid acc: {:.2f}%\".format(\n",
    "        aspect_train_acc*100, aspect_test_acc*100))\n",
    "    print(\"Aspect Train f1: {:.2f}%; Valid f1: {:.2f}%\".format(\n",
    "        aspect_train_f1*100, aspect_test_f1*100))\n",
    "    print(\"Aspect Train cm:\\n {}\".format(np.flip(aspect_train_cm)))\n",
    "    print(\"Aspect Valid cm:\\n {}\".format(np.flip(aspect_test_cm)))\n",
    "    print()\n",
    "    \n",
    "    if avg_test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        best_loss = avg_test_loss    \n",
    "        \n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['aspact_train_acc'].append(aspect_train_acc.cpu().numpy())\n",
    "    history['valid_loss'].append(avg_test_loss)\n",
    "    history['aspact_valid_acc'].append(aspect_test_acc.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac026d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyV0lEQVR4nO3deXwV5dn/8c9FSEjCmhBEJGwCCogsGlDBWhVtwY1WtGBrrailWkVtra0/Wx+16lMfu4lLtWhxaalota51qVgsdYWw75VNiaCyL5KQ7fr9MUM4OZyEE8jJyfJ9v1555czc98xcZwj3NTP3zD3m7oiIiERrluwARESkflKCEBGRmJQgREQkJiUIERGJSQlCRERiUoIQEZGYlCCkSTKz18zse7Vdt4YxnGpmBdWUP2xmt9T2dkXiZXoOQhoKM9sVMZkJ7AHKwukfuPvUuo/q4JnZqcBf3D33ENezFrjC3afXQlgiFZonOwCReLl7q72fq2sUzay5u5fWZWwNlfaVVEeXmKTB23upxsx+ZmafAY+ZWZaZvWJmG81sa/g5N2KZt83sivDzpWb2jpn9Jqy7xsxGHWTdHmY208x2mtl0M3vQzP5ygPhvMLMvzGyDmY2PmP+4md0Zfs4Jv8M2M9tiZv8xs2Zm9megK/Cyme0ys5+G9c8zsyVh/bfNrG/EeteG+2oh8KWZ3Whmz0XFdL+Z3XsQ/xzSiChBSGNxOJANdAMmEPxtPxZOdwUKgQeqWf4EYAWQA9wD/MnM7CDq/hWYBbQHbgO+G0fcbYHOwOXAg2aWFaPeDUAB0AHoCNwMuLt/F/gEONfdW7n7PWZ2FPAUcH1Y/1WCBJIWsb6LgLOBdsBfgJFm1g6CswpgLPDnA8QujZwShDQW5cCt7r7H3QvdfbO7P+fuu919J3AX8NVqlv/Y3R9x9zLgCaATQUMcd10z6woMAf7H3Yvd/R3gpQPEXQL80t1L3P1VYBdwdBX1OgHdwrr/8ao7EMcC/3D3N929BPgNkAEMi6hzn7uvC/fVBmAmcGFYNhLY5O5zDhC7NHJKENJYbHT3or0TZpZpZn80s4/NbAdBA9jOzFKqWP6zvR/cfXf4sVUN6x4BbImYB7DuAHFvjuoD2F3Fdn8NrAT+aWarzeymatZ5BPBxRIzlYRydq4nrCeDi8PPF6OxBUIKQxiP6aPoGgiPxE9y9DXBKOL+qy0a1YQOQbWaZEfO61MaK3X2nu9/g7kcC5wI/NrMRe4ujqq8nuLQGQHj5qwvwaeQqo5Z5ARhgZv2Bc4AGdUeYJIYShDRWrQn6HbaZWTZwa6I36O4fA/nAbWaWZmYnETTmh8zMzjGzXmFjv4Pg9t69t/h+DhwZUf0Z4GwzG2FmqQTJcg/wXjWxFwHPEvahuPsntRG3NGxKENJY3Utw3X0T8AHweh1t9zvAScBm4E7gaYLG+VD1BqYT9FG8D/zB3d8Oy34F/CK8Y+kn7r6C4DLR/QTf/1yCTuziA2zjCeBYdHlJQnpQTiSBzOxpYLm7J/wM5lCFnezLgcPdfUey45Hk0xmESC0ysyFm1jN8RmEkMJrg+n69ZmbNgB8D05QcZK+EJQgzmxI+/LO4inIzs/vMbKWZLTSz4yLKRprZirCsurs1ROqbw4G3CS4F3Qdc5e7zkhrRAZhZS4J+jTOpg74aaTgSdonJzE4h+E/ypLv3j1F+FjAROIvgwaNJ7n5CeBvifwn+WAuA2cBF7r40IYGKiEhMCTuDcPeZwJZqqowmSB7u7h8Q3KPeCRgKrHT31WGn2rSwroiI1KFkDtbXmcoP6xSE82LNP6GqlZjZBIKhFWjZsuXxffr0qf1IRUQaqTlz5mxy9w6xypKZIGI9sOTVzI/J3ScDkwHy8vI8Pz+/dqITEWkCzOzjqsqSmSAKqPyUaS7BE6BpVcwXEZE6lMzbXF8CLgnvZjoR2B4OGjYb6B0Om5wGjOPAA56JiEgtS9gZhJk9BZwK5FjwWsVbgVQAd3+YYAjiswgGINsNjA/LSs3sGuANIAWY4u5LEhWniIjElrAE4e4XHaDcgaurKHuVIIGIiEiS6ElqERGJSQlCRERiUoIQEWmg3J09pWXsLCpJyPqTeZuriEij4+6UlDlFpWUUFZdRVFJOYUkZRSVlFb+Dn+j55RVlhcUx5kUsFzld7nBY6xbM+vkZtf5dlCBEpEkoKdvXsO4JG+fC4ioa6IgGfE9EY1wYUadSveIy9pSG6ystp6z84Ma4S09tRkZqCumpKWSkptAiNYWM1Gakp6bQNiOV9LCsUr20FNpkpNby3gooQYhIvVFUUkbB1kK2fFkcdbS9r/ENfsc+Ot9TzVF56UE22i2aNyMjLYX05kFjHDl9WOtU0sMGPLJh3zuv0vy0ZqQ3TyE9Yl2RDX2L5s0IXhhYfyhBiEidKSkrZ8O2ItZt3c26Lbsp2FpY8Xnd1kI27ozv5XstmjersjHOaZVW0YDva4yb7WvgI5bLqDgiT9nv6H1vo92sWf1qtOuSEoSI1JrycueLnXv2NfpbggRQsDX4vGF7IZEH8inNjE5t0+mSlclpR3egS1YmudkZdGiVHjTq0UfharTrlBKEiMTN3dm6uyQ84t+XANZt2c2nWwsp2FZIcWl5pWUOa92CLtmZDOmeRZfszhVJoEtWJp3aptM8RTdT1ldKECJSyc6ikuDST3jZJ7gUFCSDgq27+bK4rFL9rMxUumRn0qdTa87s15Hc7Ey6ZGXQJTuTzu0ySE9NSdI3kUOlBCHSxOztCA4u/RRSEHU2sG135XvqW6al0CU7ky7ZmQzr1Z7crH0JIDcrg9bpibmDRpJPCUKkkSktK2fD9qKKy0DRZwNfRHUEp6U0Izcrg9zsTAbktq1o+LtkBUkhKzO13t1dI3VDCUKkgSkvdzbu2lO5HyDijqAN24sq3YffzKBT2wy6ZGfw1aM6hGcDQQLIzcrksNYt1OkrMSlBiNQzezuCC6I6gdeFl4Oq6wg+vltWeOS/7wzg8LbppKojWA6CEoRIEuzaU7rvqD/iTKAgvCS0a09ppfrtMlPpkhXRERxeEgrOAtQRLImhBCGSQJ/vKOK9VZtY/tlOCiLOBrZGdQRnpqVUHPmfeGT74DJQVkbQIZytjmBJDiUIkVq0o6iED1dv4d2Vm3h35SY++mIXEHQEd87KIDcrg/7Hdqp0GSg3K4PslmnqCJZ6RwlC5BDsKS1j3ifbKhLCgoLtlJU76anNGNqjPRfm5TKsZw59O7UhRR3B0sAoQYjUQHm5s+yzHWFC2MysNVsoLCmjmcHALu344ak9Gd4rh8Fd29GiufoFpGFTghA5gHVbdvNOeIbw3qrNbPmyGIBeh7Vi7JAuDO+VwwlHZtNG/QTSyCQ0QZjZSGASkAI86u53R5VnAVOAnkARcJm7Lw7LfgRcATiwCBjv7kWJjFcEYMuXxby3alPFWcInW3YD0LFNC049ugMn98phWM8cDm+bnuRIRRIrYQnCzFKAB4EzgQJgtpm95O5LI6rdDMx392+aWZ+w/ggz6wxcC/Rz90IzewYYBzyeqHil6SosLmPW2n0dy0vW7wCgdYvmnNizPZef3IPhvdrTs0MrdSRLk5LIM4ihwEp3Xw1gZtOA0UBkgugH/ArA3ZebWXcz6xgRW4aZlQCZwPoExipNSGlZOQs/3c67H23i3VWbmPvxNorLyklLacZx3drxk68dxfBeORzbua1GGpUmLZEJojOwLmK6ADghqs4C4HzgHTMbCnQDct19jpn9BvgEKAT+6e7/jLURM5sATADo2rVr7X4DaRTcnVUbd/HOR5t4d9VmPli1mZ3hg2jHHNGG8cO7M6xXDkO6Z5GZpm45kb0S+b8h1rl49Dv/7gYmmdl8gn6GeUBp2DcxGugBbAP+ZmYXu/tf9luh+2RgMkBeXt7BvVNQGp3PthcFl4zCvoTPdwQD1HXNzuScgUdwcq8cTurZnuyWaUmOVKT+SmSCKAC6REznEnWZyN13AOMBLLi4uyb8+Tqwxt03hmV/B4YB+yUIEQgeUPtg1WbeW7WZd1ZuYmX4gFp2yzSG9WzPyb1yGN4rhy7ZmUmOVKThSGSCmA30NrMewKcEnczfjqxgZu2A3e5eTHDH0kx332FmnwAnmlkmwSWmEUB+AmOVBmZPaRlzP95WcZawYN02yh0yUlMY2iObsXldGNarPX0Pb6ORSkUOUsIShLuXmtk1wBsEt7lOcfclZnZlWP4w0Bd40szKCDqvLw/LPjSzZ4G5QCnBpafJiYpV6r/ycmfphvABtVWbmbVmM0Ul5aQ0MwbmtuWa03oxTA+oidQqc288l+3z8vI8P18nGo3FJ5vDB9RWbeK9lZsqBrjrfVgrhvfK4eTwATUNZCdy8MxsjrvnxSrTLRtSb2zetYf3Vm3mvVWbeGflJtZtKQTg8DbpnN6nIyf3bs+wnjl0bKMH1ETqghKEJM3u4lJmrdkSdCx/tImlG8IH1NKbc9KR7fn+V45kWM8cenZoqQfURJJACULqTGlZOQsKtlc8sTz3k62UlDlpKc04vlsWN379aIb1bK8H1ETqCSUISRh3Z+UXu8KB7jbz4ergATWz4AG1y07uwfCeOQzpnk1GmjqWReobJQipVRu2F/Luys28tzLoR/hiZ/CAWrf2mZw76AiG99QDaiINhRKEHJLthSV8sHpfQli18UsA2rdMY1ivHE7uFXQs6wE1kYZHCUJqbOn6Hby6aAPvrNzEwoJ9D6idcGQ2Fw3tyrCeOfQ5vLUeUBNp4JQgpEb+tfxzrvzzXMrcGdSlHdec3pvhPdszuGsWac3VsSzSmChBSNymL/2cq6bOoc/hbXh8/BDat2qR7JBEJIGUICQuby79nB9OnUPfTm3482Un0DZTTy+LNHa6JiAH9MaSz/jh1Dn069SGP1+u5CDSVOgMQqr1+uLPuOavc+nfuS1PXj6UNhr3SKTJUIKQKr22aAMTn5rHsblteeIyJQdJgPJyKN4V/OzZCXt2wZ4dUFaS7MgalpRU6Hlara9WCUJi+sfCDVw7bR4Dw+SgEVOlQnlZ0JhHNurFOyMa+J3h9K6IemHDX2mZ8EcOXcvD4MaPan21ShCyn1cWrue6afMZ3KUdj182lFYt9GfS4JWVRDXWOys36hUNd1TDH6uxL9kd3zZT0iCtFbRove8nMweyugef01pDi7A8sl5aK2jegthvLZaYUhLzf1T/86WSlxas50dPz+f4rllMGT9EySGZSovDxnpH1NF4dEMefTQfY5nSovi22Tw9orFuFTTirQ6H9lU05C1aQYs2+y/TYm8jLw2Z/vdLhRfnf8qPnp5PXvdsHrt0CC0be3JwDy6XeFnU7/JDmF8a8bl8X53SoiqO4Ktp+MuK4/seqZkRjXV4ZN4mN2ysoxv01pXrRR/Bp+hSouzTyFsAidcL8z7lx8/MZ2iPbKZcOoTMtPBPo6wUCrfC7s1QuCX4vXtL0ODt11iWx2g8azo/VmNbkwa7BtsiiW9TTG0Z1Vi3gnZdo47M9zbirSMa+zaVl0lrlbDLCyL6y2pKSvcEjXtkQ1+4hSUr17B58Uc83q6Y4RnNSHliy756RdsPbluWAs1Son43izG/WZz1UoKGcO90s+bV1417W7U1/wBxpGbsO0pPaxmUi9RzShANVfHuyg397s3hkf6W/Y/2C8MGv4o7Ro4Beqamk5bWgWa7syGzPWT1CH5nZkNGdvA7MyzLyA4ua1TXKIpIg5fQBGFmI4FJQArwqLvfHVWeBUwBegJFwGXuvjgsawc8CvQnuBZwmbu/n8h4k8I9aLgrGvqIBj26oY8sKy2sep0t2kJmVtCYt+wAHfrsa+Az9jX0/1xTzC1vfkbfI7vx0PeG0Uwv7RGRCAlLEGaWAjwInAkUALPN7CV3XxpR7WZgvrt/08z6hPVHhGWTgNfd/QIzSwPq/wsFysthz/aaNfS7N0N5VQ8FGWS023fU3jYXOg3Yr6EPPu892s+Kq6Pxmdnr+NmbCzm5V28eviSP9FQlBxGpLJFnEEOBle6+GsDMpgGjgcgE0Q/4FYC7Lzez7mbWESgETgEuDcuKgThv6agl5WVQuK2KyzXRDf3esq1BB2gslhLRsLeH7CMhNy+qcY/4nNke0tsm5Fr1tFmfcNPfF3HKUR2Y/N3jlRxEJKZEJojOwLqI6QLghKg6C4DzgXfMbCjQDcgFyoCNwGNmNhCYA1zn7l9Gb8TMJgATALp27VrzKN3hxWtg96bKSaBwG1Xe5ZKSVrkxP6xvNQ19OJ3eFiz5D/789cNPuPn5RXz1qA78UclBRKqRyAQRqzWMbnHvBiaZ2XxgETAPKAVSgeOAie7+oZlNAm4Cbtlvhe6TgckAeXl5Nb9v0QzWzw2O1DPbQ9suMRr6rMqXctJa1ovGvqamfvgxP39+Macd3YGHLlZyEJHqJTJBFABdIqZzgfWRFdx9BzAewMwMWBP+ZAIF7v5hWPVZggSRGD9sfH3f0f78wcfc8sJiTu9zGA9dfBwtmis5iEj1Enk/4mygt5n1CDuZxwEvRVYws3ZhGcAVwEx33+HunwHrzOzosGwElfsupAaefH8tt7ywmDP6KjmISPwSdgbh7qVmdg3wBsFtrlPcfYmZXRmWPwz0BZ40szKCBHB5xComAlPDBLKa8ExDaubxd9dw28tLObNfRx789nF6b7SIxM3ckzjcQC3Ly8vz/Pz8ZIdRb0x5Zw2/fGUpX+vXkQeUHEQkBjOb4+55scr0JHUj9eh/VnPnP5Yx8pjDuf/bg0lNUXIQkZpRq9EI7U0Oo/orOYjIwdMZRCMzeeYq/vfV5Zx9bCfuHTdIyUFEDpoSRCPy8L9XcfdryzlnQCfuHTuI5koOInIIlCAaiT+8vZJ7Xl/BuQOP4PffGqjkICKHTAmiEXhwxkp+/cYKRg86gt9eqOQgIrVDCaKBu/+tj/jtm//lm4M785sLB5LSrOENASIi9ZMSRAM2afpH/H76fzl/cGd+reQgIrVMCaIBcnfunf4Rk976iDHH5XLPBQOUHESk1ilBNDDuzu/f/C/3/WslFx6fy91jlBxEJDGUIBoQd+e3//wvD8xYydi8Lvzq/GNppuQgIgmiBNFAuDu/fmMFf3h7FeOGdOF/v6nkICKJpQTRALg7//f6Ch7+9youGtqVu77RX8lBRBJOCaKec3fufm05f5y5mu+c0JU7Ris5iEjdUIKox9yd/311GY/8Zw3fPbEbvxx9DNYAX3UqIg2TEkQ95e7c+Y9l/OmdNXzvpG7cdp6Sg4jULSWIesjd+eUrS3ns3bVcOqw7t57bT8lBROqcEkQ94+7c/vJSHn9vLeOHd+d/zlFyEJHkUIKoR9ydW19awpPvf8zlJ/fgF2f3VXIQkaRRgqgnysud/3lpMX/54BMmnHIk/29UHyUHEUmqhI4LbWYjzWyFma00s5tilGeZ2fNmttDMZplZ/6jyFDObZ2avJDLOZCsvd255MUgOP/iqkoOI1A8JSxBmlgI8CIwC+gEXmVm/qGo3A/PdfQBwCTApqvw6YFmiYqwPysudn7+wmKkffsJVp/bkppFKDiJSPyTyDGIosNLdV7t7MTANGB1Vpx/wFoC7Lwe6m1lHADPLBc4GHk1gjElVXu7c/Pwinpr1CVef1pOffv1oJQcRqTcSmSA6A+sipgvCeZEWAOcDmNlQoBuQG5bdC/wUKK9uI2Y2wczyzSx/48aNtRB23Sgvd276+0KmzV7HxNN78ZOvKTmISP2SyAQRq7XzqOm7gSwzmw9MBOYBpWZ2DvCFu8850EbcfbK757l7XocOHQ415jpRVu789LmFPJNfwLUjevPjM49SchCReueAdzGFjfWr7l7tkXwMBUCXiOlcYH1kBXffAYwPt2PAmvBnHHCemZ0FpANtzOwv7n5xDWOod8rKnZ8+u5Dn5hZw/Rm9uf6Mo5IdkohITPGcQYwDPjKze8ysbw3WPRvobWY9zCwtXM9LkRXMrF1YBnAFMNPdd7j7/3P3XHfvHi73r8aSHG782wKem1vAj844SslBROq1A55BuPvFZtYGuAh4zMwceAx4yt13VrNcqZldA7wBpABT3H2JmV0Zlj8M9AWeNLMyYClw+SF/o3qqrNy54Zn5vDB/PTeceRQTR/ROdkgiItUy9+hugSoqmuUAFwPXE9x62gu4z93vT1h0NZSXl+f5+fnJDmM/pWXl3PC3Bbw4fz03fv1orj6tV7JDEhEBwMzmuHterLIDXmIys3PN7HngX0AqMNTdRwEDgZ/UaqSNUGlZOT96JkgOPx2p5CAiDUc8Q21cCPze3WdGznT33WZ2WWLCahxKy8q57un5/GPhBm4a1Ycrv9oz2SGJiMQtngRxK7Bh74SZZQAd3X2tu7+VsMgauJKycq6fNp9/LNrAzWf1YcIpSg4i0rDEcxfT36j8sFpZOE+qUFJWzrVPzeMfizbwi7P7KjmISIMUzxlE83CoDADcvTji1lSJUlxazsSn5vLGks+55Zx+XH5yj2SHJCJyUOI5g9hoZuftnTCz0cCmxIXUcBWXlnPNX4PkcOu5Sg4i0rDFcwZxJTDVzB4gGD5jHcHIqxKhuLScH06dy/Rln3P7ecfwvWHdkx2SiMghiedBuVXAiWbWiuC5iSofjmuq9pSWcfXUuUxf9gW/HH0Ml5zUPdkhiYgcsrjeKGdmZwPHAOl7B5Vz918mMK4GY09pGVf9ZS7/Wv4Fd3yjP989sVuyQxIRqRXxDNb3MJAJnEbwboYLgFkJjqtBKCop46q/zGHGio3c9c3+fOcEJQcRaTzi6aQe5u6XAFvd/XbgJCqP0tokFZWU8YM/B8nhV+cfq+QgIo1OPAmiKPy928yOAEqAJn17TlFJGd9/Mp+ZH23k/8Ycy0VDuyY7JBGRWhdPH8TLZtYO+DUwl+ClP48kMqj6bG9yeGflJv7v/AF8a0iTP5kSkUaq2gRhZs2At9x9G/Ccmb0CpLv79roIrr4pLA6Sw7urNnHPmAFcmKfkICKNV7WXmMK3yP02YnpPU04Olz8xm3dXbeI3FwxUchCRRi+ePoh/mtkYa8IvTd5dXMplj8/mg9Wb+d23BjLm+NxkhyQiknDx9EH8GGgJlJpZEcHT1O7ubRIaWT2xu7iU8Y/NZvbaLfzuW4P4xuDOyQ5JRKROxPMkdeu6CKQ++nJPkBzyP97C78cOYvQgJQcRaTrieVDulFjzo18g1Njs2lPK+MdmMfeTbUwaN5hzBx6R7JBEROpUPJeYboz4nA4MBeYApyckonpgZ1EJlz42m/nrtjFp3CDOGaDkICJNzwE7qd393IifM4H+wOfxrNzMRprZCjNbaWY3xSjPMrPnzWyhmc0ys/7h/C5mNsPMlpnZEjO7rqZf7GDtLCrhe1NmMX/dNu6/aLCSg4g0WfHcxRStgCBJVMvMUoAHgVFAP+AiM+sXVe1mYL67DyAYQnxSOL8UuMHd+wInAlfHWLbW7Sgq4ZIps1hYsJ0HLhrMWcd2SvQmRUTqrXj6IO4neHoagoQyCFgQx7qHAivdfXW4nmnAaGBpRJ1+wK8A3H25mXU3s47uvoHwPdjuvtPMlgGdo5atVdsLg+Sw5NPtPPDt4xjZ//BEbUpEpEGIpw8iP+JzKfCUu78bx3KdCV4utFcBcEJUnQXA+cA7ZjYU6AbkEnEJy8y6A4OBD2NtxMwmABMAunY9uDGRtheWcMmfPmTphh384TvH8bVjlBxEROJJEM8CRe5eBsGlIzPLdPfdB1gu1oN1HjV9NzDJzOYDi4B5BEmIcFutgOeA6919R6yNuPtkYDJAXl5e9PoPaEdRCd/904cs27CDh75zPGf061jTVYiINErxJIi3gDOAXeF0BvBPYNgBliug8rDgucD6yAphoz8eIHxSe034g5mlEiSHqe7+9zjiPCgZqSkcmdOS60b0ZkRfJQcRkb3iSRDp7r43OeDuu8wsM47lZgO9zawH8CkwDvh2ZIVwlNjd7l4MXAHMdPcdYbL4E7DM3X8X31c5OKkpzbh33OBEbkJEpEGK5y6mL83suL0TZnY8UHighdy9FLgGeANYBjzj7kvM7EozuzKs1hdYYmbLCe522ns763Dgu8DpZjY//Dkr7m8lIiKHLJ4ziOuBv5nZ3stDnYCx8azc3V8FXo2a93DE5/eB3jGWe4fYfRgiIlJH4hmLabaZ9QGOJmi0l7t7ScIjExGRpDrgJSYzuxpo6e6L3X0R0MrMfpj40EREJJni6YP4fvhGOQDcfSvw/YRFJCIi9UI8CaJZ5MuCwiE00hIXkoiI1AfxdFK/ATxjZg8TPOh2JfBaQqMSEZGkiydB/IxgKIurCDqp5xHcySQiIo1YPMN9lwMfAKuBPGAEwXMNIiLSiFV5BmFmRxE8/XwRsBl4GsDdT6ub0EREJJmqu8S0HPgPcK67rwQwsx/VSVQiIpJ01V1iGgN8Bswws0fMbAR6ullEpMmoMkG4+/PuPhboA7wN/AjoaGYPmdnX6ig+ERFJkng6qb9096nufg7BkN3zgf3eLy0iIo1Ljd5J7e5b3P2P7n56ogISEZH6oUYJQkREmg4lCBERiUkJQkREYlKCEBGRmJQgREQkJiUIERGJSQlCRERiSmiCMLORZrbCzFaa2X4P15lZlpk9b2YLzWyWmfWPd1kREUmshCWI8M1zDwKjgH7ARWbWL6razcB8dx8AXAJMqsGyIiKSQIk8gxgKrHT31e5eDEwDRkfV6Qe8BeDuy4HuZtYxzmVFRCSBEpkgOgPrIqYLwnmRFgDnA5jZUKAbwXhP8SxLuNwEM8s3s/yNGzfWUugiIpLIBBFraHCPmr4byDKz+cBEgteZlsa5bDDTfbK757l7XocOHQ4hXBERiRTPO6kPVgHQJWI6F1gfWcHddwDjAczMgDXhT+aBlhURkcRK5BnEbKC3mfUwszSC15e+FFnBzNqFZQBXADPDpHHAZUVEJLESdgbh7qVmdg3wBpACTHH3JWZ2ZVj+MNAXeNLMyoClwOXVLZuoWEVEZH/mHvPSfoOUl5fn+fn5yQ5DRKTBMLM57p4Xq0xPUouISExKECIiEpMShIiIxKQEISIiMSlBiIhITEoQIiISkxKEiIjEpAQhIiIxKUGIiEhMShAiIhKTEoSIiMSkBCEiIjEpQYiISExKECIiEpMShIiIxKQEISIiMSlBiIhITEoQIiISkxKEiIjEpAQhIiIxJTRBmNlIM1thZivN7KYY5W3N7GUzW2BmS8xsfETZj8J5i83sKTNLT2SsIiJSWcIShJmlAA8Co4B+wEVm1i+q2tXAUncfCJwK/NbM0sysM3AtkOfu/YEUYFyiYhURkf0l8gxiKLDS3Ve7ezEwDRgdVceB1mZmQCtgC1AaljUHMsysOZAJrE9grCIiEiWRCaIzsC5iuiCcF+kBoC9B478IuM7dy939U+A3wCfABmC7u/8z1kbMbIKZ5ZtZ/saNG2v7O4iINFmJTBAWY55HTX8dmA8cAQwCHjCzNmaWRXC20SMsa2lmF8faiLtPdvc8d8/r0KFDbcUuItLkJTJBFABdIqZz2f8y0Xjg7x5YCawB+gBnAGvcfaO7lwB/B4YlMFYREYmSyAQxG+htZj3MLI2gk/mlqDqfACMAzKwjcDSwOpx/opllhv0TI4BlCYxVRESiNE/Uit291MyuAd4guAtpirsvMbMrw/KHgTuAx81sEcElqZ+5+yZgk5k9C8wl6LSeB0xOVKwiIrI/c4/uFmi48vLyPD8/P9lhiIg0GGY2x93zYpUl7AyivigpKaGgoICioqJkhyL1QHp6Orm5uaSmpiY7FJF6r9EniIKCAlq3bk337t0JujOkqXJ3Nm/eTEFBAT169Eh2OCL1XqMfi6moqIj27dsrOQhmRvv27XU2KRKnRp8gACUHqaC/BZH4NYkEISIiNacEkWDbtm3jD3/4w0Ete9ZZZ7Ft27baDUhEJE5KEAlWXYIoKyurdtlXX32Vdu3aJSCqQ+PulJeXJzsMEUmwRn8XU6TbX17C0vU7anWd/Y5ow63nHlNl+U033cSqVasYNGgQZ555JmeffTa33347nTp1Yv78+SxdupRvfOMbrFu3jqKiIq677jomTJgAQPfu3cnPz2fXrl2MGjWKk08+mffee4/OnTvz4osvkpGRUWlbL7/8MnfeeSfFxcW0b9+eqVOn0rFjR3bt2sXEiRPJz8/HzLj11lsZM2YMr7/+OjfffDNlZWXk5OTw1ltvcdttt9GqVSt+8pOfANC/f39eeeUVAEaNGsVpp53G+++/zwsvvMDdd9/N7NmzKSws5IILLuD2228HYPbs2Vx33XV8+eWXtGjRgrfeeouzzjqL+++/n0GDBgEwfPhwHnroIQYMGFCr/x4iUnuaVIJIhrvvvpvFixczf/58AN5++21mzZrF4sWLK261nDJlCtnZ2RQWFjJkyBDGjBlD+/btK63no48+4qmnnuKRRx7hW9/6Fs899xwXX1x5/MKTTz6ZDz74ADPj0Ucf5Z577uG3v/0td9xxB23btmXRokUAbN26lY0bN/L973+fmTNn0qNHD7Zs2XLA77JixQoee+yxijOiu+66i+zsbMrKyhgxYgQLFy6kT58+jB07lqeffpohQ4awY8cOMjIyuOKKK3j88ce59957+e9//8uePXuUHETquSaVIKo70q9LQ4cOrXQf/n333cfzzz8PwLp16/joo4/2SxA9evSoOPo+/vjjWbt27X7rLSgoYOzYsWzYsIHi4uKKbUyfPp1p06ZV1MvKyuLll1/mlFNOqaiTnZ19wLi7devGiSeeWDH9zDPPMHnyZEpLS9mwYQNLly7FzOjUqRNDhgwBoE2bNgBceOGF3HHHHfz6179mypQpXHrppQfcnogkl/ogkqBly5YVn99++22mT5/O+++/z4IFCxg8eHDM+/RbtGhR8TklJYXS0tL96kycOJFrrrmGRYsW8cc//rFiPe6+3+2dseYBNG/evFL/QmQskXGvWbOG3/zmN7z11lssXLiQs88+m6KioirXm5mZyZlnnsmLL77IM888w7e//e2Y+0ZE6g8liARr3bo1O3furLJ8+/btZGVlkZmZyfLly/nggw8Oelvbt2+nc+fgnUxPPPFExfyvfe1rPPDAAxXTW7du5aSTTuLf//43a9asAai4xNS9e3fmzp0LwNy5cyvKo+3YsYOWLVvStm1bPv/8c1577TUA+vTpw/r165k9ezYAO3furEhmV1xxBddeey1DhgyJ64xFRJJLCSLB2rdvz/Dhw+nfvz833njjfuUjR46ktLSUAQMGcMstt1S6hFNTt912GxdeeCFf+cpXyMnJqZj/i1/8gq1bt9K/f38GDhzIjBkz6NChA5MnT+b8889n4MCBjB07FoAxY8awZcsWBg0axEMPPcRRRx0Vc1sDBw5k8ODBHHPMMVx22WUMHz4cgLS0NJ5++mkmTpzIwIEDOfPMMyvOQo4//njatGnD+PHjD/o7ikjdafSjuS5btoy+ffsmKSKJtH79ek499VSWL19Os2bJOzbR34TIPtWN5qozCKkTTz75JCeccAJ33XVXUpODiMSvSd3FJMlzySWXcMkllyQ7DBGpAR3KiYhITEoQIiISkxKEiIjEpAQhIiIxJTRBmNlIM1thZivN7KYY5W3N7GUzW2BmS8xsfERZOzN71syWm9kyMzspkbHWJ61atQKC20IvuOCCmHVOPfVUom/pjXbvvfeye/fuimkNHy4iNZGwBGFmKcCDwCigH3CRmfWLqnY1sNTdBwKnAr81s7SwbBLwurv3AQYCyxIVa311xBFH8Oyzzx708tEJor4OH14VDSsuklyJvM11KLDS3VcDmNk0YDSwNKKOA60tGLynFbAFKDWzNsApwKUA7l4MFB9yRK/dBJ8tOuTVVHL4sTDq7iqLf/azn9GtWzd++MMfAsHTzq1bt+YHP/gBo0ePZuvWrZSUlHDnnXcyevToSsuuXbuWc845h8WLF1NYWMj48eNZunQpffv2pbCwsKLeVVddtd+w2/fddx/r16/ntNNOIycnhxkzZlQMH56Tk8Pvfvc7pkyZAgRDYFx//fWsXbtWw4qLSIVEXmLqDKyLmC4I50V6AOgLrAcWAde5ezlwJLAReMzM5pnZo2bWkhjMbIKZ5ZtZ/saNG2v9SxyqcePG8fTTT1dMP/PMM1x44YWkp6fz/PPPM3fuXGbMmMENN9xAdU+1P/TQQ2RmZrJw4UJ+/vOfM2fOnIqyu+66i/z8fBYuXMi///1vFi5cyLXXXssRRxzBjBkzmDFjRqV1zZkzh8cee4wPP/yQDz74gEceeYR58+YBwbDiV199NUuWLKFdu3Y899xz+8Wyd1jxefPmMW7cOO655x6ASsOKL1y4kNNPP71iWPHnnnuOBQsW8Le//e2A+2zFihVccsklzJs3j27dusX8fsXFxYwdO5ZJkyaxYMECpk+fXmlYcUDDioscokSeQcR6O3x0C/h1YD5wOtATeNPM/hPGdRww0d0/NLNJwE3ALfut0H0yMBmCoTaqjaiaI/1EGTx4MF988QXr169n48aNZGVl0bVrV0pKSrj55puZOXMmzZo149NPP+Xzzz/n8MMPj7memTNncu211wIwYMCASo1erGG3q2sU33nnHb75zW9WjM56/vnn85///IfzzjtPw4qLSIVEJogCoEvEdC7BmUKk8cDdHhw6rzSzNUAf4BOgwN0/DOs9S5AgGqQLLriAZ599ls8++4xx48YBMHXqVDZu3MicOXNITU2le/fuMYf5jhRrGO29w27Pnj2brKwsLr300gOup7ozlehhxSMvZe01ceJEfvzjH3Peeefx9ttvc9ttt1WsN1HDikd/v3iHFT9QR76IVC2Rl5hmA73NrEfY8TwOeCmqzifACAAz6wgcDax298+AdWZ2dFhvBJX7LhqUcePGMW3aNJ599tmKu5K2b9/OYYcdRmpqKjNmzODjjz+udh2nnHIKU6dOBWDx4sUsXLgQqHrYbah6qPFTTjmFF154gd27d/Pll1/y/PPP85WvfCXu76NhxUWahoSdQbh7qZldA7wBpABT3H2JmV0Zlj8M3AE8bmaLCC5J/czdN4WrmAhMDZPLaoKzjQbpmGOOYefOnXTu3JlOnToB8J3vfIdzzz2XvLw8Bg0aRJ8+fapdx1VXXcX48eMZMGAAgwYNYujQoUDlYbePPPLIimG3ASZMmMCoUaPo1KlTpX6I4447jksvvbRiHVdccQWDBw+OeTkplr3Dinfu3JkTTzyxonH/xS9+wdVXX03//v1JSUnh1ltv5fzzz68YVry8vJzDDjuMN998kzFjxvDkk08yaNAghgwZEtew4pHfL3JY8cLCQjIyMpg+fTqtWrXSsOIitUTDfUujc6BhxfU3IbKPhvuWJkPDiovUHg33LY2KhhUXqT1N4hCrMV1Gk0OjvwWR+DX6BJGens7mzZvVMAjuzubNm0lPT092KCINQqO/xJSbm0tBQQH18SlrqXvp6enk5uYmOwyRBqHRJ4jU1NSKp3hFRCR+jf4Sk4iIHBwlCBERiUkJQkREYmpUT1Kb2Uag+kGNqpYDbDpgrbqnuGpGcdWM4qqZxhhXN3fvEKugUSWIQ2Fm+VU9bp5MiqtmFFfNKK6aaWpx6RKTiIjEpAQhIiIxKUHsMznZAVRBcdWM4qoZxVUzTSou9UGIiEhMOoMQEZGYlCBERCSmJpUgzGykma0ws5VmdlOMcjOz+8LyhWZ2XD2J61Qz225m88Of/6mjuKaY2RdmtriK8mTtrwPFlaz91cXMZpjZMjNbYmbXxahT5/sszrjqfJ+ZWbqZzTKzBWFct8eok4z9FU9cSfkbC7edYmbzzOyVGGW1u7/cvUn8ELwXexVwJJAGLAD6RdU5C3iN4P3YJwIf1pO4TgVeScI+OwU4DlhcRXmd768440rW/uoEHBd+bg38t578jcUTV53vs3AftAo/pwIfAifWg/0VT1xJ+RsLt/1j4K+xtl/b+6spnUEMBVa6+2p3LwamAaOj6owGnvTAB0A7M+tUD+JKCnefCWyppkoy9lc8cSWFu29w97nh553AMqBzVLU632dxxlXnwn2wK5xMDX+i75pJxv6KJ66kMLNc4Gzg0Sqq1Or+akoJojOwLmK6gP3/k8RTJxlxAZwUnvK+ZmbHJDimeCVjf8UrqfvLzLoDgwmOPiMldZ9VExckYZ+Fl0vmA18Ab7p7vdhfccQFyfkbuxf4KVBeRXmt7q+mlCAsxrzoo4J46tS2eLY5l2C8lIHA/cALCY4pXsnYX/FI6v4ys1bAc8D17r4jujjGInWyzw4QV1L2mbuXufsgIBcYamb9o6okZX/FEVed7y8zOwf4wt3nVFctxryD3l9NKUEUAF0ipnOB9QdRp87jcvcde0953f1VINXMchIcVzySsb8OKJn7y8xSCRrhqe7+9xhVkrLPDhRXsv/G3H0b8DYwMqooqX9jVcWVpP01HDjPzNYSXIo+3cz+ElWnVvdXU0oQs4HeZtbDzNKAccBLUXVeAi4J7wQ4Edju7huSHZeZHW5mFn4eSvDvtjnBccUjGfvrgJK1v8Jt/glY5u6/q6Jane+zeOJKxj4zsw5m1i78nAGcASyPqpaM/XXAuJKxv9z9/7l7rrt3J2gn/uXuF0dVq9X91ehfObqXu5ea2TXAGwR3Dk1x9yVmdmVY/jDwKsFdACuB3cD4ehLXBcBVZlYKFALjPLxlIZHM7CmCuzVyzKwAuJWgwy5p+yvOuJKyvwiO8L4LLAqvXwPcDHSNiC0Z+yyeuJKxzzoBT5hZCkED+4y7v5Ls/5NxxpWsv7H9JHJ/aagNERGJqSldYhIRkRpQghARkZiUIEREJCYlCBERiUkJQkREYlKCEKkBMyuzfSN4zrcYo+8ewrq7WxUj1IokQ5N5DkKklhSGQzCINHo6gxCpBWa21sz+z4L3CMwys17h/G5m9pYFY/O/ZWZdw/kdzez5cLC3BWY2LFxVipk9YsF7CP4ZPskrkhRKECI1kxF1iWlsRNkOdx8KPEAw6ibh5yfdfQAwFbgvnH8f8O9wsLfjgCXh/N7Ag+5+DLANGJPQbyNSDT1JLVIDZrbL3VvFmL8WON3dV4cD433m7u3NbBPQyd1Lwvkb3D3HzDYCue6+J2Id3QmGlu4dTv8MSHX3O+vgq4nsR2cQIrXHq/hcVZ1Y9kR8LkP9hJJEShAitWdsxO/3w8/vEYy8CfAd4J3w81vAVVDxcpo2dRWkSLx0dCJSMxkRI6ICvO7ue291bWFmHxIceF0UzrsWmGJmNwIb2Te65nXAZDO7nOBM4Sog6UOli0RSH4RILQj7IPLcfVOyYxGpLbrEJCIiMekMQkREYtIZhIiIxKQEISIiMSlBiIhITEoQIiISkxKEiIjE9P8BODE6Mjylyi8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['aspact_train_acc'], label='train accuracy')\n",
    "plt.plot(history['aspact_valid_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea406efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: model.task1.cleaned.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AT       0.89      0.89      0.89      1826\n",
      "         NAT       0.98      0.98      0.98      9475\n",
      "\n",
      "    accuracy                           0.96     11301\n",
      "   macro avg       0.93      0.93      0.93     11301\n",
      "weighted avg       0.96      0.96      0.96     11301\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_classification_report(test_data_loader, model, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)   \n",
    "    \n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "            pred_aspect_tags, loss = model(**data)\n",
    "            \n",
    "            final_pred_aspect_tags.extend(torch.argmax(pred_aspect_tags, dim=2))\n",
    "            final_true_aspect_tags.extend(data['aspect_tags'])\n",
    "            \n",
    "    final_pred_aspect_tags = torch.stack(final_pred_aspect_tags).cpu()\n",
    "    final_true_aspect_tags = torch.stack(final_true_aspect_tags).cpu()\n",
    "    \n",
    "    # Remove the special -100 tokens \n",
    "    final_pred_aspect_tags = final_pred_aspect_tags[final_true_aspect_tags!=-100]\n",
    "    final_true_aspect_tags = final_true_aspect_tags[final_true_aspect_tags!=-100]\n",
    "        \n",
    "    print(classification_report(final_true_aspect_tags, final_pred_aspect_tags, \n",
    "                                target_names=encoder.classes_))\n",
    "    \n",
    "get_classification_report(test_data_loader, model, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a71c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(test_dataset, test_data_loader, model, num=5, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num):\n",
    "            \n",
    "            data = next(iter(test_data_loader))\n",
    "            \n",
    "            pred_aspect_tags, _ = model(**data)\n",
    "            \n",
    "            \n",
    "            input_ids = data['input_ids']\n",
    "            pred_aspect_tags = torch.argmax(pred_aspect_tags, dim=2)\n",
    "            true_aspect_tags = data['aspect_tags']\n",
    "            mask = data['attention_mask']\n",
    "            \n",
    "            # Randomly pick a test data from this batch\n",
    "            #\n",
    "            rng = np.random.default_rng()\n",
    "            idx = rng.integers(low=0, high=pred_aspect_tags.shape[0],size=1)[0]\n",
    "\n",
    "            ids_array = input_ids[idx].cpu().numpy()\n",
    "            pred_aspect_array = pred_aspect_tags[idx].cpu().numpy()\n",
    "            true_aspect_array = true_aspect_tags[idx].cpu().numpy()\n",
    "            mask_array = mask[idx].cpu().numpy()\n",
    "\n",
    "            # Remove the padding as we do not want to print them\n",
    "            #\n",
    "            mask_array = np.logical_not(mask_array)\n",
    "\n",
    "            # Only print the unpadded portion\n",
    "            ids_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, ids_array))\n",
    "            pred_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       pred_aspect_array))\n",
    "            true_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       true_aspect_array))\n",
    "            \n",
    "            aspect_pred = pred_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            aspect_true = true_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            \n",
    "            aspect_acc = np.sum(aspect_pred == aspect_true) / len(aspect_pred)\n",
    "            \n",
    "            # Remove begin and end\n",
    "            ids_unpadded = ids_unpadded[1:-1]\n",
    "            pred_aspect_unpadded = pred_aspect_unpadded[1:-1]\n",
    "            true_aspect_unpadded = true_aspect_unpadded[1:-1]\n",
    "            \n",
    "            true_aspect_unpadded = np.where(true_aspect_unpadded==-100, 1, true_aspect_unpadded)\n",
    "\n",
    "            orig_sentence = np.array(tokenizer.convert_ids_to_tokens(ids_unpadded))\n",
    "            decoded_aspect_tags = encoder.inverse_transform(true_aspect_unpadded)\n",
    "            aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "            \n",
    "            print(\"Aspect Acc: {:.2f}%\".format(aspect_acc*100))\n",
    "            print(\"Predicted Aspect:\")\n",
    "            print(encoder.inverse_transform(pred_aspect_unpadded))\n",
    "            print(\"True Aspect:\")\n",
    "            print(decoded_aspect_tags)\n",
    "            print(\"Sentence:\")\n",
    "            print(orig_sentence)   \n",
    "            print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67842c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: model.task1.cleaned.bin\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['Some' 'problems' 'can' 'be' 'fixed' 'if' 'you' 'purchase' 'new'\n",
      " 'software' 'but' 'there' 'is' 'no' 'g' '##ua' '##rent' '##ee']\n",
      "Aspect Terms: ['software']\n",
      "\n",
      "Aspect Acc: 90.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['The' 'screen' 'almost' 'looked' 'like' 'a' 'bar' '##code' 'when' 'it'\n",
      " 'froze']\n",
      "Aspect Terms: ['screen']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT'\n",
      " 'AT' 'AT' 'AT' 'AT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT'\n",
      " 'NAT' 'AT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['We' 'got' 'in' 'line' 'and' 'were' 'served' 'while' 'in' 'line' 'a'\n",
      " 'ban' '##nan' 'f' '##rit' '##ter']\n",
      "Aspect Terms: ['served' 'ban' 'f']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['Some' 'problems' 'can' 'be' 'fixed' 'if' 'you' 'purchase' 'new'\n",
      " 'software' 'but' 'there' 'is' 'no' 'g' '##ua' '##rent' '##ee']\n",
      "Aspect Terms: ['software']\n",
      "\n",
      "Aspect Acc: 90.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['The' 'screen' 'almost' 'looked' 'like' 'a' 'bar' '##code' 'when' 'it'\n",
      " 'froze']\n",
      "Aspect Terms: ['screen']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'AT' 'AT' 'AT' 'AT' 'NAT' 'AT' 'AT' 'AT' 'AT' 'AT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'NAT' 'NAT' 'AT' 'AT' 'NAT' 'AT' 'AT' 'NAT' 'NAT' 'AT' 'NAT'\n",
      " 'NAT']\n",
      "Sentence:\n",
      "['Best' 'drums' '##tick' '##s' 'over' 'rice' 'and' 'sour' 's' '##pic'\n",
      " '##y' 'soup' 'in' 'town']\n",
      "Aspect Terms: ['drums' 'over' 'rice' 'sour' 's' 'soup']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['Some' 'problems' 'can' 'be' 'fixed' 'if' 'you' 'purchase' 'new'\n",
      " 'software' 'but' 'there' 'is' 'no' 'g' '##ua' '##rent' '##ee']\n",
      "Aspect Terms: ['software']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'NAT']\n",
      "Sentence:\n",
      "['He' 'takes' 'real' 'pride' 'in' 'his' 'food' 'and' 'his' 'business']\n",
      "Aspect Terms: ['food']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'AT']\n",
      "True Aspect:\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT']\n",
      "Sentence:\n",
      "['Really' 'though' 'where' \"'\" 's' 'the' 'season' '##ing']\n",
      "Aspect Terms: ['season']\n",
      "\n",
      "Aspect Acc: 100.00%\n",
      "Predicted Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT']\n",
      "True Aspect:\n",
      "['NAT' 'AT' 'AT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT' 'AT' 'NAT' 'NAT'\n",
      " 'NAT']\n",
      "Sentence:\n",
      "['The' 'menu' 'choices' 'are' 'similar' 'but' 'the' 'taste' 'lacked'\n",
      " 'more' 'flavor' 'than' 'it' 'looked']\n",
      "Aspect Terms: ['menu' 'choices' 'taste' 'flavor']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_test(test_dataset, test_data_loader, model, num=10, model_path=MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b24aac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Raw Data\n",
      "*** input_ids\n",
      "tensor([  101,   146,  2965,  1122,  1120,  1480,  1105, 19476,  1781,  1103,\n",
      "        13408,  1114,  1143,  1272,  1104,  1103,  1363,  7105,  1297,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "*** aspect_tags\n",
      "tensor([-100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    0,    1,\n",
      "           1,    1,    1,    1,    1,    0,    0, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])\n",
      "\n",
      "['[CLS]' 'I' 'charge' 'it' 'at' 'night' 'and' 'skip' 'taking' 'the' 'cord'\n",
      " 'with' 'me' 'because' 'of' 'the' 'good' 'battery' 'life' '[SEP]']\n",
      "['NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'NAT'\n",
      " 'NAT' 'NAT' 'NAT' 'NAT' 'NAT' 'AT' 'AT' 'NAT']\n",
      "Aspect Terms: ['cord' 'battery' 'life']\n"
     ]
    }
   ],
   "source": [
    "def test_dataset(idx=0):\n",
    "\n",
    "\n",
    "    train_dataset = SentenceTagDataset(tokenizer=tokenizer,\n",
    "                                       sentences=train_sentences,\n",
    "                                       aspect_tags=train_aspect_tags,\n",
    "#                                        polarity_tags=train_polarity_tags,\n",
    "                                       aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "\n",
    "    train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=32), device)    \n",
    "\n",
    "    data = train_dataset[idx]\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = np.logical_not(data['attention_mask'])\n",
    "    aspect_tags = data['aspect_tags']\n",
    "    \n",
    "    print(\"*** Raw Data\")\n",
    "    print(\"*** input_ids\")\n",
    "    print(input_ids)\n",
    "    print(\"*** aspect_tags\")\n",
    "    print(aspect_tags)\n",
    "    print()\n",
    "    \n",
    "    input_ids = np.ma.compressed(np.ma.masked_where(attention_mask, input_ids))\n",
    "    aspect_tags = np.ma.compressed(np.ma.masked_where(attention_mask, aspect_tags))\n",
    "    \n",
    "    aspect_tags = np.where(aspect_tags==-100, 1, aspect_tags)\n",
    "    \n",
    "    orig_sentence = np.array(train_dataset.tokenizer.convert_ids_to_tokens(input_ids))\n",
    "    decoded_aspect_tags = encoder.inverse_transform(aspect_tags)\n",
    "    \n",
    "    aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "    \n",
    "    print(orig_sentence)\n",
    "    print(decoded_aspect_tags)  \n",
    "    \n",
    "    print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "\n",
    "test_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b0500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
