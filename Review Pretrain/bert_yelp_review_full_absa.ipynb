{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d01f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99bf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of aspect tags: 2\n",
      "num of polarity tags: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../Dataset/data/restaurants_laptop_train_with_pos.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# df = df[:200]\n",
    "\n",
    "# replace all -1 to 2 since pytorch cannot handle negative\n",
    "# so, 2 now means negative polarity\n",
    "df.polarity = df.polarity.replace(-1,2)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
    "\n",
    "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
    "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
    "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
    "\n",
    "polarity_unique_values = df.polarity.unique()\n",
    "\n",
    "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
    "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
    "\n",
    "np.where(encoder.classes_ == \"AT\")[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abf5a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['However', ',', 'the', 'multi', '-', 'touch', 'gestures', 'and', 'large', 'tracking', 'area', 'make', 'having', 'an', 'external', 'mouse', 'unnecessary', '(', 'unless', 'you', \"'re\", 'gaming', ')', '.']\n",
      "[1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "[0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(sentences[idx])\n",
    "print(aspect_tags[idx])\n",
    "print(polarity_tags[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af348a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            data[k] = to_device(v, device)\n",
    "        return data\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739a3984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 8\n",
    "MODEL_PATH = \"absa_results/bert_yelp_review_full.bin\"\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_ASPECT_TAGS = len(encoder.classes_)\n",
    "NUM_POLARITY_TAGS = len(polarity_unique_values)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b65241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTagDataset(Dataset):\n",
    "    def __init__(self, tokenizer, sentences, aspect_tags, polarity_tags, aspect_term_tag, \n",
    "                 max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.aspect_tags = aspect_tags\n",
    "        self.polarity_tags = polarity_tags\n",
    "        self.aspect_term_tag = aspect_term_tag\n",
    "        self.max_length = max_length\n",
    "        self.special_token = -100\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]  # Get a sentence\n",
    "        aspect_tags = self.aspect_tags[idx]  # Get the corresponding aspect tags\n",
    "        polarity_tags = self.polarity_tags[idx]\n",
    "\n",
    "        sentence_encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            is_split_into_words=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        word_ids = sentence_encoding.word_ids(batch_index=0)\n",
    "        aspect_tags_encoding = []\n",
    "        polarity_tags_encoding = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "                polarity_tags_encoding.append(self.special_token)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                aspect_tags_encoding.append(aspect_tags[word_idx])\n",
    "                if aspect_tags[word_idx] == self.aspect_term_tag:\n",
    "                    polarity_tags_encoding.append(polarity_tags[word_idx])\n",
    "                else:\n",
    "                    polarity_tags_encoding.append(self.special_token)\n",
    "            else:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "                polarity_tags_encoding.append(self.special_token)\n",
    "            previous_word_idx = word_idx\n",
    "        aspect_tags_encoding = torch.LongTensor(aspect_tags_encoding)\n",
    "        polarity_tags_encoding = torch.LongTensor(polarity_tags_encoding)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": sentence_encoding[\"input_ids\"][0],\n",
    "            \"attention_mask\": sentence_encoding[\"attention_mask\"][0],\n",
    "            \"token_type_ids\": sentence_encoding[\"token_type_ids\"][0],\n",
    "            \"aspect_tags\": aspect_tags_encoding,\n",
    "            \"polarity_tags\": polarity_tags_encoding,\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad052c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pretrain_results/bert_yelp_review_full_mlm_29500 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrain_results/bert_yelp_review_full_mlm_29500 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(output, target, mask, num_labels):\n",
    "    cel = nn.CrossEntropyLoss()\n",
    "    masking = mask.view(-1) == 1\n",
    "    pred = output.view(-1, num_labels)\n",
    "    true = torch.where(masking, target.view(-1), \n",
    "                       torch.tensor(cel.ignore_index).type_as(target))\n",
    "    \n",
    "    loss = cel(pred, true)\n",
    "    return loss\n",
    "\n",
    "class AspectExtractionModel(nn.Module):\n",
    "    def __init__(self, num_aspect_tags, num_polarity_tags, num_vocab):\n",
    "        super(AspectExtractionModel, self).__init__()\n",
    "        self.num_aspect_tags = num_aspect_tags\n",
    "        self.num_polarity_tags = num_polarity_tags\n",
    "        self.bert_model = transformers.BertModel.from_pretrained(\"pretrain_results/yelp_review_full/bert-yelp-review-full-mlm-29500\")\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(768, self.num_aspect_tags)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(768, self.num_polarity_tags)\n",
    "        # if the number of vocab has been increased, then need to add the new vector \n",
    "        # at the end of the embedding matrix\n",
    "        self.bert_model.resize_token_embeddings(num_vocab)\n",
    "                \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, aspect_tags, polarity_tags):\n",
    "        out, pool_out = self.bert_model(input_ids, attention_mask = attention_mask, \n",
    "                                 token_type_ids = token_type_ids, return_dict=False)\n",
    "        \n",
    "        tag_out = self.dropout1(out)\n",
    "        tag_out = self.fc1(tag_out)\n",
    "        \n",
    "        pol_out = self.dropout2(out)\n",
    "        pol_out = self.fc2(pol_out)\n",
    "        \n",
    "        loss_tag = loss_fn(tag_out, aspect_tags, attention_mask, self.num_aspect_tags)\n",
    "        loss_pol = loss_fn(pol_out, polarity_tags, attention_mask, self.num_polarity_tags)\n",
    "        loss = (loss_tag + loss_pol) / 2\n",
    "        \n",
    "        s = nn.Softmax(dim=2)\n",
    "        \n",
    "        tag_out = s(tag_out)\n",
    "        pol_out = s(pol_out)\n",
    "        \n",
    "        return tag_out, pol_out, loss\n",
    "\n",
    "model = to_device(AspectExtractionModel(num_aspect_tags = NUM_ASPECT_TAGS,\n",
    "                                        num_polarity_tags = NUM_POLARITY_TAGS,\n",
    "                                        num_vocab = len(tokenizer)), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e888395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(pred_tags, true_tags):\n",
    "    if isinstance(pred_tags, list):\n",
    "        pred_tags = torch.cat(pred_tags, 0)\n",
    "        true_tags = torch.cat(true_tags, 0)\n",
    "    pred_tags = pred_tags[true_tags!=-100]\n",
    "    true_tags = true_tags[true_tags!=-100]\n",
    "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
    "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
    "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
    "\n",
    "    return acc, f1, cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883d3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((2745,), (687,), (2745,), (687,), (2745,), (687,))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_sentences, test_sentences, \n",
    " train_aspect_tags, test_aspect_tags) = model_selection.train_test_split(\n",
    "    sentences, aspect_tags, random_state = 42, test_size = TEST_SIZE)\n",
    "\n",
    "## TODO: Need to combine the two to ensure they split the two training and test set correctly \n",
    "##\n",
    "(_, _, \n",
    " train_polarity_tags, test_polarity_tags) = model_selection.train_test_split(\n",
    "    sentences, polarity_tags, random_state = 42, test_size = TEST_SIZE)\n",
    "\n",
    "train_sentences.shape, test_sentences.shape, train_aspect_tags.shape, test_aspect_tags.shape, train_polarity_tags.shape, test_polarity_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52bef269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'pizza', 'was', 'pretty', 'good', 'and', 'huge', '.']\n",
      "[1, 0, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(train_sentences[idx])\n",
    "print(train_aspect_tags[idx])\n",
    "print(train_polarity_tags[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5b8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=train_sentences, \n",
    "                                   aspect_tags=train_aspect_tags,\n",
    "                                   polarity_tags=train_polarity_tags,\n",
    "                                   aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE), device)    \n",
    "\n",
    "test_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=test_sentences, \n",
    "                                  aspect_tags=test_aspect_tags,\n",
    "                                  polarity_tags=test_polarity_tags,\n",
    "                                  aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "test_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=TEST_BATCH_SIZE), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa1753e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yunxuan\\onedrive\\cs4248\\env\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 86/86 [00:24<00:00,  3.53it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 39.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48493; Valid Loss: 0.33664\n",
      "Aspect Train acc: 90.92%; Valid acc: 94.67%\n",
      "Aspect Train f1: 90.10%; Valid f1: 94.71%\n",
      "Aspect Train cm:\n",
      " [[42148  1096]\n",
      " [ 3455  3426]]\n",
      "Aspect Valid cm:\n",
      " [[10846   372]\n",
      " [  319  1436]]\n",
      "\n",
      "Polarity Train acc: 66.39%; Valid acc: 77.78%\n",
      "Polarity Train f1: 65.81%; Valid f1: 76.45%\n",
      "Polarity Train cm:\n",
      " [[ 936  737  157]\n",
      " [ 197 3303  192]\n",
      " [ 309  721  329]]\n",
      "Polarity Valid cm:\n",
      " [[429  70  32]\n",
      " [ 42 808  59]\n",
      " [102  85 128]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:22<00:00,  3.79it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 38.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.25334; Valid Loss: 0.34811\n",
      "Aspect Train acc: 95.29%; Valid acc: 95.37%\n",
      "Aspect Train f1: 95.25%; Valid f1: 95.42%\n",
      "Aspect Train cm:\n",
      " [[42209  1035]\n",
      " [ 1324  5557]]\n",
      "Aspect Valid cm:\n",
      " [[10872   346]\n",
      " [  255  1500]]\n",
      "\n",
      "Polarity Train acc: 84.49%; Valid acc: 79.09%\n",
      "Polarity Train f1: 84.86%; Valid f1: 79.15%\n",
      "Polarity Train cm:\n",
      " [[1553   92  185]\n",
      " [ 106 3429  157]\n",
      " [ 279  248  832]]\n",
      "Polarity Valid cm:\n",
      " [[424  55  52]\n",
      " [ 43 797  69]\n",
      " [ 85  63 167]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:22<00:00,  3.79it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 39.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.16289; Valid Loss: 0.38168\n",
      "Aspect Train acc: 96.39%; Valid acc: 95.51%\n",
      "Aspect Train f1: 96.37%; Valid f1: 95.58%\n",
      "Aspect Train cm:\n",
      " [[42445   799]\n",
      " [ 1010  5871]]\n",
      "Aspect Valid cm:\n",
      " [[10860   358]\n",
      " [  224  1531]]\n",
      "\n",
      "Polarity Train acc: 91.38%; Valid acc: 78.97%\n",
      "Polarity Train f1: 91.87%; Valid f1: 78.77%\n",
      "Polarity Train cm:\n",
      " [[1665   35  130]\n",
      " [  49 3536  107]\n",
      " [ 158  114 1087]]\n",
      "Polarity Valid cm:\n",
      " [[418  55  58]\n",
      " [ 30 796  83]\n",
      " [ 75  68 172]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:22<00:00,  3.75it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 38.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.11389; Valid Loss: 0.39550\n",
      "Aspect Train acc: 96.80%; Valid acc: 95.85%\n",
      "Aspect Train f1: 96.79%; Valid f1: 95.87%\n",
      "Aspect Train cm:\n",
      " [[42495   749]\n",
      " [  857  6024]]\n",
      "Aspect Valid cm:\n",
      " [[10921   297]\n",
      " [  242  1513]]\n",
      "\n",
      "Polarity Train acc: 94.86%; Valid acc: 79.43%\n",
      "Polarity Train f1: 95.13%; Valid f1: 79.60%\n",
      "Polarity Train cm:\n",
      " [[1730   17   83]\n",
      " [  23 3607   62]\n",
      " [  96   73 1190]]\n",
      "Polarity Valid cm:\n",
      " [[423  51  57]\n",
      " [ 32 781  96]\n",
      " [ 74  51 190]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:22<00:00,  3.80it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 38.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08908; Valid Loss: 0.40800\n",
      "Aspect Train acc: 97.08%; Valid acc: 95.84%\n",
      "Aspect Train f1: 97.07%; Valid f1: 95.88%\n",
      "Aspect Train cm:\n",
      " [[42558   686]\n",
      " [  778  6103]]\n",
      "Aspect Valid cm:\n",
      " [[10909   309]\n",
      " [  231  1524]]\n",
      "\n",
      "Polarity Train acc: 96.50%; Valid acc: 78.18%\n",
      "Polarity Train f1: 96.74%; Valid f1: 79.23%\n",
      "Polarity Train cm:\n",
      " [[1771    4   55]\n",
      " [  20 3635   37]\n",
      " [  76   49 1234]]\n",
      "Polarity Valid cm:\n",
      " [[373  72  86]\n",
      " [ 25 797  87]\n",
      " [ 46  67 202]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_train_steps = int(len(train_sentences) / TRAIN_BATCH_SIZE * NUM_EPOCHS)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=num_train_steps)\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": list(),\n",
    "    \"aspact_train_acc\": list(),\n",
    "    \"polarity_train_acc\": list(),\n",
    "    \"valid_loss\": list(),\n",
    "    \"aspact_valid_acc\": list(),\n",
    "    \"polarity_valid_acc\": list(),\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    train_f1 = []\n",
    "    test_f1 = []\n",
    "\n",
    "    model.train()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    for data in tqdm(train_data_loader, total=len(train_data_loader)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_aspect_tags, pred_polarity_tags, loss = model(**data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_pred_polarity_tags.append(torch.argmax(pred_polarity_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "        final_true_polarity_tags.append(data['polarity_tags'])\n",
    "        \n",
    "#         print(pred_polarity_tags)\n",
    "#         print(data['polarity_tags'])\n",
    "        \n",
    "    aspect_train_acc, aspect_train_f1, aspect_train_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                                 final_true_aspect_tags)\n",
    "    polarity_train_acc, polarity_train_f1, polarity_train_cm = cal_acc(final_pred_polarity_tags, \n",
    "                                                                       final_true_polarity_tags)\n",
    "        \n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "        pred_aspect_tags, pred_polarity_tags, loss = model(**data)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_pred_polarity_tags.append(torch.argmax(pred_polarity_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "        final_true_polarity_tags.append(data['polarity_tags'])\n",
    "\n",
    "    aspect_test_acc, aspect_test_f1, aspect_test_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                              final_true_aspect_tags)\n",
    "    polarity_test_acc, polarity_test_f1, polarity_test_cm = cal_acc(final_pred_polarity_tags, \n",
    "                                                                    final_true_polarity_tags)\n",
    "\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
    "        \n",
    "    print(\"Train Loss: {:.5f}; Valid Loss: {:.5f}\".format(avg_train_loss, avg_test_loss))\n",
    "    print(\"Aspect Train acc: {:.2f}%; Valid acc: {:.2f}%\".format(\n",
    "        aspect_train_acc*100, aspect_test_acc*100))\n",
    "    print(\"Aspect Train f1: {:.2f}%; Valid f1: {:.2f}%\".format(\n",
    "        aspect_train_f1*100, aspect_test_f1*100))\n",
    "    print(\"Aspect Train cm:\\n {}\".format(np.flip(aspect_train_cm)))\n",
    "    print(\"Aspect Valid cm:\\n {}\".format(np.flip(aspect_test_cm)))\n",
    "    print()\n",
    "    print(\"Polarity Train acc: {:.2f}%; Valid acc: {:.2f}%\".format(\n",
    "        polarity_train_acc*100, polarity_test_acc*100))\n",
    "    print(\"Polarity Train f1: {:.2f}%; Valid f1: {:.2f}%\".format(\n",
    "        polarity_train_f1*100, polarity_test_f1*100))\n",
    "    print(\"Polarity Train cm:\\n {}\".format(np.flip(polarity_train_cm)))\n",
    "    print(\"Polarity Valid cm:\\n {}\".format(np.flip(polarity_test_cm)))\n",
    "    \n",
    "    if avg_test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        best_loss = avg_test_loss    \n",
    "        \n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['aspact_train_acc'].append(aspect_train_acc.cpu().numpy())\n",
    "    history['polarity_train_acc'].append(polarity_train_acc.cpu().numpy())\n",
    "    history['valid_loss'].append(avg_test_loss)\n",
    "    history['aspact_valid_acc'].append(aspect_test_acc.cpu().numpy())\n",
    "    history['polarity_valid_acc'].append(polarity_test_acc.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac026d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history['aspact_train_acc'], label='train accuracy')\n",
    "plt.plot(history['aspact_valid_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea406efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(test_data_loader, model, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)   \n",
    "    \n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "            pred_aspect_tags, pred_polarity_tags, loss = model(**data)\n",
    "            \n",
    "            final_pred_aspect_tags.extend(torch.argmax(pred_aspect_tags, dim=2))\n",
    "            final_pred_polarity_tags.extend(torch.argmax(pred_polarity_tags, dim=2))\n",
    "            final_true_aspect_tags.extend(data['aspect_tags'])\n",
    "            final_true_polarity_tags.extend(data['polarity_tags'])\n",
    "            \n",
    "    final_pred_aspect_tags = torch.stack(final_pred_aspect_tags).cpu()\n",
    "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
    "    final_true_aspect_tags = torch.stack(final_true_aspect_tags).cpu()\n",
    "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
    "    \n",
    "    # Remove the special -100 tokens \n",
    "    final_pred_aspect_tags = final_pred_aspect_tags[final_true_aspect_tags!=-100]\n",
    "    final_true_aspect_tags = final_true_aspect_tags[final_true_aspect_tags!=-100]\n",
    "    final_pred_polarity_tags = final_pred_polarity_tags[final_true_polarity_tags!=-100]\n",
    "    final_true_polarity_tags = final_true_polarity_tags[final_true_polarity_tags!=-100]\n",
    "        \n",
    "    print(classification_report(final_true_aspect_tags, final_pred_aspect_tags, \n",
    "                                target_names=encoder.classes_))\n",
    "    \n",
    "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
    "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
    "    \n",
    "get_classification_report(test_data_loader, model, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(test_dataset, test_data_loader, model, num=5, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num):\n",
    "            \n",
    "            data = next(iter(test_data_loader))\n",
    "            \n",
    "            pred_aspect_tags, pred_polarity_tags, _ = model(**data)\n",
    "            \n",
    "            \n",
    "            input_ids = data['input_ids']\n",
    "            pred_aspect_tags = torch.argmax(pred_aspect_tags, dim=2)\n",
    "            pred_polarity_tags = torch.argmax(pred_polarity_tags, dim=2)\n",
    "            true_aspect_tags = data['aspect_tags']\n",
    "            true_polarity_tags = data['polarity_tags']\n",
    "            mask = data['attention_mask']\n",
    "            \n",
    "            # Randomly pick a test data from this batch\n",
    "            #\n",
    "            rng = np.random.default_rng()\n",
    "            idx = rng.integers(low=0, high=pred_aspect_tags.shape[0],size=1)[0]\n",
    "#             idx = np.random.randint(0,pred_aspect_tags.shape[0],size=1)[0]\n",
    "\n",
    "            ids_array = input_ids[idx].cpu().numpy()\n",
    "            pred_aspect_array = pred_aspect_tags[idx].cpu().numpy()\n",
    "            true_aspect_array = true_aspect_tags[idx].cpu().numpy()\n",
    "            pred_polarity_array = pred_polarity_tags[idx].cpu().numpy()\n",
    "            true_polarity_array = true_polarity_tags[idx].cpu().numpy()\n",
    "            mask_array = mask[idx].cpu().numpy()\n",
    "\n",
    "            # Remove the padding as we do not want to print them\n",
    "            #\n",
    "            mask_array = np.logical_not(mask_array)\n",
    "\n",
    "            # Only print the unpadded portion\n",
    "            ids_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, ids_array))\n",
    "            pred_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       pred_aspect_array))\n",
    "            true_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       true_aspect_array))\n",
    "            pred_polarity_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                         pred_polarity_array))\n",
    "            true_polarity_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                         true_polarity_array))\n",
    "            \n",
    "            aspect_pred = pred_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            aspect_true = true_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            polarity_pred = pred_polarity_unpadded[true_polarity_unpadded!=-100]\n",
    "            polarity_true = true_polarity_unpadded[true_polarity_unpadded!=-100]\n",
    "            \n",
    "            aspect_acc = np.sum(aspect_pred == aspect_true) / len(aspect_pred)\n",
    "            polarity_acc = np.sum(polarity_pred == polarity_true) / len(polarity_pred)\n",
    "            \n",
    "            # Remove begin and end\n",
    "            ids_unpadded = ids_unpadded[1:-1]\n",
    "            pred_aspect_unpadded = pred_aspect_unpadded[1:-1]\n",
    "            true_aspect_unpadded = true_aspect_unpadded[1:-1]\n",
    "            pred_polarity_unpadded = pred_polarity_unpadded[1:-1]\n",
    "            true_polarity_unpadded = true_polarity_unpadded[1:-1]\n",
    "            \n",
    "            true_aspect_unpadded = np.where(true_aspect_unpadded==-100, 1, true_aspect_unpadded)\n",
    "\n",
    "            # let's replace 2 back to -1 for presentation\n",
    "            pred_polarity_unpadded = np.where(pred_polarity_unpadded == 2, -1, \n",
    "                                              pred_polarity_unpadded)\n",
    "            true_polarity_unpadded = np.where(true_polarity_unpadded == 2, -1, \n",
    "                                              true_polarity_unpadded)\n",
    "            \n",
    "            orig_sentence = np.array(tokenizer.convert_ids_to_tokens(ids_unpadded))\n",
    "            decoded_aspect_tags = encoder.inverse_transform(true_aspect_unpadded)\n",
    "            aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "            \n",
    "            pred_polarity_unpadded = pred_polarity_unpadded[aspect_tag_indices]\n",
    "            true_polarity_unpadded = true_polarity_unpadded[aspect_tag_indices]\n",
    "\n",
    "            print(\"Aspect Acc: {:.2f}%\".format(aspect_acc*100))\n",
    "            print(\"Polarity Acc: {:.2f}%\".format(polarity_acc*100))\n",
    "            print(\"Predicted Aspect:\")\n",
    "            print(encoder.inverse_transform(pred_aspect_unpadded))\n",
    "            print(\"True Aspect:\")\n",
    "            print(decoded_aspect_tags)\n",
    "            print(\"Predicted Polarity:\")\n",
    "            print(pred_polarity_unpadded)\n",
    "            print(\"True Polarity:\")\n",
    "            print(true_polarity_unpadded)\n",
    "            print(\"Sentence:\")\n",
    "            print(orig_sentence)   \n",
    "            print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_test(test_dataset, test_data_loader, model, num=10, model_path=MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24aac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(idx=0):\n",
    "\n",
    "\n",
    "    train_dataset = SentenceTagDataset(tokenizer=tokenizer,\n",
    "                                       sentences=train_sentences,\n",
    "                                       aspect_tags=train_aspect_tags,\n",
    "                                       polarity_tags=train_polarity_tags,\n",
    "                                       aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "\n",
    "    train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=32), device)    \n",
    "\n",
    "    data = train_dataset[idx]\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = np.logical_not(data['attention_mask'])\n",
    "    aspect_tags = data['aspect_tags']\n",
    "    polarity_tags = data['polarity_tags']\n",
    "    \n",
    "    print(\"*** Raw Data\")\n",
    "    print(\"*** input_ids\")\n",
    "    print(input_ids)\n",
    "    print(\"*** aspect_tags\")\n",
    "    print(aspect_tags)\n",
    "    print(\"*** polarity_tags\")\n",
    "    print(polarity_tags)\n",
    "    print()\n",
    "    \n",
    "    input_ids = np.ma.compressed(np.ma.masked_where(attention_mask, input_ids))\n",
    "    aspect_tags = np.ma.compressed(np.ma.masked_where(attention_mask, aspect_tags))\n",
    "    polarity_tags = np.ma.compressed(np.ma.masked_where(attention_mask, polarity_tags))\n",
    "    \n",
    "#     input_ids = input_ids[(input_ids!=101) & (input_ids!=102)]\n",
    "    \n",
    "    aspect_tags = np.where(aspect_tags==-100, 1, aspect_tags)\n",
    "#     polarity_tags = np.where(polarity_tags==-100, 0, polarity_tags)\n",
    "    \n",
    "#     aspect_tags = aspect_tags[aspect_tags!=-100]\n",
    "    polarity_tags = polarity_tags[polarity_tags!=-100]\n",
    "    \n",
    "    orig_sentence = np.array(train_dataset.tokenizer.convert_ids_to_tokens(input_ids))\n",
    "    decoded_aspect_tags = encoder.inverse_transform(aspect_tags)\n",
    "    \n",
    "    aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "    \n",
    "    print(orig_sentence)\n",
    "    print(decoded_aspect_tags)  \n",
    "    print(polarity_tags)  \n",
    "    \n",
    "    print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "\n",
    "test_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b0500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}