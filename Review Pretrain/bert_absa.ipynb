{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d01f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99bf534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of aspect tags: 2\n",
      "num of polarity tags: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/restaurants_laptop_train_with_pos.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# df = df[:200]\n",
    "\n",
    "# replace all -1 to 2 since pytorch cannot handle negative\n",
    "# so, 2 now means negative polarity\n",
    "df.polarity = df.polarity.replace(-1,2)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
    "\n",
    "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
    "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
    "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
    "\n",
    "polarity_unique_values = df.polarity.unique()\n",
    "\n",
    "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
    "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
    "\n",
    "np.where(encoder.classes_ == \"AT\")[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abf5a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['However', ',', 'the', 'multi', '-', 'touch', 'gestures', 'and', 'large', 'tracking', 'area', 'make', 'having', 'an', 'external', 'mouse', 'unnecessary', '(', 'unless', 'you', \"'re\", 'gaming', ')', '.']\n",
      "[1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "[0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(sentences[idx])\n",
    "print(aspect_tags[idx])\n",
    "print(polarity_tags[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af348a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            data[k] = to_device(v, device)\n",
    "        return data\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739a3984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 8\n",
    "MODEL_PATH = \"model.bin\"\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "NUM_ASPECT_TAGS = len(encoder.classes_)\n",
    "NUM_POLARITY_TAGS = len(polarity_unique_values)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b65241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTagDataset(Dataset):\n",
    "    def __init__(self, tokenizer, sentences, aspect_tags, polarity_tags, aspect_term_tag, \n",
    "                 max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.aspect_tags = aspect_tags\n",
    "        self.polarity_tags = polarity_tags\n",
    "        self.aspect_term_tag = aspect_term_tag\n",
    "        self.max_length = max_length\n",
    "        self.special_token = -100\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]  # Get a sentence\n",
    "        aspect_tags = self.aspect_tags[idx]  # Get the corresponding aspect tags\n",
    "        polarity_tags = self.polarity_tags[idx]\n",
    "\n",
    "        sentence_encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            is_split_into_words=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        word_ids = sentence_encoding.word_ids(batch_index=0)\n",
    "        aspect_tags_encoding = []\n",
    "        polarity_tags_encoding = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "                polarity_tags_encoding.append(self.special_token)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                aspect_tags_encoding.append(aspect_tags[word_idx])\n",
    "                if aspect_tags[word_idx] == self.aspect_term_tag:\n",
    "                    polarity_tags_encoding.append(polarity_tags[word_idx])\n",
    "                else:\n",
    "                    polarity_tags_encoding.append(self.special_token)\n",
    "            else:\n",
    "                aspect_tags_encoding.append(self.special_token)\n",
    "                polarity_tags_encoding.append(self.special_token)\n",
    "            previous_word_idx = word_idx\n",
    "        aspect_tags_encoding = torch.LongTensor(aspect_tags_encoding)\n",
    "        polarity_tags_encoding = torch.LongTensor(polarity_tags_encoding)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": sentence_encoding[\"input_ids\"][0],\n",
    "            \"attention_mask\": sentence_encoding[\"attention_mask\"][0],\n",
    "            \"token_type_ids\": sentence_encoding[\"token_type_ids\"][0],\n",
    "            \"aspect_tags\": aspect_tags_encoding,\n",
    "            \"polarity_tags\": polarity_tags_encoding,\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad052c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, target, mask, num_labels):\n",
    "    cel = nn.CrossEntropyLoss()\n",
    "    masking = mask.view(-1) == 1\n",
    "    pred = output.view(-1, num_labels)\n",
    "    true = torch.where(masking, target.view(-1), \n",
    "                       torch.tensor(cel.ignore_index).type_as(target))\n",
    "    \n",
    "    loss = cel(pred, true)\n",
    "    return loss\n",
    "\n",
    "class AspectExtractionModel(nn.Module):\n",
    "    def __init__(self, num_aspect_tags, num_polarity_tags, num_vocab):\n",
    "        super(AspectExtractionModel, self).__init__()\n",
    "        self.num_aspect_tags = num_aspect_tags\n",
    "        self.num_polarity_tags = num_polarity_tags\n",
    "        self.bert_model = transformers.BertModel.from_pretrained(\"bert-base-cased\")        \n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(768, self.num_aspect_tags)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(768, self.num_polarity_tags)\n",
    "        # if the number of vocab has been increased, then need to add the new vector \n",
    "        # at the end of the embedding matrix\n",
    "        self.bert_model.resize_token_embeddings(num_vocab)\n",
    "                \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, aspect_tags, polarity_tags):\n",
    "        out, pool_out = self.bert_model(input_ids, attention_mask = attention_mask, \n",
    "                                 token_type_ids = token_type_ids, return_dict=False)\n",
    "        \n",
    "        tag_out = self.dropout1(out)\n",
    "        tag_out = self.fc1(tag_out)\n",
    "        \n",
    "        pol_out = self.dropout2(out)\n",
    "        pol_out = self.fc2(pol_out)\n",
    "        \n",
    "        loss_tag = loss_fn(tag_out, aspect_tags, attention_mask, self.num_aspect_tags)\n",
    "        loss_pol = loss_fn(pol_out, polarity_tags, attention_mask, self.num_polarity_tags)\n",
    "        loss = (loss_tag + loss_pol) / 2\n",
    "        \n",
    "        s = nn.Softmax(dim=2)\n",
    "        \n",
    "        tag_out = s(tag_out)\n",
    "        pol_out = s(pol_out)\n",
    "        \n",
    "        return tag_out, pol_out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e888395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(pred_tags, true_tags):\n",
    "    if isinstance(pred_tags, list):\n",
    "        pred_tags = torch.cat(pred_tags, 0)\n",
    "        true_tags = torch.cat(true_tags, 0)\n",
    "    pred_tags = pred_tags[true_tags!=-100]\n",
    "    true_tags = true_tags[true_tags!=-100]\n",
    "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
    "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
    "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
    "\n",
    "    return acc, f1, cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883d3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2745,), (687,), (2745,), (687,), (2745,), (687,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_sentences, test_sentences, \n",
    " train_aspect_tags, test_aspect_tags) = model_selection.train_test_split(\n",
    "    sentences, aspect_tags, random_state = 42, test_size = TEST_SIZE)\n",
    "\n",
    "## TODO: Need to combine the two to ensure they split the two training and test set correctly \n",
    "##\n",
    "(_, _, \n",
    " train_polarity_tags, test_polarity_tags) = model_selection.train_test_split(\n",
    "    sentences, polarity_tags, random_state = 42, test_size = TEST_SIZE)\n",
    "\n",
    "train_sentences.shape, test_sentences.shape, train_aspect_tags.shape, test_aspect_tags.shape, train_polarity_tags.shape, test_polarity_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52bef269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'pizza', 'was', 'pretty', 'good', 'and', 'huge', '.']\n",
      "[1, 0, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(train_sentences[idx])\n",
    "print(train_aspect_tags[idx])\n",
    "print(train_polarity_tags[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5b8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=train_sentences, \n",
    "                                   aspect_tags=train_aspect_tags,\n",
    "                                   polarity_tags=train_polarity_tags,\n",
    "                                   aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH_SIZE), device)    \n",
    "\n",
    "test_dataset = SentenceTagDataset(tokenizer=tokenizer, sentences=test_sentences, \n",
    "                                  aspect_tags=test_aspect_tags,\n",
    "                                  polarity_tags=test_polarity_tags,\n",
    "                                  aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "test_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=TEST_BATCH_SIZE), device)   \n",
    "\n",
    "model = to_device(AspectExtractionModel(num_aspect_tags = NUM_ASPECT_TAGS, \n",
    "                                        num_polarity_tags = NUM_POLARITY_TAGS,\n",
    "                                        num_vocab = len(tokenizer)), device)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa1753e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:49<00:00,  1.73it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.54413; Valid Loss: 0.37384\n",
      "Aspect Train acc: 89.41%; Valid acc: 94.27%\n",
      "Aspect Train f1: 88.41%; Valid f1: 94.34%\n",
      "Aspect Train cm:\n",
      " [[41810  1434]\n",
      " [ 3875  3006]]\n",
      "Aspect Valid cm:\n",
      " [[10793   425]\n",
      " [  319  1436]]\n",
      "\n",
      "Polarity Train acc: 60.54%; Valid acc: 72.88%\n",
      "Polarity Train f1: 60.08%; Valid f1: 72.80%\n",
      "Polarity Train cm:\n",
      " [[ 780  937  113]\n",
      " [ 355 3180  157]\n",
      " [ 359  794  206]]\n",
      "Polarity Valid cm:\n",
      " [[401  68  62]\n",
      " [ 77 722 110]\n",
      " [ 80  79 156]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:50<00:00,  1.72it/s]\n",
      "100%|██████████| 86/86 [00:05<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.28797; Valid Loss: 0.35233\n",
      "Aspect Train acc: 95.08%; Valid acc: 95.16%\n",
      "Aspect Train f1: 95.05%; Valid f1: 95.23%\n",
      "Aspect Train cm:\n",
      " [[42124  1120]\n",
      " [ 1344  5537]]\n",
      "Aspect Valid cm:\n",
      " [[10842   376]\n",
      " [  252  1503]]\n",
      "\n",
      "Polarity Train acc: 81.85%; Valid acc: 75.33%\n",
      "Polarity Train f1: 82.39%; Valid f1: 75.41%\n",
      "Polarity Train cm:\n",
      " [[1498  137  195]\n",
      " [ 163 3347  182]\n",
      " [ 290  282  787]]\n",
      "Polarity Valid cm:\n",
      " [[419  48  64]\n",
      " [ 61 721 127]\n",
      " [ 78  55 182]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:51<00:00,  1.68it/s]\n",
      "100%|██████████| 86/86 [00:05<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.17546; Valid Loss: 0.37514\n",
      "Aspect Train acc: 96.13%; Valid acc: 95.14%\n",
      "Aspect Train f1: 96.12%; Valid f1: 95.23%\n",
      "Aspect Train cm:\n",
      " [[42348   896]\n",
      " [ 1042  5839]]\n",
      "Aspect Valid cm:\n",
      " [[10814   404]\n",
      " [  227  1528]]\n",
      "\n",
      "Polarity Train acc: 90.58%; Valid acc: 77.44%\n",
      "Polarity Train f1: 91.05%; Valid f1: 78.17%\n",
      "Polarity Train cm:\n",
      " [[1661   45  124]\n",
      " [  66 3510  116]\n",
      " [ 169  128 1062]]\n",
      "Polarity Valid cm:\n",
      " [[390  72  69]\n",
      " [ 42 784  83]\n",
      " [ 63  67 185]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:51<00:00,  1.66it/s]\n",
      "100%|██████████| 86/86 [00:05<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.12137; Valid Loss: 0.40044\n",
      "Aspect Train acc: 96.70%; Valid acc: 95.53%\n",
      "Aspect Train f1: 96.69%; Valid f1: 95.57%\n",
      "Aspect Train cm:\n",
      " [[42449   795]\n",
      " [  861  6020]]\n",
      "Aspect Valid cm:\n",
      " [[10889   329]\n",
      " [  251  1504]]\n",
      "\n",
      "Polarity Train acc: 94.74%; Valid acc: 77.55%\n",
      "Polarity Train f1: 94.94%; Valid f1: 77.43%\n",
      "Polarity Train cm:\n",
      " [[1742   21   67]\n",
      " [  36 3578   78]\n",
      " [  91   69 1199]]\n",
      "Polarity Valid cm:\n",
      " [[427  57  47]\n",
      " [ 61 769  79]\n",
      " [ 84  66 165]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:51<00:00,  1.66it/s]\n",
      "100%|██████████| 86/86 [00:05<00:00, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09506; Valid Loss: 0.41330\n",
      "Aspect Train acc: 96.99%; Valid acc: 95.50%\n",
      "Aspect Train f1: 96.99%; Valid f1: 95.55%\n",
      "Aspect Train cm:\n",
      " [[42504   740]\n",
      " [  768  6113]]\n",
      "Aspect Valid cm:\n",
      " [[10880   338]\n",
      " [  246  1509]]\n",
      "\n",
      "Polarity Train acc: 96.47%; Valid acc: 77.21%\n",
      "Polarity Train f1: 96.74%; Valid f1: 78.17%\n",
      "Polarity Train cm:\n",
      " [[1770   10   50]\n",
      " [  23 3623   46]\n",
      " [  75   39 1245]]\n",
      "Polarity Valid cm:\n",
      " [[375  81  75]\n",
      " [ 33 789  87]\n",
      " [ 56  68 191]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "num_train_steps = int(len(train_sentences) / TRAIN_BATCH_SIZE * NUM_EPOCHS)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=num_train_steps)\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": list(),\n",
    "    \"aspact_train_acc\": list(),\n",
    "    \"polarity_train_acc\": list(),\n",
    "    \"valid_loss\": list(),\n",
    "    \"aspact_valid_acc\": list(),\n",
    "    \"polarity_valid_acc\": list(),\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    train_f1 = []\n",
    "    test_f1 = []\n",
    "\n",
    "    model.train()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    for data in tqdm(train_data_loader, total=len(train_data_loader)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_aspect_tags, pred_polarity_tags, loss = model(**data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_pred_polarity_tags.append(torch.argmax(pred_polarity_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "        final_true_polarity_tags.append(data['polarity_tags'])\n",
    "        \n",
    "#         print(pred_polarity_tags)\n",
    "#         print(data['polarity_tags'])\n",
    "        \n",
    "    aspect_train_acc, aspect_train_f1, aspect_train_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                                 final_true_aspect_tags)\n",
    "    polarity_train_acc, polarity_train_f1, polarity_train_cm = cal_acc(final_pred_polarity_tags, \n",
    "                                                                       final_true_polarity_tags)\n",
    "        \n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "        pred_aspect_tags, pred_polarity_tags, loss = model(**data)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "        final_pred_aspect_tags.append(torch.argmax(pred_aspect_tags, dim=2))\n",
    "        final_pred_polarity_tags.append(torch.argmax(pred_polarity_tags, dim=2))\n",
    "        final_true_aspect_tags.append(data['aspect_tags'])\n",
    "        final_true_polarity_tags.append(data['polarity_tags'])\n",
    "\n",
    "    aspect_test_acc, aspect_test_f1, aspect_test_cm = cal_acc(final_pred_aspect_tags, \n",
    "                                                              final_true_aspect_tags)\n",
    "    polarity_test_acc, polarity_test_f1, polarity_test_cm = cal_acc(final_pred_polarity_tags, \n",
    "                                                                    final_true_polarity_tags)\n",
    "\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
    "        \n",
    "    print(\"Train Loss: {:.5f}; Valid Loss: {:.5f}\".format(avg_train_loss, avg_test_loss))\n",
    "    print(\"Aspect Train acc: {:.2f}%; Valid acc: {:.2f}%\".format(\n",
    "        aspect_train_acc*100, aspect_test_acc*100))\n",
    "    print(\"Aspect Train f1: {:.2f}%; Valid f1: {:.2f}%\".format(\n",
    "        aspect_train_f1*100, aspect_test_f1*100))\n",
    "    print(\"Aspect Train cm:\\n {}\".format(np.flip(aspect_train_cm)))\n",
    "    print(\"Aspect Valid cm:\\n {}\".format(np.flip(aspect_test_cm)))\n",
    "    print()\n",
    "    print(\"Polarity Train acc: {:.2f}%; Valid acc: {:.2f}%\".format(\n",
    "        polarity_train_acc*100, polarity_test_acc*100))\n",
    "    print(\"Polarity Train f1: {:.2f}%; Valid f1: {:.2f}%\".format(\n",
    "        polarity_train_f1*100, polarity_test_f1*100))\n",
    "    print(\"Polarity Train cm:\\n {}\".format(np.flip(polarity_train_cm)))\n",
    "    print(\"Polarity Valid cm:\\n {}\".format(np.flip(polarity_test_cm)))\n",
    "    \n",
    "    if avg_test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        best_loss = avg_test_loss    \n",
    "        \n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['aspact_train_acc'].append(aspect_train_acc.cpu().numpy())\n",
    "    history['polarity_train_acc'].append(polarity_train_acc.cpu().numpy())\n",
    "    history['valid_loss'].append(avg_test_loss)\n",
    "    history['aspact_valid_acc'].append(aspect_test_acc.cpu().numpy())\n",
    "    history['polarity_valid_acc'].append(polarity_test_acc.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac026d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxZ0lEQVR4nO3deXwV9b3/8deHJBACBMIqO1RR9jUEl+rFYt1atbVa0CoFRat163K9+rPt1d7WW6/bVautlyooal3q0qrXaq+t1HqvAkHZBUVACWtYwxYgyef3xwzh5GSSnEBOTpb38/HI45yZ73dmPmc4fD9nvjPzHXN3RERE4rVIdQAiItIwKUGIiEgkJQgREYmkBCEiIpGUIEREJJIShIiIRFKCkGbJzP5sZt+t67q1jGG8mRVUU/6omf2srrcrkijTfRDSWJjZ7pjJLGA/UBpOf8/dn6n/qI6cmY0Hnnb3Xke5njXANHd/uw7CEimXnuoARBLl7m0Pva+uUTSzdHcvqc/YGivtK6mOupik0TvUVWNmt5jZRmCmmeWY2etmVmhm28P3vWKWmW1m08L3U8zsPTO7N6y72szOOcK6/c3sXTPbZWZvm9kjZvZ0DfH/2Mw2m9kGM5saM/8JM/tl+L5z+Bl2mNk2M/uHmbUws6eAPsBrZrbbzP4lrH++mS0N6882s0Ex610T7qtFwB4zu9nMXoqL6ddm9sAR/HNIE6IEIU3FMUBHoC9wNcF3e2Y43QfYBzxczfLjgBVAZ+Bu4HEzsyOo+3tgLtAJuAO4PIG42wM9gSuBR8wsJ6Lej4ECoAvQDbgNcHe/HPgCOM/d27r73WZ2PPAs8IOw/hsECaRlzPouAb4GdACeBs42sw4QHFUAE4GnaohdmjglCGkqyoDb3X2/u+9z963u/pK773X3XcCdwD9Vs/zn7v47dy8FngS6EzTECdc1sz7AWOBf3f2Au78HvFpD3AeBf3P3g+7+BrAbOKGKet2BvmHdf3jVJxAnAv/t7v/j7geBe4HWwMkxdR5y97XhvtoAvAtcHJadDWxx9/k1xC5NnBKENBWF7l58aMLMsszsv8zsczMrImgAO5hZWhXLbzz0xt33hm/b1rJuD2BbzDyAtTXEvTXuHMDeKrZ7D7AS+IuZrTKzW6tZZw/g85gYy8I4elYT15PAZeH7y9DRg6AEIU1H/K/pHxP8Eh/n7tnAaeH8qrqN6sIGoKOZZcXM610XK3b3Xe7+Y3f/EnAe8CMzm3CoOK76eoKuNQDC7q/ewLrYVcYt80dguJkNBb4ONKorwiQ5lCCkqWpHcN5hh5l1BG5P9gbd/XMgH7jDzFqa2UkEjflRM7Ovm9lxYWNfRHB576FLfDcBX4qp/gLwNTObYGYZBMlyP/B/1cReDLxIeA7F3b+oi7ilcVOCkKbqAYJ+9y3AB8Cb9bTd7wAnAVuBXwLPEzTOR2sA8DbBOYr3gd+4++yw7FfAT8Mrlv7Z3VcQdBP9muDzn0dwEvtADdt4EhiGupckpBvlRJLIzJ4Hlrt70o9gjlZ4kn05cIy7F6U6Hkk9HUGI1CEzG2tmx4b3KJwNXEDQv9+gmVkL4EfAc0oOckjSEoSZzQhv/llSRbmZ2UNmttLMFpnZ6Jiys81sRVhW3dUaIg3NMcBsgq6gh4Br3f2jlEZUAzNrQ3Be46vUw7kaaTyS1sVkZqcR/CeZ5e5DI8rPBW4AziW48ehBdx8XXob4CcGXtQCYB1zi7suSEqiIiERK2hGEu78LbKumygUEycPd/QOCa9S7A3nASndfFZ5Uey6sKyIi9SiVg/X1pOLNOgXhvKj546paiZldTTC0Am3atBkzcODAuo9URKSJmj9//hZ37xJVlsoEEXXDklczP5K7TwemA+Tm5np+fn7dRCci0gyY2edVlaUyQRRQ8S7TXgR3gLasYr6IiNSjVF7m+iowObya6URgZzho2DxgQDhscktgEjUPeCYiInUsaUcQZvYsMB7obMFjFW8HMgDc/VGCIYjPJRiAbC8wNSwrMbPrgbeANGCGuy9NVpwiIhItaQnC3S+podyB66ooe4MggYjIETp48CAFBQUUFxfXXFmavMzMTHr16kVGRkbCy+iRoyJNVEFBAe3ataNfv35U/ewjaQ7cna1bt1JQUED//v0TXk5DbYg0UcXFxXTq1EnJQTAzOnXqVOujSSUIkSZMyUEOOZLvghKEiIhEUoIQkaTYsWMHv/nNb45o2XPPPZcdO3bUbUBSa0oQIpIU1SWI0tLSyPmHvPHGG3To0CEJUR0dd6esrCzVYdQbJQgRSYpbb72Vzz77jJEjR3LzzTcze/ZsTj/9dC699FKGDRsGwDe+8Q3GjBnDkCFDmD59evmy/fr1Y8uWLaxZs4ZBgwZx1VVXMWTIEM4880z27dtXaVuvvfYa48aNY9SoUZxxxhls2rQJgN27dzN16lSGDRvG8OHDeemllwB48803GT16NCNGjGDChODR3nfccQf33ntv+TqHDh3KmjVrymP4/ve/z+jRo1m7di3XXnstubm5DBkyhNtvPzxC+rx58zj55JMZMWIEeXl57Nq1i1NPPZUFCxaU1znllFNYtGhR3e3oJNJlriLNwM9fW8qy9XX7HKDBPbK5/bwhVZbfddddLFmypLxxnD17NnPnzmXJkiXll1rOmDGDjh07sm/fPsaOHcu3vvUtOnXqVGE9n376Kc8++yy/+93v+Pa3v81LL73EZZddVqHOl7/8ZT744APMjMcee4y7776b++67j1/84he0b9+exYsXA7B9+3YKCwu56qqrePfdd+nfvz/btlU36HRgxYoVzJw5s/yI6M4776Rjx46UlpYyYcIEFi1axMCBA5k4cSLPP/88Y8eOpaioiNatWzNt2jSeeOIJHnjgAT755BP279/P8OHDE97PqaQEISL1Ji8vr8J1+A899BCvvPIKAGvXruXTTz+tlCD69+/PyJEjARgzZgxr1qyptN6CggImTpzIhg0bOHDgQPk23n77bZ577rnyejk5Obz22mucdtpp5XU6duxYY9x9+/blxBNPLJ9+4YUXmD59OiUlJWzYsIFly5ZhZnTv3p2xY8cCkJ2dDcDFF1/ML37xC+655x5mzJjBlClTatxeQ6EEIdIMVPdLvz61adOm/P3s2bN5++23ef/998nKymL8+PGR1+m3atWq/H1aWlpkF9MNN9zAj370I84//3xmz57NHXfcAQTnDOIv74yaB5Cenl7h/EJsLLFxr169mnvvvZd58+aRk5PDlClTKC4urnK9WVlZfPWrX+VPf/oTL7zwAo1pxGmdgxCRpGjXrh27du2qsnznzp3k5OSQlZXF8uXL+eCDD454Wzt37qRnz54APPnkk+XzzzzzTB5++OHy6e3bt3PSSSfx97//ndWrVwOUdzH169ePDz/8EIAPP/ywvDxeUVERbdq0oX379mzatIk///nPAAwcOJD169czb948AHbt2kVJSQkA06ZN48Ybb2Ts2LEJHbE0FEoQIpIUnTp14pRTTmHo0KHcfPPNlcrPPvtsSkpKGD58OD/72c8qdOHU1h133MHFF1/MqaeeSufOncvn//SnP2X79u0MHTqUESNG8M4779ClSxemT5/OhRdeyIgRI5g4cSIA3/rWt9i2bRsjR47kt7/9Lccff3zktkaMGMGoUaMYMmQIV1xxBaeccgoALVu25Pnnn+eGG25gxIgRfPWrXy0/ChkzZgzZ2dlMnTr1iD9jKiTtmdSpoAcGiRz28ccfM2jQoFSHIcD69esZP348y5cvp0WL1P0uj/pOmNl8d8+Nqq8jCBGRJJo1axbjxo3jzjvvTGlyOBI6SS0ikkSTJ09m8uTJqQ7jiDSudCYiIvVGCUJERCIpQYiISCQlCBERiaQEISINRtu2bYHgstCLLrooss748eNrvBv5gQceYO/eveXTGj78yCQ1QZjZ2Wa2wsxWmtmtEeU5ZvaKmS0ys7lmNjSm7IdmttTMlpjZs2aWmcxYRaTh6NGjBy+++OIRLx+fIBrq8OFVaSjDiictQZhZGvAIcA4wGLjEzAbHVbsNWODuw4HJwIPhsj2BG4Fcdx8KpAGTkhWriNS9W265pcLzIO644w7uu+8+du/ezYQJExg9ejTDhg3jT3/6U6Vl16xZw9Chwe/Fffv2MWnSJIYPH87EiRMrjMUUNez2Qw89xPr16zn99NM5/fTTgcPDhwPcf//9DB06lKFDh/LAAw+Ub0/DileWzPsg8oCV7r4KwMyeAy4AlsXUGQz8CsDdl5tZPzPrFhNbazM7CGQB65MYq0jT9udbYePiul3nMcPgnLuqLJ40aRI/+MEP+P73vw8EI6C++eabZGZm8sorr5Cdnc2WLVs48cQTOf/886t8ZvJvf/tbsrKyWLRoEYsWLWL06NHlZVHDbt94443cf//9vPPOOxWG3QCYP38+M2fOZM6cObg748aN45/+6Z/IycnRsOIRktnF1BNYGzNdEM6LtRC4EMDM8oC+QC93XwfcC3wBbAB2uvtfojZiZlebWb6Z5RcWFtbxRxCRIzVq1Cg2b97M+vXrWbhwITk5OfTp0wd357bbbmP48OGcccYZrFu3rvyXeJR33323vKEePnx4hUbvhRdeYPTo0YwaNYqlS5eybNmyqlYDwHvvvcc3v/lN2rRpQ9u2bbnwwgv5xz/+ASQ+rPhZZ53FsGHDuOeee1i6dCkQDCt+3XXXldfLycnhgw8+qJNhxeM/34oVKyoNK56ens7FF1/M66+/zsGDB+tsWPFkHkFE/RyIH/jpLuBBM1sALAY+AkrMLIfgaKM/sAP4g5ld5u5PV1qh+3RgOgRjMdVZ9CJNSTW/9JPpoosu4sUXX2Tjxo1MmhT0Ej/zzDMUFhYyf/58MjIy6NevX+Qw37Giji6qGna7OtWNPadhxStL5hFEAdA7ZroXcd1E7l7k7lPdfSTBOYguwGrgDGC1uxe6+0HgZeDkJMYqIkkwadIknnvuOV588cXyq5J27txJ165dycjI4J133uHzzz+vdh2nnXYazzzzDABLliwp71evathtqHqo8dNOO40//vGP7N27lz179vDKK69w6qmnJvx5mtuw4slMEPOAAWbW38xaEpxkfjW2gpl1CMsApgHvunsRQdfSiWaWZUGqnAB8nMRYRSQJhgwZwq5du+jZsyfdu3cH4Dvf+Q75+fnk5ubyzDPPMHDgwGrXce2117J7926GDx/O3XffTV5eHlD1sNsAV199Neecc075SepDRo8ezZQpU8jLy2PcuHFMmzaNUaNGJfx5mtuw4kkd7tvMzgUeILgKaYa732lm1wC4+6NmdhIwCyglOHl9pbtvD5f9OTARKCHoeprm7vur256G+xY5TMN9Nz81DSte2+G+kzqaq7u/AbwRN+/RmPfvAwOqWPZ24PaoMhERqWjWrFn85Cc/4f7776+zYcU13LeISBOQjGHFNdSGSBPWlJ4YKUfnSL4LShAiTVRmZiZbt25VkhDcna1bt5KZWbsRi9TFJNJE9erVi4KCAnQDqUDwg6FXr161WkYJQqSJysjIKL+LV+RIqItJREQiKUGIiEgkJQgREYmkcxAiIg1ESWkZu/eXsKs4+AveH2T3/hKKikvYXVzC7v0Hg7LicN7+g2RmpPHE1Lw6j0cJQkTkKJWVObsPBI32rrDRPtygh418eYMe1tt/sLz+rnDevoOlNW4rrYXRLjOddpnptG2VQbtW6bRtlZymXAlCRJotd2fvgdLyRvzwr/ZDv9APHm7Qw7Koebv3l9S4LTNo2yqddq3SaZeZQdvMdDpktaR3x6ywwc8IyjPTy18rzMtMp12rDDIzWlT5cKW6pgQhIo2Ou7O/pKxiN0yFX+gHYxr0yvOCLpygoS9L4D7CrJZpMQ13Bu0y0+nePpO2rcJf8ZnpFX7Vtz00HZMMsjLSaNGifhr2uqIEISIpdaCkjE1FxWwqKmbDzuB1654D4S/0g1X2yR8srbllb5XeotIv8T5tssob+Qq/zjPD7prM9ArJoG2rdNIaWcNeV5QgRCRpdu8vYePOfWzcuZ8NO/dVSAIbi4rZuLOYLbsPVFouPexnP9St0jYznR4dMg832mEDnh1XJ5h3+H3LdF2oeTSUIESk1srKnG17D7BxZ9DIbygqZtPOyo1/VN98TlYG3bIzOaZ9JsN6tqdbdibd22eGr605JjuT7Nbp9dbPLlVTghCRCmK7fA419PFJYPOu4kpdPGktjK7tWtEtO5PjurTly8d15pj2sY1/8JqZkZaiTya1pQQh0oxEdfmUJ4FqunwyM1rQvX1rumW3Iq9/x+AIILsVx7RvXZ4EOrdt1Wz76psqJQiRJqCqLp/4xj+qy6dDVgbHVNHlc0z7TLpnt1aXTzOlBCHSwB0oKWPzrooNfXwS2FRUucunhUG37Ex1+cgRU4IQSaGgyye28d9X6y6f3L45QVePunykjiU1QZjZ2cCDQBrwmLvfFVeeA8wAjgWKgSvcfUlY1gF4DBgKeFj2fjLjFalrO/YeYMm6ItZs3VPxCKCWXT6HptXlI/UpaQnCzNKAR4CvAgXAPDN71d2XxVS7DVjg7t80s4Fh/Qlh2YPAm+5+kZm1BLKSFatIXTiUDBav28nidTtYvG4na7ftKy9vYdC1XdDIR3X5HEoC6vKRhiKZRxB5wEp3XwVgZs8BFwCxCWIw8CsAd19uZv3MrBuwDzgNmBKWHQAqH2eLpMihZLBo3Q6WrNtZKRn07tia4T07cGleX4b1bM9xXdvSpZ26fKRxSWaC6AmsjZkuAMbF1VkIXAi8Z2Z5QF+gF1AKFAIzzWwEMB+4yd33xG/EzK4Grgbo06dPXX8GkRqTQZ+OWRWSwdCe2XTIapnCiEXqRjITRNRPpfjBU+4CHjSzBcBi4COgBMgARgM3uPscM3sQuBX4WaUVuk8HpgPk5uYmMOyWSNV27D0QdhHtVDKQZi+ZCaIA6B0z3QtYH1vB3YuAqQAWnHFbHf5lAQXuPies+iJBghCpM0oGItVLZoKYBwwws/7AOmAScGlshfBKpb3hOYZpwLth0igys7VmdoK7ryA4cb0MkSNUm2QwvFd7hvZoT/usjBRGLJJ6SUsQ7l5iZtcDbxFc5jrD3Zea2TVh+aPAIGCWmZUSJIArY1ZxA/BMeAXTKsIjDZGaxCeDRQU7KdiuZCBSW+bedLrtc3NzPT8/P9VhSD1KJBkM69meYb3aB91ESgYiFZjZfHfPjSrTndTSaMQmg8UFwWt8MhjRuwOXndhXyaChKzkA+7bB3m2VX/duhZJiwMBaBM/qtBbhdNS8qqathvL6rE8C62sR9zkTiSF83kVaBnSo+6s4lSCkQdq+5wBL1gdHBIfOGSgZNEDucGBPxcZ93/bKDX6FJLAdDuyqep3prSGjNeDB+t3D92XhdFnV081Vm65w86d1vlolCEm5mpJB305KBvWirAyKd9TQuG8LE8DWw/NKq7mHNbM9tO4IWR2hTRfockI43Qmycg6Xxb62PIpBEw4llOqSSIXphlg/gUQYnzjTWx35PquGEoTUq+17Kl9NpGSQBCX7o7tvyhv+qLLtVL5VKWRpMQ15J+j4Jeg5puK8+Ia+dQ6k1XMTU971o0eN1gUlCEkaJYM64A4Hdsc05FuDLpoKjfvWit03+7YFy1QlIytsyMNf8O2HV27cs+Let8oOG15pTpQgpHZKD8LWz2D/rpiTdFBUXMrKwj18unlP+LqbjUUHCA6Cje4dWnNW13YMGJbN8d2yGdCtHe1ahzedmQG7YP8eOHBonRGvsSfwyl+h0snCyOWrKKvPRq+sFPbtqKZxj2nkY7t2yg5Wvc7MDocb8rbdoMugyo17/GtG6/r6xNLIKUFItLJS2L4GNn8c/i2DwuWw5dPIBiubYGyU0bEzY7tF9wGfh38NUWTyqSnBUE1ZXGI7uDdIDlV14bRIj/nl3gk6HQtZY+Ma97hunMwO9d+FI82Kvl3NnTvsXBuTCMJksOWT8FLDUIe+0HUwO3t/hfsXtODzfZmA061dK/p1yqJ/p9b07ZhFn06taZORVvGkW/xr1DziTrpVV6fasmq2e7TLH03c6a2r78Zp1U5dONLgKEE0F+6we1PQ+Mcmg8LlFfur2/WAroOg/2nBa9dB0PkEaNWWzUXFXPTo+xT5Qe6fPIIxfTvSvrXOGYg0VUoQTdGerVAYczSweXnwWrzjcJ02XaDLQBj5ncOJoMtAaN0hcpU79x5k8oy5bNm9n99fdSIje0fXE5GmQwmiMSveGTT+8clgz+bDdTLbQ9fBMOSbweuhZNCmc8Kb2XughCuenMeqwj3MmDJWyUGkmVCCaAwO7IHCFWGX0KFksByKCg7XyWgDXQfC8WcGV7J0HRQkhHbHHFXf9oGSMq59+kM++mI7j1w6mi8PSDyxiEjjpgTRkJTsD64SqpAIlsH2zym/+iWtFXQ5HvqdEnYLhcmgfW9oUbc3B5WVOf/8h4X8/ZNCfnXhMM4Z1r1O1y8iDZsSRCqUlsC2z2JOFIevWz8DLw3qtEiHTgOgx6jD5wm6DIKO/aFF8h9q7+7c/upSXl24nlvOHsgleXqcq0hzowSRTGVlsGPN4ZPEh64a2vJJzPg1Fgxb0HUQDL7gcNdQx2MhPXVPL/vP//mEpz74nO+d9iWuHX9syuIQkdRRgqgL7lC0LvpegoN7D9dr3ydIAMedEXMJ6fEN7s7WGe+t5qG/rWRibm9uPWdgqsMRkRRRgqgNd9i9Oeb8QMy9BPuLDtdr1z24ZHTM1ODEcdfBwSiWrdqlLvYEvfxhAf/2+jLOGtKNO785FNPNWyLNlhJEVfZuCxr+8hvLwvf7th2u07ojdBsCwydWvJcgq2Pq4j4Kby/bxM0vLuLkYzvx4KRRpKdpREyR5kwJoqwM1s2vfFSwe+PhOq2yg8Z/0Hlx9xJ0aTLDI8xZtZXrfv8hQ3tkM31yLpkZyT8RLiINmxIEwJPnQcm+YBjkLifAcROCI4FDySC7R5NJBFGWrNvJtCfz6ZXTmplT82jbSl8LEUlygjCzs4EHgTTgMXe/K648B5gBHAsUA1e4+5KY8jQgH1jn7l9PSpAtWsB3/gDtewUD0tXxvQQN3eote5gycy7tMtN56spxdGyTuiunRKRhSVprGDbujwDnAIOBS8xscFy124AF7j4cmEyQTGLdBHycrBjL9T81vL+geSWHDTv3cdljc3CHp6aNo0eHhnU1lYikVjJbxDxgpbuvcvcDwHPABXF1BgN/BXD35UA/M+sGYGa9gK8BjyUxxmZr+54DTH58Ljv3HeTJK/I4tkvbVIckIg1MMhNET2BtzHRBOC/WQuBCADPLA/oCvcKyB4B/Acqq24iZXW1m+WaWX1hYWAdhN3179pcw9Yl5fL5tL7+bnMvQnu1THZKINEDJTBBRZ3XjH6d1F5BjZguAG4CPgBIz+zqw2d3n17QRd5/u7rnuntulS5ejjbnJ219Syveems/idTt5+JJRnHRsp1SHJCINVI0nqcPG+g13r/aXfIQCoHfMdC9gfWwFdy8CpobbMWB1+DcJON/MzgUygWwze9rdL6tlDBKjtMz54fMLeG/lFu69eARnDjkm1SGJSAOWyBHEJOBTM7vbzAbVYt3zgAFm1t/MWobreTW2gpl1CMsApgHvunuRu/8/d+/l7v3C5f6m5HB03J2f/nExbyzeyE+/NoiLxvSqeSERadZqPIJw98vMLBu4BJhpZg7MBJ51913VLFdiZtcDbxFc5jrD3Zea2TVh+aPAIGCWmZUCy4Arj/oTSaS731rBs3PXcv3pxzHt1C+lOhwRaQTMPf60QBUVzToDlwE/ILj09DjgIXf/ddKiq6Xc3FzPz89PdRgNzvR3P+Pf31jOpeP6cOc3NL6SiBxmZvPdPTeqrMYuJjM7z8xeAf4GZAB57n4OMAL45zqNVOrcC/PW8u9vLOfrw7vziwuUHEQkcYncSX0x8J/u/m7sTHffa2ZXJCcsqQtvLtnIrS8v4rTju3D/t0eS1kLJQUQSl0iCuB3YcGjCzFoD3dx9jbv/NWmRyVH5v5VbuPHZjxjRuwOPXjaalunN6y5xETl6ibQaf6DizWql4TxpoBau3cFVs/Lp37kNM6eMJaulBt8TkdpLJEGkh0NlABC+14huDdTKzbuYMnMuHdu2ZNaVeXTI0j+ViByZRBJEoZmdf2jCzC4AtiQvJDlS63bs4/LH55LWogVPXTGObtmZqQ5JRBqxRPoergGeMbOHCYbPWEsw8qo0IFt37+fyx+ewe38Jz199Ev06t0l1SCLSyCVyo9xnwIlm1pbgvokqb46T1NhVfJDvzpzL+h37eOrKcQzukZ3qkESkCUjo7KWZfQ0YAmQeuo7e3f8tiXFJgooPlnLVrHyWb9jF7ybnMrZf43wetog0PIkM1vcokAWcTvBshouAuUmOSxJQUlrGDc9+xJzV23hg4khOH9g11SGJSBOSyEnqk919MrDd3X8OnETFUVolBcrKnFtfXsz/LNvEHecN4YKR8Y/aEBE5OokkiOLwda+Z9QAOAv2TF5LUxN359zc+5sX5BfzgjAF89+R+qQ5JRJqgRM5BvGZmHYB7gA8JHvrzu2QGJdX7zezPeOy91Uw5uR83TRiQ6nBEpImqNkGYWQvgr+6+A3jJzF4HMt19Z30EJ5U9M+dz7nlrBd8c1ZN//fpgDb4nIklTbRdT+BS5+2Km9ys5pM7ri9bz0z8u4SsDu3L3RcNpocH3RCSJEjkH8Rcz+5bpp2pK/f2TQn74/AJy++bwyKWjyUjT4HsiklyJnIP4EdAGKDGzYoK7qd3ddTdWPZn/+XaueWo+x3Vtx2PfHUvrlmmpDklEmoFE7qRuVx+BSLQVG3dxxRPz6JbdillX5NG+dUaqQxKRZiKRG+VOi5of/wAhqXtrt+3l8sfnkJnRgqeuHEeXdq1SHZKINCOJdDHdHPM+E8gD5gNfSUpEAsDmXcVc9vgc9peU8cL3TqJ3x6xUhyQizUyNZzrd/byYv68CQ4FNiazczM42sxVmttLMbo0ozzGzV8xskZnNNbOh4fzeZvaOmX1sZkvN7KbafrDGbOe+g3x3xjwKd+1n5tSxnHCMevlEpP4dyaUwBQRJolpmlgY8ApwDDAYuMbPBcdVuAxa4+3CCIcQfDOeXAD9290HAicB1Ecs2SfsOlDLtyXms3LyL/7p8DKP75KQ6JBFpphI5B/FrgrunIUgoI4GFCaw7D1jp7qvC9TwHXAAsi6kzGPgVgLsvN7N+ZtbN3TcQPgfb3XeZ2cdAz7hlm5yDpWVc9/sPyf98Ow9fMppTB3RJdUgi0owlcg4iP+Z9CfCsu/9vAsv1JHi40CEFwLi4OguBC4H3zCwP6Av0IqYLy8z6AaOAOVEbMbOrgasB+vTpk0BYDVNZmfPPf1jI35Zv5t+/OYyvDe+e6pBEpJlLJEG8CBS7eykEXUdmluXue2tYLurGOo+bvgt40MwWAIuBjwiSEOG22gIvAT9w96Kojbj7dGA6QG5ubvz6GwV35+evLeVPC9Zz81kncOm4xpvoRKTpSCRB/BU4A9gdTrcG/gKcXMNyBVQcFrwXsD62QtjoTwUI79ReHf5hZhkEyeEZd385gTgbrQf/+ilPvv85V53an++PPzbV4YiIAImdpM5090PJgfB9ItdczgMGmFl/M2sJTAJeja1gZh3CMoBpwLvuXhQmi8eBj939/kQ+SGP1xP+u5oG3P+XiMb247dxBGnxPRBqMRBLEHjMbfWjCzMYA+2payN1LgOuBt4CPgRfcfamZXWNm14TVBgFLzWw5wdVOhy5nPQW4HPiKmS0I/85N+FM1En/8aB13vLaMMwd341cXDlNyEJEGJZEuph8AfzCzQ91D3YGJiazc3d8A3oib92jM+/eBSg80cPf3iD6H0WT8bfkmfvyHhZz0pU48dMko0jX4nog0MImMxTTPzAYCJxA02svd/WDSI2vC5q7exrVPf8jg7tlMnzyGzAwNviciDU+NP1vN7DqgjbsvcffFQFsz+37yQ2ualq0v4son59EzpzVPTB1Lu0wNviciDVMi/RpXhU+UA8DdtwNXJS2iJmzNlj1MnjGXtq3SeerKcXRqq8H3RKThSiRBtIh9WFA4hEbLaupLhE1FweB7Ze48deU4enZoneqQRESqlchJ6reAF8zsUYIb3a4B/pzUqJqYHXsPcPnjc9i+5wDPXn0ix3Vtm+qQRERqlEiCuIVgKItrCU5Sf0RwJZMkYO+BEqY+MY81W/byxBVjGd6rQ6pDEhFJSCLDfZcBHwCrgFxgAsF9DVKD/SWlfO+p+Sxcu4NfXzqKk4/tnOqQREQSVuURhJkdT3D38yXAVuB5AHc/vX5Ca9xKy5wfvbCQf3y6hbsvGs5ZQ45JdUgiIrVSXRfTcuAfwHnuvhLAzH5YL1E1cu7Oz/60hP9etIGfnDuIb+f2rnkhEZEGproupm8BG4F3zOx3ZjaBJn53c1259y8r+P2cL/j++GO56rQvpTocEZEjUmWCcPdX3H0iMBCYDfwQ6GZmvzWzM+spvkbnsX+s4pF3PuOSvD7cfNYJqQ5HROSIJXKSeo+7P+PuXycYsnsBUOn50gJ/yF/LL//7Y742rDu//MZQDb4nIo1arUaIc/dt7v5f7v6VZAXUWP1l6UZufXkxpw7ozP0TR5DWQslBRBo3DSFaB97/bCvXP/sRw3q259HLxtAqXYPviUjjpwRxlBYX7OSqWfn07ZjFzCljadMqkXsPRUQaPiWIo/BZ4W6+O3MuHbIyeOrKceS00RBVItJ0KEEcofU79nH5Y3NoYfDUleM4pn1mqkMSEalTShBHYNueYPC9XcUlPHlFHv07t0l1SCIidU4d5rW0e38JU2bOpWD7Pp66chxDerRPdUgiIkmhBFELxQdLuXpWPkvXFzH98jHk9e+Y6pBERJImqV1MZna2ma0ws5VmVunmOjPLMbNXzGyRmc01s6GJLlvfSkrLuOm5j/i/z7Zy38UjmDCoW6pDEhFJqqQliPDJc48A5wCDgUvMbHBctduABe4+HJgMPFiLZeuNu3PbK4t5a+kmbj9vMN8Y1TNVoYiI1JtkHkHkASvdfZW7HwCeAy6IqzMY+CuAuy8H+plZtwSXrRfuzq/+vJwX8gu4ccIApp7SPxVhiIjUu2QmiJ7A2pjpgnBerIXAhQBmlgf0JRjvKZFlCZe72szyzSy/sLCwjkI/7NG/r2L6u6v47kl9+eEZA+p8/SIiDVUyE0TUYEQeN30XkGNmC4AbCB5nWpLgssFM9+nunuvuuV26dDmKcCt7du4X/Meby7lgZA9uP2+IBt8TkWYlmVcxFQCxT8rpBayPreDuRcBUAAta39XhX1ZNyybbG4s38JNXFjP+hC7ce/EIWmjwPRFpZpJ5BDEPGGBm/c2sJcHjS1+NrWBmHcIygGnAu2HSqHHZZPrHp4Xc9NxHjO6Tw2+/M4aMNN1PKCLNT9KOINy9xMyuB94C0oAZ7r7UzK4Jyx8FBgGzzKwUWAZcWd2yyYo11kdfbOd7T83n2C5teXzKWFq31MisItI8mXtk136jlJub6/n5+Ue8/CebdvHt/3qf9q0z+MM1J9G1ncZXEpGmzczmu3tuVJn6TkJrt+3l8sfn0DKtBU9fOU7JQUSaPSUIoHDXfi5/fA77DpQy68o8enfMSnVIIiIp1+zHYtpVfJDvzpjLpqL9PD1tHAOPyU51SCIiDUKzTxCZGWkM6ZHNLecMZEzfnFSHIyLSYDT7BJGR1oJ7Lh6R6jBERBocnYMQEZFIShAiIhJJCUJERCIpQYiISCQlCBERiaQEISIikZQgREQkkhKEiIhEUoIQEZFIShAiIhJJCUJERCIpQYiISCQlCBERiaQEISIikZQgREQkUlIThJmdbWYrzGylmd0aUd7ezF4zs4VmttTMpsaU/TCct8TMnjUzPSRaRKQeJS1BmFka8AhwDjAYuMTMBsdVuw5Y5u4jgPHAfWbW0sx6AjcCue4+FEgDJiUrVhERqSyZRxB5wEp3X+XuB4DngAvi6jjQzswMaAtsA0rCsnSgtZmlA1nA+iTGKiIicZKZIHoCa2OmC8J5sR4GBhE0/ouBm9y9zN3XAfcCXwAbgJ3u/peojZjZ1WaWb2b5hYWFdf0ZRESarWQmCIuY53HTZwELgB7ASOBhM8s2sxyCo43+YVkbM7ssaiPuPt3dc909t0uXLnUVu4hIs5fMBFEA9I6Z7kXlbqKpwMseWAmsBgYCZwCr3b3Q3Q8CLwMnJzFWERGJk8wEMQ8YYGb9zawlwUnmV+PqfAFMADCzbsAJwKpw/olmlhWen5gAfJzEWEVEJE56slbs7iVmdj3wFsFVSDPcfamZXROWPwr8AnjCzBYTdEnd4u5bgC1m9iLwIcFJ64+A6cmKVUREKjP3+NMCjVdubq7n5+enOgwRkUbDzOa7e25Ume6kFhGRSEoQIiISSQlCREQiKUGIiEgkJQgREYmkBCEiIpGUIEREJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEgkJQgREYmkBCEiIpGUIEREJJIShIiIRFKCEBGRSEoQIiISSQlCREQiKUGIiEikpCYIMzvbzFaY2UozuzWivL2ZvWZmC81sqZlNjSnrYGYvmtlyM/vYzE5KZqwiIlJR0hKEmaUBjwDnAIOBS8xscFy164Bl7j4CGA/cZ2Ytw7IHgTfdfSAwAvg4WbGKiEhlyTyCyANWuvsqdz8APAdcEFfHgXZmZkBbYBtQYmbZwGnA4wDufsDddyQxVhERiZPMBNETWBszXRDOi/UwMAhYDywGbnL3MuBLQCEw08w+MrPHzKxN1EbM7Gozyzez/MLCwjr/ECIizVUyE4RFzPO46bOABUAPYCTwcHj0kA6MBn7r7qOAPUClcxgA7j7d3XPdPbdLly51FLqIiCQzQRQAvWOmexEcKcSaCrzsgZXAamBguGyBu88J671IkDBERKSeJDNBzAMGmFn/8MTzJODVuDpfABMAzKwbcAKwyt03AmvN7ISw3gRgWRJjFRGROOnJWrG7l5jZ9cBbQBoww92Xmtk1YfmjwC+AJ8xsMUGX1C3uviVcxQ3AM2FyWUVwtCEiIvXE3ONPCzReubm5np+fn+owREQaDTOb7+65UWW6k1pERCIpQYiISCQlCBERiaQEISIikZQgREQkkhKEiIhEUoIQEZFIShAiIhJJCUJERCI1qTupzawQ+PwIF+8MbKmxVv1TXLWjuGpHcdVOU4yrr7tHDoXdpBLE0TCz/KpuN08lxVU7iqt2FFftNLe41MUkIiKRlCBERCSSEsRh01MdQBUUV+0ortpRXLXTrOLSOQgREYmkIwgREYmkBCEiIpGaVYIws7PNbIWZrTSzWyPKzcweCssXmdnoBhLXeDPbaWYLwr9/rae4ZpjZZjNbUkV5qvZXTXGlan/1NrN3zOxjM1tqZjdF1Kn3fZZgXPW+z8ws08zmmtnCMK6fR9RJxf5KJK6UfMfCbaeZ2Udm9npEWd3uL3dvFn8Ez8X+DPgS0BJYCAyOq3Mu8GeC52OfCMxpIHGNB15PwT47DRgNLKmivN73V4JxpWp/dQdGh+/bAZ80kO9YInHV+z4L90Hb8H0GMAc4sQHsr0TiSsl3LNz2j4DfR22/rvdXczqCyANWuvsqdz8APAdcEFfnAmCWBz4AOphZ9wYQV0q4+7vAtmqqpGJ/JRJXSrj7Bnf/MHy/C/gY6BlXrd73WYJx1btwH+wOJzPCv/irZlKxvxKJKyXMrBfwNeCxKqrU6f5qTgmiJ7A2ZrqAyv9JEqmTirgATgoPef9sZkOSHFOiUrG/EpXS/WVm/YBRBL8+Y6V0n1UTF6Rgn4XdJQuAzcD/uHuD2F8JxAWp+Y49APwLUFZFeZ3ur+aUICxiXvyvgkTq1LVEtvkhwXgpI4BfA39MckyJSsX+SkRK95eZtQVeAn7g7kXxxRGL1Ms+qyGulOwzdy9195FALyDPzIbGVUnJ/kogrnrfX2b2dWCzu8+vrlrEvCPeX80pQRQAvWOmewHrj6BOvcfl7kWHDnnd/Q0gw8w6JzmuRKRif9UolfvLzDIIGuFn3P3liCop2Wc1xZXq75i77wBmA2fHFaX0O1ZVXCnaX6cA55vZGoKu6K+Y2dNxdep0fzWnBDEPGGBm/c2sJTAJeDWuzqvA5PBKgBOBne6+IdVxmdkxZmbh+zyCf7etSY4rEanYXzVK1f4Kt/k48LG7319FtXrfZ4nElYp9ZmZdzKxD+L41cAawPK5aKvZXjXGlYn+5+/9z917u3o+gnfibu18WV61O91f6kYfbuLh7iZldD7xFcOXQDHdfambXhOWPAm8QXAWwEtgLTG0gcV0EXGtmJcA+YJKHlywkk5k9S3C1RmczKwBuJzhhl7L9lWBcKdlfBL/wLgcWh/3XALcBfWJiS8U+SySuVOyz7sCTZpZG0MC+4O6vp/r/ZIJxpeo7Vkky95eG2hARkUjNqYtJRERqQQlCREQiKUGIiEgkJQgREYmkBCEiIpGUIERqwcxK7fAIngssYvTdo1h3P6tihFqRVGg290GI1JF94RAMIk2ejiBE6oCZrTGz/7DgOQJzzey4cH5fM/urBWPz/9XM+oTzu5nZK+FgbwvN7ORwVWlm9jsLnkPwl/BOXpGUUIIQqZ3WcV1ME2PKitw9D3iYYNRNwvez3H048AzwUDj/IeDv4WBvo4Gl4fwBwCPuPgTYAXwrqZ9GpBq6k1qkFsxst7u3jZi/BviKu68KB8bb6O6dzGwL0N3dD4bzN7h7ZzMrBHq5+/6YdfQjGFp6QDh9C5Dh7r+sh48mUomOIETqjlfxvqo6UfbHvC9F5wklhZQgROrOxJjX98P3/0cw8ibAd4D3wvd/Ba6F8ofTZNdXkCKJ0q8TkdppHTMiKsCb7n7oUtdWZjaH4IfXJeG8G4EZZnYzUMjh0TVvAqab2ZUERwrXAikfKl0kls5BiNSB8BxErrtvSXUsInVFXUwiIhJJRxAiIhJJRxAiIhJJCUJERCIpQYiISCQlCBERiaQEISIikf4/Av9RRaof328AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['aspact_train_acc'], label='train accuracy')\n",
    "plt.plot(history['aspact_valid_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0.85, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea406efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:05<00:00, 16.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AT       0.80      0.86      0.83      1755\n",
      "         NAT       0.98      0.97      0.97     11218\n",
      "\n",
      "    accuracy                           0.95     12973\n",
      "   macro avg       0.89      0.91      0.90     12973\n",
      "weighted avg       0.95      0.95      0.95     12973\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.49      0.58      0.53       315\n",
      "    Positive       0.88      0.79      0.83       909\n",
      "    Negative       0.75      0.79      0.77       531\n",
      "\n",
      "    accuracy                           0.75      1755\n",
      "   macro avg       0.70      0.72      0.71      1755\n",
      "weighted avg       0.77      0.75      0.76      1755\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_classification_report(test_data_loader, model, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)   \n",
    "    \n",
    "    model.eval()\n",
    "    final_pred_aspect_tags = []\n",
    "    final_true_aspect_tags = []\n",
    "    final_pred_polarity_tags = []\n",
    "    final_true_polarity_tags = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "            pred_aspect_tags, pred_polarity_tags, loss = model(**data)\n",
    "            \n",
    "            final_pred_aspect_tags.extend(torch.argmax(pred_aspect_tags, dim=2))\n",
    "            final_pred_polarity_tags.extend(torch.argmax(pred_polarity_tags, dim=2))\n",
    "            final_true_aspect_tags.extend(data['aspect_tags'])\n",
    "            final_true_polarity_tags.extend(data['polarity_tags'])\n",
    "            \n",
    "    final_pred_aspect_tags = torch.stack(final_pred_aspect_tags).cpu()\n",
    "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
    "    final_true_aspect_tags = torch.stack(final_true_aspect_tags).cpu()\n",
    "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
    "    \n",
    "    # Remove the special -100 tokens \n",
    "    final_pred_aspect_tags = final_pred_aspect_tags[final_true_aspect_tags!=-100]\n",
    "    final_true_aspect_tags = final_true_aspect_tags[final_true_aspect_tags!=-100]\n",
    "    final_pred_polarity_tags = final_pred_polarity_tags[final_true_polarity_tags!=-100]\n",
    "    final_true_polarity_tags = final_true_polarity_tags[final_true_polarity_tags!=-100]\n",
    "        \n",
    "    print(classification_report(final_true_aspect_tags, final_pred_aspect_tags, \n",
    "                                target_names=encoder.classes_))\n",
    "    \n",
    "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
    "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
    "    \n",
    "get_classification_report(test_data_loader, model, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(test_dataset, test_data_loader, model, num=5, model_path=None):\n",
    "    if model_path is not None: # load the saved model\n",
    "        print('Loading saved model from: {}'.format(model_path))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model = to_device(model, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num):\n",
    "            \n",
    "            data = next(iter(test_data_loader))\n",
    "            \n",
    "            pred_aspect_tags, pred_polarity_tags, _ = model(**data)\n",
    "            \n",
    "            \n",
    "            input_ids = data['input_ids']\n",
    "            pred_aspect_tags = torch.argmax(pred_aspect_tags, dim=2)\n",
    "            pred_polarity_tags = torch.argmax(pred_polarity_tags, dim=2)\n",
    "            true_aspect_tags = data['aspect_tags']\n",
    "            true_polarity_tags = data['polarity_tags']\n",
    "            mask = data['attention_mask']\n",
    "            \n",
    "            # Randomly pick a test data from this batch\n",
    "            #\n",
    "            rng = np.random.default_rng()\n",
    "            idx = rng.integers(low=0, high=pred_aspect_tags.shape[0],size=1)[0]\n",
    "#             idx = np.random.randint(0,pred_aspect_tags.shape[0],size=1)[0]\n",
    "\n",
    "            ids_array = input_ids[idx].cpu().numpy()\n",
    "            pred_aspect_array = pred_aspect_tags[idx].cpu().numpy()\n",
    "            true_aspect_array = true_aspect_tags[idx].cpu().numpy()\n",
    "            pred_polarity_array = pred_polarity_tags[idx].cpu().numpy()\n",
    "            true_polarity_array = true_polarity_tags[idx].cpu().numpy()\n",
    "            mask_array = mask[idx].cpu().numpy()\n",
    "\n",
    "            # Remove the padding as we do not want to print them\n",
    "            #\n",
    "            mask_array = np.logical_not(mask_array)\n",
    "\n",
    "            # Only print the unpadded portion\n",
    "            ids_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, ids_array))\n",
    "            pred_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       pred_aspect_array))\n",
    "            true_aspect_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                       true_aspect_array))\n",
    "            pred_polarity_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                         pred_polarity_array))\n",
    "            true_polarity_unpadded = np.ma.compressed(np.ma.masked_where(mask_array, \n",
    "                                                                         true_polarity_array))\n",
    "            \n",
    "            aspect_pred = pred_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            aspect_true = true_aspect_unpadded[true_aspect_unpadded!=-100]\n",
    "            polarity_pred = pred_polarity_unpadded[true_polarity_unpadded!=-100]\n",
    "            polarity_true = true_polarity_unpadded[true_polarity_unpadded!=-100]\n",
    "            \n",
    "            aspect_acc = np.sum(aspect_pred == aspect_true) / len(aspect_pred)\n",
    "            polarity_acc = np.sum(polarity_pred == polarity_true) / len(polarity_pred)\n",
    "            \n",
    "            # Remove begin and end\n",
    "            ids_unpadded = ids_unpadded[1:-1]\n",
    "            pred_aspect_unpadded = pred_aspect_unpadded[1:-1]\n",
    "            true_aspect_unpadded = true_aspect_unpadded[1:-1]\n",
    "            pred_polarity_unpadded = pred_polarity_unpadded[1:-1]\n",
    "            true_polarity_unpadded = true_polarity_unpadded[1:-1]\n",
    "            \n",
    "            true_aspect_unpadded = np.where(true_aspect_unpadded==-100, 1, true_aspect_unpadded)\n",
    "\n",
    "            # let's replace 2 back to -1 for presentation\n",
    "            pred_polarity_unpadded = np.where(pred_polarity_unpadded == 2, -1, \n",
    "                                              pred_polarity_unpadded)\n",
    "            true_polarity_unpadded = np.where(true_polarity_unpadded == 2, -1, \n",
    "                                              true_polarity_unpadded)\n",
    "            \n",
    "            orig_sentence = np.array(tokenizer.convert_ids_to_tokens(ids_unpadded))\n",
    "            decoded_aspect_tags = encoder.inverse_transform(true_aspect_unpadded)\n",
    "            aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "            \n",
    "            pred_polarity_unpadded = pred_polarity_unpadded[aspect_tag_indices]\n",
    "            true_polarity_unpadded = true_polarity_unpadded[aspect_tag_indices]\n",
    "\n",
    "            print(\"Aspect Acc: {:.2f}%\".format(aspect_acc*100))\n",
    "            print(\"Polarity Acc: {:.2f}%\".format(polarity_acc*100))\n",
    "            print(\"Predicted Aspect:\")\n",
    "            print(encoder.inverse_transform(pred_aspect_unpadded))\n",
    "            print(\"True Aspect:\")\n",
    "            print(decoded_aspect_tags)\n",
    "            print(\"Predicted Polarity:\")\n",
    "            print(pred_polarity_unpadded)\n",
    "            print(\"True Polarity:\")\n",
    "            print(true_polarity_unpadded)\n",
    "            print(\"Sentence:\")\n",
    "            print(orig_sentence)   \n",
    "            print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_test(test_dataset, test_data_loader, model, num=10, model_path=MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24aac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(idx=0):\n",
    "\n",
    "\n",
    "    train_dataset = SentenceTagDataset(tokenizer=tokenizer,\n",
    "                                       sentences=train_sentences,\n",
    "                                       aspect_tags=train_aspect_tags,\n",
    "                                       polarity_tags=train_polarity_tags,\n",
    "                                       aspect_term_tag=np.where(encoder.classes_ == \"AT\")[0].item())\n",
    "\n",
    "    train_data_loader = DeviceDataLoader(torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=32), device)    \n",
    "\n",
    "    data = train_dataset[idx]\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = np.logical_not(data['attention_mask'])\n",
    "    aspect_tags = data['aspect_tags']\n",
    "    polarity_tags = data['polarity_tags']\n",
    "    \n",
    "    print(\"*** Raw Data\")\n",
    "    print(\"*** input_ids\")\n",
    "    print(input_ids)\n",
    "    print(\"*** aspect_tags\")\n",
    "    print(aspect_tags)\n",
    "    print(\"*** polarity_tags\")\n",
    "    print(polarity_tags)\n",
    "    print()\n",
    "    \n",
    "    input_ids = np.ma.compressed(np.ma.masked_where(attention_mask, input_ids))\n",
    "    aspect_tags = np.ma.compressed(np.ma.masked_where(attention_mask, aspect_tags))\n",
    "    polarity_tags = np.ma.compressed(np.ma.masked_where(attention_mask, polarity_tags))\n",
    "    \n",
    "#     input_ids = input_ids[(input_ids!=101) & (input_ids!=102)]\n",
    "    \n",
    "    aspect_tags = np.where(aspect_tags==-100, 1, aspect_tags)\n",
    "#     polarity_tags = np.where(polarity_tags==-100, 0, polarity_tags)\n",
    "    \n",
    "#     aspect_tags = aspect_tags[aspect_tags!=-100]\n",
    "    polarity_tags = polarity_tags[polarity_tags!=-100]\n",
    "    \n",
    "    orig_sentence = np.array(train_dataset.tokenizer.convert_ids_to_tokens(input_ids))\n",
    "    decoded_aspect_tags = encoder.inverse_transform(aspect_tags)\n",
    "    \n",
    "    aspect_tag_indices = decoded_aspect_tags == \"AT\"\n",
    "    \n",
    "    print(orig_sentence)\n",
    "    print(decoded_aspect_tags)  \n",
    "    print(polarity_tags)  \n",
    "    \n",
    "    print(\"Aspect Terms: {}\".format(orig_sentence[aspect_tag_indices]))\n",
    "\n",
    "test_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b0500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}