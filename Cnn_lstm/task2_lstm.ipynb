{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVlBRwsjo3A9",
        "outputId": "c73353d2-d0e0-46ab-cb7b-742f72aa0104"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext\n",
        "#!pip install transformers\n",
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "#!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Pp-VjL_5Xw",
        "outputId": "a043786f-12ea-4b95-f6bb-4f7c9288537a"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\"\n",
        "VALID_SIZE = .2\n",
        "MODEL_PATH = \"model_task2.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f_ihgOgKQQ5e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.optim import AdamW\n",
        "from fasttext import load_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing, model_selection\n",
        "from torch import LongTensor\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Dataset/data/restaurants_laptop_train_with_pos_task2_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of aspect tags: 2\n",
            "num of polarity tags: 4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.polarity = df.polarity.replace(-1,2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
        "\n",
        "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
        "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
        "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
        "\n",
        "polarity_unique_values = df.polarity.unique()\n",
        "\n",
        "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
        "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
        "\n",
        "np.where(encoder.classes_ == \"AT\")[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "idx = 0\n",
        "print(sentences[idx])\n",
        "print(aspect_tags[idx])\n",
        "print(polarity_tags[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2448bddb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_new_aspect_cluster(left, right, aspect_term, polarity, sentence):\n",
        "\n",
        "    if len(polarity) == 0:\n",
        "        polarity = 0\n",
        "    else:\n",
        "        polarity = int(sum(polarity)/len(polarity))\n",
        "   \n",
        "    left.extend(aspect_term)\n",
        "    left.extend(right)\n",
        "    return {\n",
        "        \"local_context\":left,\n",
        "        \"global_context\":sentence,\n",
        "        \"aspect_term\":aspect_term,\n",
        "        \"polarity\":polarity,\n",
        "    }\n",
        "\n",
        "def chop(sentence, aspect_tag, polarity_tag):\n",
        "    ret_aspect_clusters = []\n",
        "#     ret_aspect_clusters = {\n",
        "#         \"context\":list(),\n",
        "#         \"aspect_term\":list(),\n",
        "#         \"polarity\":list(),\n",
        "#     }\n",
        "    left = []\n",
        "    right = []\n",
        "    aspect_term = []\n",
        "    polarity = []\n",
        "    doing_left = True\n",
        "    doing_right = False\n",
        "    doing_aspect = False\n",
        "    for i in range(len(sentence)):\n",
        "        # check if the current token is an aspect term\n",
        "        if aspect_tag[i] == 0:\n",
        "            if doing_left:\n",
        "                doing_aspect = True\n",
        "                doing_left = False\n",
        "            elif doing_right:\n",
        "                doing_right = False\n",
        "                doing_aspect = True\n",
        "                # Now, need to save the previous aspect term cluster\n",
        "                ret_aspect_clusters.append(get_new_aspect_cluster(\n",
        "                    left, right, aspect_term, polarity, sentence))\n",
        "                left = right\n",
        "                right = []\n",
        "                aspect_term = []\n",
        "                polarity = []\n",
        "            aspect_term.append(sentence[i])\n",
        "            polarity.append(polarity_tag[i])\n",
        "        else:\n",
        "            if doing_left:\n",
        "                left.append(sentence[i])\n",
        "            elif doing_right:\n",
        "                right.append(sentence[i])\n",
        "            else:\n",
        "                doing_aspect = False\n",
        "                doing_right = True\n",
        "                right.append(sentence[i])\n",
        "                \n",
        "    ret_aspect_clusters.append(get_new_aspect_cluster(\n",
        "        left, right, aspect_term, polarity, sentence))\n",
        "    \n",
        "    return ret_aspect_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bb3ba0d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_aspect_clusters = []\n",
        "for i in range(len(sentences)):\n",
        "    all_aspect_clusters.extend(chop(sentences[i], aspect_tags[i], polarity_tags[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MIElcOeLQVR0"
      },
      "outputs": [],
      "source": [
        "# generate word_index list\n",
        "def build_vocab(df):\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(sorted(set(df.text.values))):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "def create_train_data_restaurant(all_aspect_clusters,  word_idx, sent_len=83):\n",
        "\n",
        "    train_X_local = np.zeros((len(all_aspect_clusters), sent_len), np.int16)\n",
        "    train_X_global = np.zeros((len(all_aspect_clusters), sent_len), np.int16)\n",
        "\n",
        "    train_y = np.zeros(len(all_aspect_clusters), np.int16)\n",
        "\n",
        "    # iterate the asoect\n",
        "    for sx, sent in enumerate(all_aspect_clusters):\n",
        "        train_y[sx] = sent['polarity']\n",
        "        global_sentence = sent['global_context']\n",
        "        local_sentence = sent['local_context']\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(global_sentence):\n",
        "                train_X_global[sx, wx] = word_idx[word]\n",
        "\n",
        "            for wx, word in enumerate(local_sentence):\n",
        "                train_X_local[sx, wx] = word_idx[word]\n",
        "\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    return train_X_local, train_X_global, train_y\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, label, num_label):\n",
        "    pred = pred.view(-1,num_label)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1, 2], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "    return acc, f1, cm\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, num_classes=3, alpha = 0.6):\n",
        "        super(Model, self).__init__()\n",
        "  \n",
        "        self.embed = nn.Embedding.from_pretrained(torch.tensor(gen_emb, dtype=torch.float))\n",
        "\n",
        "        self.lstm = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dense = nn.Linear(150*2, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "    def forward(self, x_train_local, x_train_global):\n",
        "        x_local = self.embed(x_train_local)\n",
        "        \n",
        "        local_seq_lengths = np.sum(np.array(x_train_local) !=0, axis=1)\n",
        "   \n",
        "        x_emb_l = torch.nn.utils.rnn.pack_padded_sequence(x_local, local_seq_lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        _, (h_n, _) = self.lstm(x_emb_l.float())\n",
        "\n",
        "        h_n = torch.cat([h_n[-2,:,:], h_n[-1,:,:]], dim=1)\n",
        "\n",
        "        x_global = self.embed(x_train_global)\n",
        "\n",
        "\n",
        "        global_seq_lengths = np.sum(np.array(x_train_global) !=0, axis=1)\n",
        "\n",
        "        x_emb_g = torch.nn.utils.rnn.pack_padded_sequence(x_global, global_seq_lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        _, (h_n_g,_) = self.lstm(x_emb_g.float())\n",
        "\n",
        "        h_n_g = torch.cat([h_n_g[-2,:,:], h_n_g[-1,:,:]], dim=1)\n",
        "\n",
        "        avg_pool = torch.div(torch.add(h_n * (1 - self.alpha), h_n_g * self.alpha), 2)\n",
        "        out = self.dropout(avg_pool)\n",
        "\n",
        "        out = self.dense(out)\n",
        "\n",
        "        out = torch.nn.functional.log_softmax(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_indx = build_vocab(df)\n",
        "    \n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "local_context, global_context, y = create_train_data_restaurant(all_aspect_clusters ,word_indx, sent_len=85)\n",
        "\n",
        "X_l_train, X_l_valid, X_g_train, X_g_valid,  y_train, y_valid = train_test_split(local_context, global_context, y, test_size=VALID_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4641\n",
            "valid samples:1161\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 0), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (embed): Embedding(6395, 300)\n",
            "  (lstm): LSTM(300, 150, batch_first=True, bidirectional=True)\n",
            "  (dense): Linear(in_features=300, out_features=3, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpha = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4641\n",
            "valid samples:1161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.22it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.063 valid_loss:1.031\n",
            "\ttrain_acc:51.54% valid_acc:52.54%\n",
            "\ttrain_f1:0.362 valid_f1:0.363\n",
            "\ttrain_confusion_matrix:\n",
            "[[  12  874    1]\n",
            " [  53 2362    3]\n",
            " [  18 1284    1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 326   1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.21it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.009 valid_loss:0.978\n",
            "\ttrain_acc:52.67% valid_acc:52.45%\n",
            "\ttrain_f1:0.364 valid_f1:0.361\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  884    0]\n",
            " [   0 2423    0]\n",
            " [   0 1297    4]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 327   0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.16it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.968 valid_loss:0.930\n",
            "\ttrain_acc:52.65% valid_acc:52.71%\n",
            "\ttrain_f1:0.366 valid_f1:0.368\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  887    0]\n",
            " [   0 2416    2]\n",
            " [   0 1293   10]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 224   1]\n",
            " [  0 608   1]\n",
            " [  0 323   4]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.29it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.904 valid_loss:0.847\n",
            "\ttrain_acc:57.18% valid_acc:62.02%\n",
            "\ttrain_f1:0.469 valid_f1:0.549\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  790   95]\n",
            " [   0 2339   79]\n",
            " [   0 1009  296]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 126  99]\n",
            " [  0 539  70]\n",
            " [  0 146 181]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.845 valid_loss:0.812\n",
            "\ttrain_acc:61.91% valid_acc:63.14%\n",
            "\ttrain_f1:0.553 valid_f1:0.561\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  481  406]\n",
            " [   0 2050  369]\n",
            " [   0  499  803]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 119 106]\n",
            " [  0 536  73]\n",
            " [  0 130 197]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:17<00:00,  2.06it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.814 valid_loss:0.778\n",
            "\ttrain_acc:63.67% valid_acc:64.43%\n",
            "\ttrain_f1:0.570 valid_f1:0.577\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  447  441]\n",
            " [   0 2044  373]\n",
            " [   0  413  890]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  96 129]\n",
            " [  0 529  80]\n",
            " [  0 108 219]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:16<00:00,  2.17it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.790 valid_loss:0.764\n",
            "\ttrain_acc:64.58% valid_acc:65.46%\n",
            "\ttrain_f1:0.579 valid_f1:0.586\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  454  435]\n",
            " [   0 2045  374]\n",
            " [   0  369  931]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 103 122]\n",
            " [  0 532  77]\n",
            " [  0  99 228]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:18<00:00,  2.00it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.772 valid_loss:0.750\n",
            "\ttrain_acc:65.39% valid_acc:65.20%\n",
            "\ttrain_f1:0.588 valid_f1:0.586\n",
            "\ttrain_confusion_matrix:\n",
            "[[   4  445  439]\n",
            " [   7 2053  356]\n",
            " [   0  348  956]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  3 109 113]\n",
            " [  0 538  71]\n",
            " [  1 110 216]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:18<00:00,  1.92it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.756 valid_loss:0.739\n",
            "\ttrain_acc:66.86% valid_acc:66.06%\n",
            "\ttrain_f1:0.607 valid_f1:0.601\n",
            "\ttrain_confusion_matrix:\n",
            "[[  23  430  438]\n",
            " [  11 2072  329]\n",
            " [   2  317  986]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  6  95 124]\n",
            " [  0 523  86]\n",
            " [  2  87 238]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:19<00:00,  1.81it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.738 valid_loss:0.726\n",
            "\ttrain_acc:67.45% valid_acc:67.70%\n",
            "\ttrain_f1:0.618 valid_f1:0.625\n",
            "\ttrain_confusion_matrix:\n",
            "[[  41  435  409]\n",
            " [  22 2088  312]\n",
            " [  13  309  979]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 18 106 101]\n",
            " [  5 547  57]\n",
            " [  3 103 221]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.78it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.724 valid_loss:0.719\n",
            "\ttrain_acc:68.62% valid_acc:67.18%\n",
            "\ttrain_f1:0.640 valid_f1:0.627\n",
            "\ttrain_confusion_matrix:\n",
            "[[  86  422  377]\n",
            " [  36 2094  287]\n",
            " [  26  298  982]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 23 102 100]\n",
            " [  8 534  67]\n",
            " [  8  96 223]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.76it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.710 valid_loss:0.720\n",
            "\ttrain_acc:69.44% valid_acc:67.44%\n",
            "\ttrain_f1:0.657 valid_f1:0.636\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 126  418  342]\n",
            " [  56 2093  269]\n",
            " [  42  281  981]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 28  94 103]\n",
            " [ 12 523  74]\n",
            " [ 12  83 232]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:24<00:00,  1.45it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.699 valid_loss:0.709\n",
            "\ttrain_acc:69.99% valid_acc:66.93%\n",
            "\ttrain_f1:0.669 valid_f1:0.634\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 156  392  338]\n",
            " [  94 2083  245]\n",
            " [  58  256  986]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 27  79 119]\n",
            " [ 13 510  86]\n",
            " [ 14  73 240]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:23<00:00,  1.50it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.692 valid_loss:0.708\n",
            "\ttrain_acc:70.33% valid_acc:67.70%\n",
            "\ttrain_f1:0.677 valid_f1:0.644\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 183  378  323]\n",
            " [  93 2092  238]\n",
            " [  82  253  966]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 34  83 108]\n",
            " [ 15 520  74]\n",
            " [ 15  80 232]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:27<00:00,  1.32it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.684 valid_loss:0.715\n",
            "\ttrain_acc:70.99% valid_acc:68.13%\n",
            "\ttrain_f1:0.686 valid_f1:0.660\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 207  354  327]\n",
            " [  98 2079  239]\n",
            " [  78  241  985]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 56  89  80]\n",
            " [ 30 529  50]\n",
            " [ 30  91 206]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:23<00:00,  1.50it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.677 valid_loss:0.723\n",
            "\ttrain_acc:71.05% valid_acc:67.53%\n",
            "\ttrain_f1:0.687 valid_f1:0.646\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 207  350  328]\n",
            " [ 102 2092  222]\n",
            " [  92  240  975]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 46 101  78]\n",
            " [ 19 541  49]\n",
            " [ 28 102 197]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:25<00:00,  1.42it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.675 valid_loss:0.715\n",
            "\ttrain_acc:71.12% valid_acc:68.56%\n",
            "\ttrain_f1:0.689 valid_f1:0.663\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 215  348  325]\n",
            " [ 109 2079  228]\n",
            " [  87  234  983]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 57  89  79]\n",
            " [ 22 535  52]\n",
            " [ 32  91 204]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:24<00:00,  1.44it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.660 valid_loss:0.706\n",
            "\ttrain_acc:72.16% valid_acc:68.39%\n",
            "\ttrain_f1:0.703 valid_f1:0.662\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 249  332  305]\n",
            " [ 125 2089  206]\n",
            " [  97  218  987]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 53  80  92]\n",
            " [ 24 517  68]\n",
            " [ 21  82 224]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:26<00:00,  1.34it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.653 valid_loss:0.706\n",
            "\ttrain_acc:72.61% valid_acc:67.27%\n",
            "\ttrain_f1:0.709 valid_f1:0.655\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 265  329  294]\n",
            " [ 117 2099  199]\n",
            " [ 110  213  982]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 53  68 104]\n",
            " [ 31 497  81]\n",
            " [ 24  72 231]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:25<00:00,  1.41it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.648 valid_loss:0.710\n",
            "\ttrain_acc:72.57% valid_acc:67.87%\n",
            "\ttrain_f1:0.709 valid_f1:0.659\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 260  326  297]\n",
            " [ 130 2091  197]\n",
            " [ 109  205  993]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 56  80  89]\n",
            " [ 29 517  63]\n",
            " [ 24  88 215]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 0), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        l_feature, g_feature, label = data\n",
        "        l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(l_feature, g_feature)\n",
        "        loss = loss_fn(pred_logits, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds,labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "            loss = loss_fn(pred_logits, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds,  labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n",
        "        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4, 0.9)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.4, 0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.54      0.23      0.32       225\n",
            "    Positive       0.76      0.85      0.80       609\n",
            "    Negative       0.58      0.68      0.63       327\n",
            "\n",
            "    accuracy                           0.68      1161\n",
            "   macro avg       0.63      0.59      0.58      1161\n",
            "weighted avg       0.67      0.68      0.66      1161\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpha = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4641\n",
            "valid samples:1161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.73it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.065 valid_loss:1.027\n",
            "\ttrain_acc:50.15% valid_acc:52.45%\n",
            "\ttrain_f1:0.414 valid_f1:0.361\n",
            "\ttrain_confusion_matrix:\n",
            "[[  11  736  138]\n",
            " [  13 2075  329]\n",
            " [   8 1073  225]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 327   0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:23<00:00,  1.54it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.006 valid_loss:0.973\n",
            "\ttrain_acc:52.50% valid_acc:52.54%\n",
            "\ttrain_f1:0.362 valid_f1:0.363\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  888    0]\n",
            " [   0 2417    1]\n",
            " [   0 1300    2]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 326   1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:24<00:00,  1.48it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.965 valid_loss:0.929\n",
            "\ttrain_acc:52.58% valid_acc:52.54%\n",
            "\ttrain_f1:0.364 valid_f1:0.364\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  891    0]\n",
            " [   0 2415    1]\n",
            " [   0 1293    8]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 608   1]\n",
            " [  0 325   2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:23<00:00,  1.51it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.901 valid_loss:0.863\n",
            "\ttrain_acc:55.95% valid_acc:62.45%\n",
            "\ttrain_f1:0.449 valid_f1:0.550\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  791   96]\n",
            " [   0 2343   73]\n",
            " [   0 1070  235]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 136  89]\n",
            " [  0 553  56]\n",
            " [  0 155 172]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.66it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.842 valid_loss:0.808\n",
            "\ttrain_acc:62.00% valid_acc:63.74%\n",
            "\ttrain_f1:0.554 valid_f1:0.572\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  460  428]\n",
            " [   0 2045  375]\n",
            " [   0  488  812]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  95 130]\n",
            " [  0 521  88]\n",
            " [  0 108 219]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:13<00:00,  2.70it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.807 valid_loss:0.773\n",
            "\ttrain_acc:64.06% valid_acc:64.94%\n",
            "\ttrain_f1:0.575 valid_f1:0.579\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  417  474]\n",
            " [   0 2042  377]\n",
            " [   0  388  910]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 103 122]\n",
            " [  0 542  67]\n",
            " [  0 115 212]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:12<00:00,  2.96it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.778 valid_loss:0.757\n",
            "\ttrain_acc:65.26% valid_acc:66.15%\n",
            "\ttrain_f1:0.586 valid_f1:0.594\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  415  473]\n",
            " [   0 2061  357]\n",
            " [   0  356  946]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  92 133]\n",
            " [  0 529  80]\n",
            " [  0  88 239]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.30it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.759 valid_loss:0.735\n",
            "\ttrain_acc:66.97% valid_acc:67.18%\n",
            "\ttrain_f1:0.603 valid_f1:0.603\n",
            "\ttrain_confusion_matrix:\n",
            "[[   7  428  456]\n",
            " [   1 2094  322]\n",
            " [   0  315  985]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  1  98 126]\n",
            " [  0 546  63]\n",
            " [  1  93 233]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.06it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.737 valid_loss:0.719\n",
            "\ttrain_acc:67.71% valid_acc:68.22%\n",
            "\ttrain_f1:0.614 valid_f1:0.621\n",
            "\ttrain_confusion_matrix:\n",
            "[[  20  424  446]\n",
            " [   9 2098  310]\n",
            " [   0  299 1002]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  8  99 118]\n",
            " [  2 542  65]\n",
            " [  1  84 242]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.49it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.724 valid_loss:0.740\n",
            "\ttrain_acc:68.82% valid_acc:68.39%\n",
            "\ttrain_f1:0.633 valid_f1:0.628\n",
            "\ttrain_confusion_matrix:\n",
            "[[  52  418  420]\n",
            " [  14 2121  284]\n",
            " [  11  290  998]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 17 117  91]\n",
            " [  1 564  44]\n",
            " [  7 107 213]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.51it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.709 valid_loss:0.701\n",
            "\ttrain_acc:69.44% valid_acc:68.65%\n",
            "\ttrain_f1:0.645 valid_f1:0.643\n",
            "\ttrain_confusion_matrix:\n",
            "[[  76  397  415]\n",
            " [  29 2131  264]\n",
            " [  20  283  993]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 21  77 127]\n",
            " [  9 517  83]\n",
            " [  6  62 259]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.56it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.697 valid_loss:0.695\n",
            "\ttrain_acc:70.59% valid_acc:69.25%\n",
            "\ttrain_f1:0.668 valid_f1:0.653\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 128  374  385]\n",
            " [  60 2126  229]\n",
            " [  44  263  999]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 26  83 116]\n",
            " [ 12 522  75]\n",
            " [ 11  60 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:09<00:00,  3.62it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.688 valid_loss:0.684\n",
            "\ttrain_acc:71.29% valid_acc:69.60%\n",
            "\ttrain_f1:0.678 valid_f1:0.662\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 145  365  381]\n",
            " [  64 2113  238]\n",
            " [  52  223 1027]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 33  87 105]\n",
            " [ 17 529  63]\n",
            " [ 18  63 246]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.57it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.682 valid_loss:0.684\n",
            "\ttrain_acc:71.55% valid_acc:69.51%\n",
            "\ttrain_f1:0.686 valid_f1:0.667\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 173  346  370]\n",
            " [  78 2121  218]\n",
            " [  55  244 1003]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 39  75 111]\n",
            " [ 20 518  71]\n",
            " [ 20  57 250]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.51it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.669 valid_loss:0.677\n",
            "\ttrain_acc:72.20% valid_acc:69.51%\n",
            "\ttrain_f1:0.697 valid_f1:0.669\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 200  344  340]\n",
            " [  92 2121  204]\n",
            " [  80  221 1006]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 39  63 123]\n",
            " [ 21 512  76]\n",
            " [ 18  53 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.53it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.659 valid_loss:0.706\n",
            "\ttrain_acc:72.59% valid_acc:68.56%\n",
            "\ttrain_f1:0.703 valid_f1:0.652\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 216  329  342]\n",
            " [ 100 2115  203]\n",
            " [  83  206 1014]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 39 105  81]\n",
            " [ 19 550  40]\n",
            " [ 27  93 207]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.51it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.655 valid_loss:0.690\n",
            "\ttrain_acc:72.66% valid_acc:69.51%\n",
            "\ttrain_f1:0.705 valid_f1:0.668\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 223  317  349]\n",
            " [ 106 2113  193]\n",
            " [  89  206 1012]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 49  88  88]\n",
            " [ 19 544  46]\n",
            " [ 27  86 214]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.58it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.647 valid_loss:0.671\n",
            "\ttrain_acc:73.42% valid_acc:69.85%\n",
            "\ttrain_f1:0.716 valid_f1:0.677\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 257  300  335]\n",
            " [ 113 2126  178]\n",
            " [ 112  187 1000]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 50  73 102]\n",
            " [ 24 519  66]\n",
            " [ 26  59 242]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.50it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.639 valid_loss:0.693\n",
            "\ttrain_acc:73.42% valid_acc:69.16%\n",
            "\ttrain_f1:0.714 valid_f1:0.671\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 239  314  339]\n",
            " [ 106 2109  197]\n",
            " [  94  175 1035]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 57  86  82]\n",
            " [ 31 537  41]\n",
            " [ 41  77 209]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.29it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.631 valid_loss:0.673\n",
            "\ttrain_acc:73.96% valid_acc:69.68%\n",
            "\ttrain_f1:0.725 valid_f1:0.672\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 288  291  311]\n",
            " [ 131 2124  160]\n",
            " [ 131  176  996]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 43  71 111]\n",
            " [ 25 519  65]\n",
            " [ 23  57 247]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 0.2), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        l_feature, g_feature, label = data\n",
        "        l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(l_feature, g_feature)\n",
        "        loss = loss_fn(pred_logits, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds,labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "            loss = loss_fn(pred_logits, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds,  labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n",
        "        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4, 0.9)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzVElEQVR4nO3deXwV9b34/9c7G9kXSMKSsETZSVgDuEGxiKKtuFK0tl6sS2urbW9bb7m9vWq1/tqrtl9raxdsrdrrrlXRuqJw0VosS1nDDkECISQhZN/z/v0xk3AIWU5CzjlJzvv5eJzHmTPzmZn3mZx83jOfmfmMqCrGGGOCV0igAzDGGBNYlgiMMSbIWSIwxpggZ4nAGGOCnCUCY4wJcpYIjDEmyFkiMP2aiLwtIv/W02W7GMM8EcnrYPrvReS/e3q9xnhL7D4C09uISIXHx2igFmh0P39dVZ/xf1TdJyLzgP9V1fQzXE4ucIuqruyBsIxpERboAIxpTVVjm4c7qvxEJExVG/wZW19l28p0xJqGTJ/R3MQiIj8UkaPAn0UkSUTeFJFCESlxh9M95lktIre4w0tF5GMRedgte0BELu1m2QwRWSMi5SKyUkQeE5H/7ST+74vIMRHJF5GbPMY/KSI/dYeT3e9wQkSOi8hHIhIiIn8BRgBviEiFiPyHW36RiGx3y68WkQkey811t9UWoFJE7hKRV1rF9KiI/Ko7fw/Tf1giMH3NEGAgMBK4Dec3/Gf38wigGvhNB/PPBnYBycCDwJ9ERLpR9lngn8Ag4F7gq17EnQCkATcDj4lIUhvlvg/kASnAYOBHgKrqV4HPgMtVNVZVHxSRscBzwHfd8m/hJIoIj+VdD3wBSAT+F1goIongHCUA1wFPdxK76ecsEZi+pgm4R1VrVbVaVYtV9RVVrVLVcuAB4HMdzH9QVR9X1UbgKWAoToXrdVkRGQHMBO5W1TpV/RhY0Unc9cB9qlqvqm8BFcC4dsoNBUa6ZT/S9k/kLQH+pqrvq2o98DAQBZznUeZRVT3kbqt8YA2w2J22EChS1Q2dxG76OUsEpq8pVNWa5g8iEi0ifxCRgyJShlPRJYpIaDvzH20eUNUqdzC2i2WHAcc9xgEc6iTu4lZt9FXtrPchYC/wnojsF5FlHSxzGHDQI8YmN460DuJ6CviKO/wV4C+dxG2CgCUC09e03jv+Ps6e9WxVjQfmuuPba+7pCfnAQBGJ9hg3vCcWrKrlqvp9VT0LWAR8T0TmN09uVfwITpMYAG6z1XDgsOciW83zGjBZRDKBLwJ96gos4xuWCExfF4dzXuCEiAwE7vH1ClX1ILAeuFdEIkTkXODynli2iHxRREa7lXopzmWzTe7kAuAsj+IvAl8QkfkiEo6TFGuBTzqIvQZ4Gfcch6p+1hNxm77NEoHp6x7BaRcvAtYC7/hpvTcA5wLFwE+BF3Aq4TM1BliJcw7hH8BvVXWVO+1nwI/dK4R+oKq7cJp3fo3z/S/HOZlc18k6ngKysGYh47IbyozpASLyArBTVX1+RHKm3JPdO4EhqloW6HhM4NkRgTHdICIzReRs9xr/hcAVOO3vvZqIhADfA563JGCa+TQRiMhCEdklInvbuvpBREaKyAcissW9GeaMbsE3xo+GAKtxmnAeBW5X1X8FNKJOiEgMUAYswA/nUkzf4bOmIffyvd04P7o8YB1wvarmeJR5CXhTVZ8Skc8DN7k3zhhjjPETXx4RzAL2qup+9+TV8ziHz54mAh+6w6vamG6MMcbHfNnpXBqn3sySh3PLvqfNwNXAr4CrgDgRGaSqxZ6FROQ2nO4EiImJmTF+/HifBW2MMf3Rhg0bilQ1pa1pge599AfAb0RkKc4doYc52d1wC1VdDiwHyM7O1vXr1/szRmOM6fNE5GB703yZCA5z6t2W6Zx6xyOqegTniAARiQWuUdUTPozJGGNMK748R7AOGON21xuB08vhKR1zuV3uNsfwn8ATPozHGGNMG3yWCNwOtu4A3gV2AC+q6nYRuU9EFrnF5gG7RGQ3Tg+QD/gqHmOMMW3rc3cW2zkCY06qr68nLy+PmpqazguboBAZGUl6ejrh4eGnjBeRDaqa3dY8gT5ZbIw5A3l5ecTFxTFq1Cjaf76OCRaqSnFxMXl5eWRkZHg9n3UxYUwfVlNTw6BBgywJGABEhEGDBnX5CNESgTF9nCUB46k7vwdLBMYYE+QsERhjuu3EiRP89re/7da8l112GSdOnOjZgEy3WCIwxnRbR4mgoaGhzfHN3nrrLRITE30Q1ZlRVZqamjov2I9YIjDGdNuyZcvYt28fU6dO5a677mL16tXMmTOHRYsWMXHiRACuvPJKZsyYwaRJk1i+fHnLvKNGjaKoqIjc3FwmTJjArbfeyqRJk7j44ouprq4+bV1vvPEGs2fPZtq0aVx00UUUFBQAUFFRwU033URWVhaTJ0/mlVdeAeCdd95h+vTpTJkyhfnzncc+33vvvTz88MMty8zMzCQ3N5fc3FzGjRvHjTfeSGZmJocOHeL2228nOzubSZMmcc89J3vtXrduHeeddx5Tpkxh1qxZlJeXM3fuXDZt2tRS5oILLmDz5s09t6F9zC4fNaaf+Mkb28k50rPPmpk4LJ57Lp/U7vSf//znbNu2raUSXL16NRs3bmTbtm0tly8+8cQTDBw4kOrqambOnMk111zDoEGDTlnOnj17eO6553j88cf50pe+xCuvvMJXvvKVU8pccMEFrF27FhHhj3/8Iw8++CC/+MUvuP/++0lISGDr1q0AlJSUUFhYyK233sqaNWvIyMjg+PHjnX7XPXv28NRTT3HOOecA8MADDzBw4EAaGxuZP38+W7ZsYfz48SxZsoQXXniBmTNnUlZWRlRUFDfffDNPPvkkjzzyCLt376ampoYpU6Z4vZ0DzRKBMaZHzZo165Rr2B999FFeffVVAA4dOsSePXtOSwQZGRlMnToVgBkzZpCbm3vacvPy8liyZAn5+fnU1dW1rGPlypU8//zzLeWSkpJ44403mDt3bkuZgQMHdhr3yJEjW5IAwIsvvsjy5ctpaGggPz+fnJwcRIShQ4cyc+ZMAOLj4wFYvHgx999/Pw899BBPPPEES5cu7XR9vYklAmP6iY723P0pJiamZXj16tWsXLmSf/zjH0RHRzNv3rw2r3EfMGBAy3BoaGibTUN33nkn3/ve91i0aBGrV6/m3nvv7XJsYWFhp7T/e8biGfeBAwd4+OGHWbduHUlJSSxdurTDa/Ojo6NZsGABr7/+Oi+++CIbNmzocmyBZOcIjDHdFhcXR3l5ebvTS0tLSUpKIjo6mp07d7J27dpur6u0tJS0tDQAnnrqqZbxCxYs4LHHHmv5XFJSwjnnnMOaNWs4cOAAQEvT0KhRo9i4cSMAGzdubJneWllZGTExMSQkJFBQUMDbb78NwLhx48jPz2fdunUAlJeXt5wUv+WWW/j2t7/NzJkzSUpK6vb3DARLBMaYbhs0aBDnn38+mZmZ3HXXXadNX7hwIQ0NDUyYMIFly5ad0vTSVffeey+LFy9mxowZJCcnt4z/8Y9/TElJCZmZmUyZMoVVq1aRkpLC8uXLufrqq5kyZQpLliwB4JprruH48eNMmjSJ3/zmN4wdO7bNdU2ZMoVp06Yxfvx4vvzlL3P++ecDEBERwQsvvMCdd97JlClTWLBgQcuRwowZM4iPj+emm27q9ncMFOt0zpg+bMeOHUyYMCHQYRjgyJEjzJs3j507dxISEth97LZ+Fx11OmdHBMYYc4aefvppZs+ezQMPPBDwJNAddrLYGGPO0I033siNN94Y6DC6re+lLmOMMT3KEoExxgQ5SwTGGBPkLBEYY0yQs0RgjPGr2NhYwLnc8tprr22zzLx58+jsMvFHHnmEqqqqls/WrXX3WSIwxgTEsGHDePnll7s9f+tE0Fu7tW5Pb+ru2hKBMabbli1bdkr3Ds3dPFdUVDB//nymT59OVlYWr7/++mnz5ubmkpmZCUB1dTXXXXcdEyZM4Kqrrjqlr6G2uoN+9NFHOXLkCBdeeCEXXnghcLJba4Bf/vKXZGZmkpmZySOPPNKyPuvuum12H4Ex/cXby+Do1p5d5pAsuPTn7U5esmQJ3/3ud/nWt74FOD12vvvuu0RGRvLqq68SHx9PUVER55xzDosWLWr3ebq/+93viI6OZseOHWzZsoXp06e3TGurO+hvf/vb/PKXv2TVqlWndDcBsGHDBv785z/z6aefoqrMnj2bz33ucyQlJVl31+2wIwJjTLdNmzaNY8eOceTIETZv3kxSUhLDhw9HVfnRj37E5MmTueiiizh8+HDLnnVb1qxZ01IhT548mcmTJ7dMe/HFF5k+fTrTpk1j+/bt5OTkdBjTxx9/zFVXXUVMTAyxsbFcffXVfPTRR4D33V1fcsklZGVl8dBDD7F9+3bA6e66OeGB09312rVre6S769bfb9euXad1dx0WFsbixYt58803qa+v79Huru2IwJj+ooM9d19avHgxL7/8MkePHm3p3O2ZZ56hsLCQDRs2EB4ezqhRozrsxrk9Xe0OujPW3XXb7IjAGHNGlixZwvPPP8/LL7/M4sWLAafL6NTUVMLDw1m1ahUHDx7scBlz587l2WefBWDbtm1s2bIFaL87aGi/C+w5c+bw2muvUVVVRWVlJa+++ipz5szx+vsEY3fXlgiMMWdk0qRJlJeXk5aWxtChQwG44YYbWL9+PVlZWTz99NOMHz++w2XcfvvtVFRUMGHCBO6++25mzJgBtN8dNMBtt93GwoULW04WN5s+fTpLly5l1qxZzJ49m1tuuYVp06Z5/X2Csbtr64bamD7MuqEOPt50d23dUBtjTD/lq+6u7WSxMcb0Eb7q7tqOCIzp4/pa867xre78HiwRGNOHRUZGUlxcbMnAAE4SKC4uJjIyskvzWdOQMX1Yeno6eXl5FBYWBjoU00tERkaSnp7epXksERjTh4WHh7fc1WpMd1nTkDHGBDmfJgIRWSgiu0Rkr4gsa2P6CBFZJSL/EpEtInKZL+MxxhhzOp8lAhEJBR4DLgUmAteLyMRWxX4MvKiq04DrgN/6Kh5jjDFt8+URwSxgr6ruV9U64HngilZlFIh3hxOAIz6MxxhjTBt8mQjSgEMen/PccZ7uBb4iInnAW8CdbS1IRG4TkfUist6ujjDGmJ4V6JPF1wNPqmo6cBnwFxE5LSZVXa6q2aqanZKS4vcgjTGmP/NlIjgMDPf4nO6O83Qz8CKAqv4DiASSMcYY4ze+TATrgDEikiEiETgng1e0KvMZMB9ARCbgJAJr+zHGGD/yWSJQ1QbgDuBdYAfO1UHbReQ+EVnkFvs+cKuIbAaeA5aq3StvjDF+5dM7i1X1LZyTwJ7j7vYYzgHObz2fMcYY/wn0yWJjjDEBZonAGGOCnCUCY4wJcpYIjDEmyFkiMMaYIGeJwBhjgpwlAmOMCXKWCIwxJshZIjDGmCBnicAYY4KcJQJjjAlylgiMMSbIWSIwxpggZ4nAGGOCnCUCY4wJcpYIjDEmyFkiMMaYIGeJwBhjgpwlAmOMCXI+fWaxMcaY7qmpbyS3uJIDhZUccN+vmZHOOWcN6vF1WSIwxpgAqW9sIq+kmgNFFRwoqnLfK8ktquLwiepTyqbEDeC80T2fBMASgTHGdKq0up6d+WXUNTZ1exkNTcrhkmoOFFW6lX0lnx2voqFJW8rER4aRkRLLrIyBZCTHMCo5hrPc99gBvquuLREYY4yHqroGth8pY/OhE2w9XMqWvFIOFFX22PIjw0MYNSiG8UPjuDRrCKMGxXBWSgwZybEkRYcjIj22Lm9ZIjDGBK26hiZ2Hi1jc14pW/NOsCWvlN0F5TTvpA9NiCQrLYFrZ6QzaVj8Ge2Vi8CwxCgGx0USEuL/yr4jlgiMMUGhsUnZe6yCzXkn2JpXypa8E+zIL29p7kmKDmdyeiIXTxzM5PREJqcnkBofGeCo/cMSgTGmV6msbeBoWQ0FpTUcLashv7SGgrIaCstrqW1oor6xicYmpaFRaWhqoqGN4cYmbSnX/F7b0NTSHh87IIzMtHhuOn9US6WfnhQVkGaZ3sASgTHGL5qalOLKOgrcyt2zsm8eV1BaQ3ltw2nzxkeGkRofSWR4CGEhIYSFCGGhQnRYGGGh4nwOCSE0VAgPEUJDQggPFUJDhPDQEEJDhIiwEMakxjI5PZGzkmN6XfNMIFkiMMb0KFWloKyWnUfL2HW0nF1Hy9lxtJx9xypOu+omNERIiR3AkIRIRqfEcsHoZAbHRzIkYYDzHh/JkIRIoiOsqvIl27rGmG6rqG1oqex3HS1j59Fydh4tp7S6vqXMkPhIxg2JY86YZNKTok6p4JNjBxBqe+YBZ4nAGNOhhsYmSqvrKaqoY8+xcnbmO5X9roIyDh0/edNTTEQo44bEcVnWUMYPiWP8kDjGDYkjMToigNEbb1giMCZI1DU0caK6jtKqek5U13Oiqp6SqubPdZxwx3t+Lq2qP63NPjREyEiOYXJ6IkuyhzNuSDzjh8SRlhhl7e59lCUCY/qhwvJacvLL2H6klJwjZeTkl3GgqBLVtsuHCCRGR5AYFU5CdDgpsQMYkxpHYnQ4iVERznt0OKNTYzk7JZbI8FD/fiHjU5YIjOnDmpqU3OJKcvLLyDlSxna30i8sr20pk5YYxcRh8XwxaygpcQOcCt+jgk+IDic2Isz25oOYJQJj+oia+kZ2HS1vqfRz8svYkV9GVV0jAGEhwujUWOaMSWbi0HgmDUtg4tB4EqLDAxy56e18mghEZCHwKyAU+KOq/rzV9P8HXOh+jAZSVTXRlzEZ05ccLa3h/R0FvLf9KGv3F1PfePKGqAlD4/hS9nAmDo1n4rB4xgyOZUCYNdmYrvNZIhCRUOAxYAGQB6wTkRWqmtNcRlX/3aP8ncA0X8VjTF+g6nSD8F6OU/lvzisFICM5hqXnjWL6iCQmDotneFK0NeWYHuPLI4JZwF5V3Q8gIs8DVwA57ZS/HrjHh/EY0ys1NimbDpXw3vYC3sspaOnpcsrwRO66ZByXTBrM2SmxQdv9gfE9XyaCNOCQx+c8YHZbBUVkJJABfNjO9NuA2wBGjBjRs1EaEwA19Y18sq+I93MKeD/nGEUVtYSFCOeePYivXZDBggmDGZIQHB2e9RoNtVBxzH0VuC+P4eoSSBwBQ7Kc1+BMiB7o3/i0CcKjenzRveVk8XXAy6ra2NZEVV0OLAfIzs5u5wI4Y3q30qp6Vu06xns5R1m9q5CqukZiB4Qxb1wKCyYOZt64VBKizvDEblMjVBadXolVHIOqYpAQCA2H0Aj31ZXhcKcv5e4KCYMhk/1beTarq4S89VB22GPbHDt1O9WcaHveqIEQOxiiEmHfh7D5uZPTEoafTAzNr8SR3d9OdVVQkgvH97d6HYDSQ7Do1zD9q91bdgc6TQQicjnwN1Xt6qN5DgPDPT6nu+Pach3wrS4u35heqb6xiYPFlew6WsGugnL2FJSzq6Cc3KJKmtR55OCV09K4eOJgzj17kHcneBvqnAqi4mirCr7w1MqsqsjZa2wtIu5kBdxYD411Hu910PY+mA+IU1lmzIWMz8HIc2FAXM+vpr4G8tbBgTXO6/B6aPK4MS4iFmJTnQo+ZZwTT+zgk+Oa32NSIKzVndEVx+Do1lNfu985ud0HxDtHC57JIXUChA1wpteUQcmB0yv64weg/Mip64oeBAPPghHnwMAvw9DJPb+tANH27jBpLiDyv8C5wCvAE6q606sFi4QBu4H5OAlgHfBlVd3eqtx44B0gQzsLBueIYP369d6EYIxPNTUph0qq2F1Qwe4Cp7+d3QXl7C+sbOlcLURg5KAYxg6OZdyQeOaNS2FqemL7J3rra6B4DxTugsKd7msXFO87vbIOjWi78mqpxFLd4VSIiOnkyzS2nSBaD3MGB+T1VXDon07FfOif0FgLEgpp093EMBeGz+5e00djPRz5Fxz4PzjwERz6FBpqnCOgYdMhYw6MusCpVGNSYUBs979HW+qq4NgOKPBMENug3n2yWUiYs+7qEqgsPHXe2MHOtIFnwcCMk8NJGc5RSA8RkQ2qmt3mNC/qXkQkHudk7k04v4Q/A8+pankn810GPIJz+egTqvqAiNwHrFfVFW6Ze4FIVV3mzZexRGACoaqugfW5JU7nagVOhb+noILq+pOVc1piFOOGxDFmcCzjBscxdnAco1PbuQu3tgKKdjuVfNGukxV/Se7JPUsJdSqElHHOK3ksxA87WdlHJp5ZU00g1VefTAoH1sDhDU6iC42A9FknE0PajNP3yMFJXEe3Qu5HzvwHP4G6Cmfa4KyT8488FyIT/PvdWmJscvb8j25xYi3cdXIPv7nST8ro+aTUjjNOBO5CBgFfBb4L7ABGA4+q6q97KE6vWCIw/pJfWs0HO47xwY4C/r6vmLoGp4JOjRvgVPipcYwbEsvYwXGMGRxHbESo0xZdXXL6q+aE04zTXPmXfnZyRSHhMGi0W+GPP/k+6OyTzQn9XW05fLbW3aNfA/lbAIXwaBhxrrNHnzYDju10yuR+fLJNP3msR8V/AcQMCuQ36bXOKBGIyCKcI4HRwNPAU6p6TESigRxVHdXD8XbIEoHxCVWaaivZ8Vk+a3d+xsa9h8kvLCZGahgZp2QPjSAzWUgbUEdUY5lHJX/i1Aq/qb79dYRFQfLoUyv7lPGQNMo5EWtOqjoOB//uNPMcWAOFO05OSxx5suIfNQfihwYuzj7kTBPBU8CfVHVNG9Pmq+oHPROmdywRmC5RddrX933g7HHWljl77XUVUFeJ1lbSWFtBSEMVId62f0fEQlSS034bleT9yweX/QWN8gLI3wwpY53Eabqso0TgzeWj9wL5HguLAgaraq6/k4AxXqktd/Yk9650XicOOuMThkNMCrWhURQ2DSSvNpmD5UJ50wDqQ6MZkjyIjGGpjE4fQmxcvHOCNSLWfXeHIxPbbrM2vhU3GOIuDnQU/ZY3ieAl4DyPz43uuJk+iciYrlKFgm2w9wOn4v9srdNEEx4DGXOpzP4m26Ky+fvxeD7cWcC2w2UAjBgYzfyZqcwfP5hZGQOJCAsJ8BcxJjC8SQRhqlrX/EFV60TEdolMYFUdh/2r3Mr/A+f6eqAhZRJHxt3ExvBprKzI4F+fVXN4SzVQQIgUMH1EEj9cOJ6LJqQyOtW6bTAGvEsEhSKyyONyzyuAIt+GZUwrTY1weKPT1r93pXu5YRP1EQnkJszik6iv8tey8Ww+FNXSscnIQTVMHZHIjeeOJCstgUlpCWd+564x/ZA3ieAbwDMi8htAcP7NbvRpVMYAlB9tae7R/auQ6hIU4cCA8awKWcybVRPZXHM2TWUhjBwUTebIBC5NS2CyVfrGdEmniUBV9wHniEis+7nC51GZ4NRQB4fWnmzuKdgKQFVEMqsbpvJO3STWNGURHz2YrJEJXJKWwA/SEsgclmAPXzHmDHjV6ZyIfAGYBEQ2t6mq6n0+jMsEi5Jc9+qeD5zrxesqICSM+rTZfDrqDn792Sg+LRvKjJEDuXVOBveflWyVvjE9zJtO536P8/SwC4E/AtcC//RxXKa/qqty7gptbusv3uuMTxwBk5dQPHQuyw8N4+kNx6mub2T++FRemnc2M0cFoMdKY4KEN0cE56nqZBHZoqo/EZFfAG/7OjDTj5QfhR1vwM6/OX3CNNY6d9lmzIGZt8Loi9hVn8of1uxnxStHgCIWTR3G1+eezbghPuiZ0hhzCm8SQY37XiUiw4BiwO7pNh0rzXMq/5wV8Nk/AIVBY2DWrTB6Pow4D8IjWZd7nN+9uY8Pd+4iKjyUr547klvmnEVaot2Fa4y/eJMI3hCRROAhYCNO76OP+zIo00eVHIQdKyDndacveHD6ZZ/3nzDxCkgdDzjdN3+w8xi//7+NbDhYwsCYCP79orHceO5IkmLsFhVj/K3DRCAiIcAHqnoCeEVE3sTpMrrUH8GZPqB4n1Px57wO+ZuccUOnwPy7YcIVTidrrrqGJl7fdJjla/az51gF6UlR/GTRJL6UPZyoCC8ezmKM8YkOE4GqNonIY8A093MtUOuPwEwvVrjrZOVfsM0Zl5YNC+6HiYtO6RRMVdmSV8rb247y+qbD5JfWMH5IHL+6bipfyBpKWKh162BMoHnTNPSBiFwD/NWbJ4iZfkgVCrafbPYp3AmI8/i8S34GEy6HxJNPJW1sUjYcLOHtbfm8u+0oR0prCAsRzhudzM+uzuJzY1OsawdjehFvEsHXge8BDSJSg3N3sapqvE8jM4Gl6nT727znf3yf89i/kefDzFtg/BdP6Qe+obGJtfuP8/a2fN7LKaCwvJaIsBDmjknmexeP46IJqSRGW/u/Mb2RN3cW2/V7wULV6cMn5zWn8j/xmfO4xIy5cN4dTuUfm9pSvLahkb/vLeLtrUd5f0cBJ6rqiQoP5cLxKSzMHMrnx6cSO8CrexaNMQHkzQ1lc9sa39aDakwf1NTkPOh7xwrnUs+yPOfRiWfNg7n/AeO/ANEnb+aqrmvk/3Yf4+1tR/lwxzHKaxuIGxDG/AmpLMwcyufGptiJX2P6GG921+7yGI4EZgEbgM/7JCLje02Nzo1dOa871/pXHIXQAc71/fP/G8YudJ6+5WHToRMsX7OPVTsLqa5vJCk6nEuzhnBp5lDOGz2IAWFW+RvTV3nTNHS552cRGQ484quAjI80NkDuGmevf+ebUFno3N07ZoFzjf+YiyHy9NM+eSVVPPjOLlZsPsLAmAiumZHGpZlDmZ0x0K74Maaf6E4Dbh4woacDMT6gCof+CVtfgu2vQlWR89SusZe4lf8C5xGMbSivqee3q/fxp48PECJw5+dH8/XPnW1t/sb0Q96cI/g1tDzVOwSYinOHsemtCnKcyn/by84J37BIp7kn8xqn8u/gIeoNjU08t+4Qj7y/m+LKOq6elsYPLhnHMOvywZh+y5vdu/Ueww3Ac6r6dx/FY7qr5KBT8W99GY7lOFf7nH0hzPuRc8K3jWYfT6rK6l2FPPDWDvYeq2B2xkCe/MJEstIT/PQFjDGB4k0ieBmoUdVGABEJFZFoVa3ybWimUxWFTpPPtpedK38Ahs+Gyx6GiVdCbIpXi8k5Usb/99YOPt5bREZyDMu/OoMFEwfbTV/GBAmv7iwGLgKan0wWBbwHnOeroEwHasqc7py3vgT7V4M2QuokmH+P0/STNNLrRR0rq+Hh93bx0oY8EqLCuefyidwweyQRYXYS2Jhg4k0iiPR8PKWqVohItA9jMm2pOAZv3QW734GGGkgYAed/B7KuhcGTurSoqroGHl9zgD+s2Ud9YxO3XJDBHReOsSd/GROkvEkElSIyXVU3AojIDKDat2GZ06x52DkSyL4JshZD+kzoYtNNU5Py138d5qF3d1JQVstlWUP44cLxjBzU9pVDxpjg4E0i+C7wkogcwelnaAiwxJdBmVYa6pymoAlfhMse6tYiPiuu4vZnNrD9SBlThyfy2Jenk22PfzTG4N0NZetEZDwwzh21S1XrfRuWOcWe96D6OEz5crdmV1WW/XULnx2v4tHrp3H55KF2ItgY06LTs4Ii8i0gRlW3qeo2IFZEvun70EyLzc9B7GA4u3u9eqzYfIRP9hXzw4XjWTRlmCUBY8wpvLk85Fb3CWUAqGoJcKvPIjKnqixyThBnLYbQrt/VW1ZTz0//toMp6QlcP2uEDwI0xvR13iSCUPHYhRSRUMA6lveXrS9DUwNM7V6z0P97fzdFFbX89MosQkPsSMAYczpvdjHfAV4QkT+4n78OvO27kMwpNj/rPAO4i5eIAmw/UspTn+Tyldkj7Q5hY0y7vDki+CHwIfAN97UV56Yy42sFOc5TwrpxkripSfnxa9sYGBPBDy4e1/kMxpig1WkiUNUm4FMgF+dZBJ8HdnizcBFZKCK7RGSviCxrp8yXRCRHRLaLyLPehx4ENj8LIWHOTWNd9NKGQ/zrsxP86LIJdqOYMaZD7TYNichY4Hr3VQS8AKCqF3qzYPdcwmPAApyuq9eJyApVzfEoMwb4T+B8VS0RkdS2lxaEGhtg8wsw5hKISe7SrMcr6/jZ2zuZlTGQq6al+ShAY0x/0dERwU6cvf8vquoFqvproLELy54F7FXV/apaBzwPXNGqzK3AY+6VSKjqsS4sv3/b9yFUHuvWSeIH39lJRU0D91+RaZeKGmM61VEiuBrIB1aJyOMiMh/nzmJvpQGHPD7nueM8jQXGisjfRWStiCxsa0EicpuIrBeR9YWFhV0IoQ/b/CxEDXSeHNYFGw6W8Py6Q9x8QQbjhsT5KDhjTH/SbiJQ1ddU9TpgPLAKp6uJVBH5nYh0rXZqXxgwBpiH0wT1uIgkthHLclXNVtXslBTvulbu06pLYOdbzr0DYd5fqdvQ2MSPX9vG0IRIvj1/jA8DNMb0J96cLK5U1WfdZxenA//CuZKoM4eB4R6f091xnvKAFapar6oHgN04iSG4bX8VGmth6vVdmu0vaw+yI7+Mu784kRh7pKQxxktd6nheVUvcvfP5XhRfB4wRkQwRiQCuA1a0KvMaztEAIpKM01S0vysx9UubnoWUCTB0qtezHCur4Rfv7eZzY1NYmDnEd7EZY/odnz2BRFUbgDuAd3EuN31RVbeLyH0issgt9i5QLCI5OM1Pd6lqsa9i6hOK9kDeOuckcRdO9P70bzuoa2ziJ4sm2QliY0yX+LT9QFXfAt5qNe5uj2EFvue+DDgdzEkITP6S17P8fW8RKzYf4TvzxzAq2Z4tYIzpGnsmYW/S1Aibn4ez50Ocd807dQ1N/Pfr2xg5KJrb553t4wCNMf2RJYLe5MAaKDvcpZPEj3+0n/2Fldy7aBKR4aE+DM4Y019ZIuhNNj8HAxJg3Be8Kn7oeBW//nAPCycN4cJxdlO2MaZ7LBH0FrXlsOMNyLwKwiO9muUnb+QQIsLdl0/0cXDGmP7MEkFvkfM61FfB1Bu8Kr4yp4CVOwr4zvwxDEu0zmCNMd1niaC32PQcDDwb0md2WrS6rpF739jOmNRYvnZBhh+CM8b0Z5YIeoOSXDj4sXOS2It7AB5btZe8kmruvzKT8FD7ExpjzozVIr3B5ucBgcnXdVp0X2EFf1izj6unpXHOWYN8H5sxpt+zRBBoqs7VQhlzIHF4J0WVe17fTmR4KP952QQ/BWiM6e8sEQTaZ/9wmoa8OEn85pZ8Pt5bxF2XjCMlboDvYzPGBAVLBIG26VmIiIUJl3dYrLymnvvfzCEzLZ4bZo/0U3DGmGBgiSCQ6qpg+2sw8QqIaL+PoNLqem5+cj2FFbX89MosQkOsUzljTM+xTusDaeebUFcOU9rvUuJYWQ03PvFP9hVW8Oh105g6PNF/8RljgoIlgkDa9CwkjICR57c5Obeokq8+8SnFFXU8sXQmc8YEwdPZjDF+Z01DgVJ6GPavdu4dCDn9z7DtcCnX/v4TKmoaeO7WcywJGGN8xo4IAmXL84DClNPvHfhkXxG3Pb2BhKhwnr55FmenxPo/PmNM0LBEEAiqTpcSI86FgWedMumdbfl8+7lNjEqO5umvzWZIgncd0BljTHdZ01AgHN4AxXtOO0n87Kef8c1nNpKZFs+LXz/XkoAxxi/siCAQNj0LYZEw6UrAuWP4Nx/u5Rfv7+bCcSn89oYZREXYQ2aMMf5hicDf6mtg2yvODWSRCTQ1Kfe9mcOTn+Ry9bQ0/ufaydaRnDHGrywR+Nvut6HmBEy5nrqGJr7/0mbe2HyEWy7I4EeXTSDEbhYzxviZJQJ/2/QcxA2jMu0CvvHUOj7aU8SyS8fz9blnIV50QW2MMT3NEoE/VRyDvSupnvlNvvzEerbmneDBayfzpeyOex01xhhfskTgT1teBG3k9m3j2FlWxh++ms2CiYMDHZUxJshZIvAXVWrX/4W9MpoNVan85eaZzMoYGOiojDEmiBJBbTlUn4DGOmisb/Xe+lV/2nBdXQ15xeU0NiqNqjQ2KU1NzcPQqO5nd1yTx3tDE4Q3VHJRyU7eDLmVF287lwlD4wO9RYwxBgimRLDuT7Dynm7PHgGc1WmpjpWGJPKVW/6dNEsCxpheJHgSweiLICYZQiMgNNx973i4uAYe/mA/K7YWMTw5gR9eNpEhCdGEh4YQERpCeJgQHhpy8nOoEBoi7V79k4CQ0EYHc8YYE0jBkwiGZDovL6gqL2/I44G3dlBZ28A350/mmxeezYAwu9vXGNP/BE8i8NLB4kp+9OpW/r63mOyRSfzs6izGDI4LdFjGGOMzlghc9Y1N/PGjAzyycjcRoSH89MpMvjxrhN3pa4zp9ywRAFvyTvDDV7ayI7+MSyYN5ieLMq3nT2NM0AjqRFBZ28Av39/Nn/9+gOTYAfz+KzNYmDkk0GEZY4xfBW0iWL3rGP/16jYOn6jmhtkj+OGl44mPDA90WMYY43c+vZZRRBaKyC4R2Ssiy9qYvlRECkVkk/u6xZfxABRV1PKd5//F0j+vIzI8hJe+cS4PXJVlScAYE7R8dkQgIqHAY8ACIA9YJyIrVDWnVdEXVPUOX8XRrPUlod+9aAy3z7NLQo0xxpdNQ7OAvaq6H0BEngeuAFonAr94ZOUefvXBHrJHJvHza7IYnWqXhBpjDPg2EaQBhzw+5wGz2yh3jYjMBXYD/66qh1oXEJHbgNsARowY0a1glswcTmr8AK6faZeEGmOMp0D3d/AGMEpVJwPvA0+1VUhVl6tqtqpmp6SkdGtFwxKjuGH2SEsCxhjTii8TwWHA84kr6e64FqparKq17sc/AjN8GI8xxpg2+DIRrAPGiEiGiEQA1wErPAuIyFCPj4uAHT6MxxhjTBt8do5AVRtE5A7gXSAUeEJVt4vIfcB6VV0BfFtEFgENwHFgqa/iMcYY0zZR1UDH0CXZ2dm6fv36QIdhjDF9iohsUNXstqYF+mSxMcaYALNEYIwxQc4SgTHGBDlLBMYYE+QsERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQs0RgjDFBzhKBMcYEOUsExhgT5CwRGGNMkLNEYIwxQc4SgTHGBDlLBMYYE+QsERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQs0RgjDFBzhKBMcYEOUsExhgT5CwRGGNMkLNEYIwxQc4SgTHGBDlLBMYYE+QsERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQs0RgjDFBzhKBMcYEOZ8mAhFZKCK7RGSviCzroNw1IqIiku3LeIwxxpzOZ4lAREKBx4BLgYnA9SIysY1yccB3gE99FYsxxpj2+fKIYBawV1X3q2od8DxwRRvl7gf+B6jxYSzGGGPaEebDZacBhzw+5wGzPQuIyHRguKr+TUTuam9BInIbcJv7sUJEdnUzpmSgqJvz+oPFd2YsvjPX22O0+LpvZHsTfJkIOiQiIcAvgaWdlVXV5cDyHljnelXttechLL4zY/Gdud4eo8XnG75sGjoMDPf4nO6OaxYHZAKrRSQXOAdYYSeMjTHGv3yZCNYBY0QkQ0QigOuAFc0TVbVUVZNVdZSqjgLWAotUdb0PYzLGGNOKzxKBqjYAdwDvAjuAF1V1u4jcJyKLfLXeTpxx85KPWXxnxuI7c709RovPB0RVAx2DMcaYALI7i40xJshZIjDGmCDXLxNBZ11biMgAEXnBnf6piIzyY2zDRWSViOSIyHYR+U4bZeaJSKmIbHJfd/srPnf9uSKy1V33aSfvxfGou/22uPeD+Cu2cR7bZZOIlInId1uV8fv2E5EnROSYiGzzGDdQRN4XkT3ue1I78/6bW2aPiPybn2J7SER2un+/V0UksZ15O/wt+DjGe0XksMff8bJ25vWqKxsfxPeCR2y5IrKpnXn9sg3PiKr2qxcQCuwDzgIigM3AxFZlvgn83h2+DnjBj/ENBaa7w3HA7jbimwe8GcBtmAskdzD9MuBtQHAu+/00gH/ro8DIQG8/YC4wHdjmMe5BYJk7vAz4nzbmGwjsd9+T3OEkP8R2MRDmDv9PW7F581vwcYz3Aj/w4jfQ4f+7r+JrNf0XwN2B3IZn8uqPRwTedG1xBfCUO/wyMF9ExB/BqWq+qm50h8txrqhK88e6e9AVwNPqWAskisjQAMQxH9inqgcDsO5TqOoa4Hir0Z6/s6eAK9uY9RLgfVU9rqolwPvAQl/HpqrvqXNlHziXbqf35Dq7qp3t5w1vu7I5Ix3F59YdXwKe6+n1+kt/TARtdW3RuqJtKeP+M5QCg/wSnQe3SWoabXe4d66IbBaRt0Vkkn8jQ4H3RGSD271Ha95sY3+4jvb/+QK5/ZoNVtV8d/goMLiNMr1hW34N5wivLZ39FnztDrf56ol2mtZ6w/abAxSo6p52pgd6G3aqPyaCPkFEYoFXgO+qalmryRtxmjumAL8GXvNzeBeo6nScnmO/JSJz/bz+Trk3KS4CXmpjcqC332nUaSPodddqi8h/AQ3AM+0UCeRv4XfA2cBUIB+n+aU3up6OjwZ6/f9Tf0wEnXVtcUoZEQkDEoBiv0TnrDMcJwk8o6p/bT1dVctUtcIdfgsIF5Fkf8Wnqofd92PAqziH35682ca+dimwUVULWk8I9PbzUNDcZOa+H2ujTMC2pYgsBb4I3OAmqtN48VvwGVUtUNVGVW0CHm9n3QH9Lbr1x9XAC+2VCeQ29FZ/TAQddm3hWgE0X51xLfBhe/8IPc1tT/wTsENVf9lOmSHN5yxEZBbO38kviUpEYsR5RgQiEoNzUnFbq2IrgBvdq4fOAUo9mkD8pd29sEBuv1Y8f2f/BrzeRpl3gYtFJMlt+rjYHedTIrIQ+A+cbl2q2injzW/BlzF6nne6qp11e/P/7ksXATtVNa+tiYHehl4L9NlqX7xwrmrZjXM1wX+54+7D+dEDROI0KewF/gmc5cfYLsBpItgCbHJflwHfAL7hlrkD2I5zBcRa4Dw/xneWu97NbgzN288zPsF56NA+YCuQ7ee/bwxOxZ7gMS6g2w8nKeUD9Tjt1DfjnHf6ANgDrAQGumWzgT96zPs197e4F7jJT7HtxWlbb/4NNl9FNwx4q6Pfgh+331/c39cWnMp9aOsY3c+n/b/7Iz53/JPNvzuPsgHZhmfysi4mjDEmyPXHpiFjjDFdYInAGGOCnCUCY4wJcpYIjDEmyFkiMMaYIGeJwJhWRKRRTu3htMd6tBSRUZ49WBrTG4QFOgBjeqFqVZ0a6CCM8Rc7IjDGS26/8g+6fcv/U0RGu+NHiciHbudoH4jICHf8YLev/83u6zx3UaEi8rg4z6N4T0SiAvaljMESgTFtiWrVNLTEY1qpqmYBvwEeccf9GnhKVSfjdN72qDv+UeD/1On8bjrOnaUAY4DHVHUScAK4xqffxphO2J3FxrQiIhWqGtvG+Fzg86q63+048KiqDhKRIpzuD+rd8fmqmiwihUC6qtZ6LGMUzvMHxriffwiEq+pP/fDVjGmTHREY0zXaznBX1HoMN2Ln6kyAWSIwpmuWeLz/wx3+BKfXS4AbgI/c4Q+A2wFEJFREEvwVpDFdYXsixpwuqtWDyN9R1eZLSJNEZAvOXv317rg7gT+LyF1AIXCTO/47wHIRuRlnz/92nB4sjelV7ByBMV5yzxFkq2pRoGMxpidZ05AxxgQ5OyIwxpggZ0cExhgT5CwRGGNMkLNEYIwxQc4SgTHGBDlLBMYYE+T+fxgYfbKkeYgHAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.4, 0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.47      0.20      0.28       225\n",
            "    Positive       0.80      0.86      0.83       609\n",
            "    Negative       0.59      0.74      0.65       327\n",
            "\n",
            "    accuracy                           0.70      1161\n",
            "   macro avg       0.62      0.60      0.59      1161\n",
            "weighted avg       0.67      0.70      0.67      1161\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpha = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4641\n",
            "valid samples:1161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.38it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.067 valid_loss:1.031\n",
            "\ttrain_acc:50.22% valid_acc:52.63%\n",
            "\ttrain_f1:0.384 valid_f1:0.365\n",
            "\ttrain_confusion_matrix:\n",
            "[[  75  809    3]\n",
            " [ 179 2217   22]\n",
            " [ 106 1175   22]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 325   2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.24it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.008 valid_loss:0.970\n",
            "\ttrain_acc:52.56% valid_acc:52.63%\n",
            "\ttrain_f1:0.365 valid_f1:0.365\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  892    0]\n",
            " [   0 2411    2]\n",
            " [   0 1292   11]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 325   2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.34it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.959 valid_loss:0.913\n",
            "\ttrain_acc:52.91% valid_acc:53.83%\n",
            "\ttrain_f1:0.372 valid_f1:0.395\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  886    1]\n",
            " [   0 2415    4]\n",
            " [   0 1279   23]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 220   5]\n",
            " [  0 606   3]\n",
            " [  0 308  19]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.32it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.883 valid_loss:0.837\n",
            "\ttrain_acc:59.33% valid_acc:63.48%\n",
            "\ttrain_f1:0.506 valid_f1:0.562\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  684  200]\n",
            " [   0 2280  136]\n",
            " [   0  854  454]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 131  94]\n",
            " [  0 548  61]\n",
            " [  0 138 189]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.48it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.817 valid_loss:0.784\n",
            "\ttrain_acc:63.65% valid_acc:64.77%\n",
            "\ttrain_f1:0.570 valid_f1:0.574\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  436  451]\n",
            " [   0 2065  355]\n",
            " [   0  433  868]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 129  96]\n",
            " [  0 556  53]\n",
            " [  0 131 196]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.48it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.792 valid_loss:0.770\n",
            "\ttrain_acc:65.32% valid_acc:65.98%\n",
            "\ttrain_f1:0.586 valid_f1:0.594\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  414  472]\n",
            " [   0 2073  347]\n",
            " [   0  365  937]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  89 136]\n",
            " [  0 517  92]\n",
            " [  0  78 249]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.54it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.764 valid_loss:0.745\n",
            "\ttrain_acc:66.97% valid_acc:66.84%\n",
            "\ttrain_f1:0.599 valid_f1:0.597\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  440  445]\n",
            " [   0 2143  280]\n",
            " [   0  357  943]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 114 111]\n",
            " [  0 548  61]\n",
            " [  1  98 228]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.50it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.745 valid_loss:0.740\n",
            "\ttrain_acc:67.73% valid_acc:67.10%\n",
            "\ttrain_f1:0.611 valid_f1:0.598\n",
            "\ttrain_confusion_matrix:\n",
            "[[   9  408  473]\n",
            " [   3 2106  304]\n",
            " [   1  298 1006]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  1 125  99]\n",
            " [  0 561  48]\n",
            " [  1 109 217]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.38it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.740 valid_loss:0.724\n",
            "\ttrain_acc:67.86% valid_acc:67.79%\n",
            "\ttrain_f1:0.615 valid_f1:0.612\n",
            "\ttrain_confusion_matrix:\n",
            "[[  16  389  480]\n",
            " [   7 2076  333]\n",
            " [   2  270 1035]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  4 101 120]\n",
            " [  0 546  63]\n",
            " [  3  87 237]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.29it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.729 valid_loss:0.704\n",
            "\ttrain_acc:68.64% valid_acc:68.65%\n",
            "\ttrain_f1:0.632 valid_f1:0.626\n",
            "\ttrain_confusion_matrix:\n",
            "[[  53  398  438]\n",
            " [  20 2109  288]\n",
            " [  11  290 1001]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  6  85 134]\n",
            " [  1 525  83]\n",
            " [  1  60 266]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.27it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.713 valid_loss:0.705\n",
            "\ttrain_acc:69.25% valid_acc:69.16%\n",
            "\ttrain_f1:0.639 valid_f1:0.638\n",
            "\ttrain_confusion_matrix:\n",
            "[[  58  384  448]\n",
            " [  20 2106  291]\n",
            " [  10  264 1027]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 15  94 116]\n",
            " [  2 536  71]\n",
            " [  3  72 252]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.31it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.699 valid_loss:0.695\n",
            "\ttrain_acc:70.14% valid_acc:69.77%\n",
            "\ttrain_f1:0.651 valid_f1:0.648\n",
            "\ttrain_confusion_matrix:\n",
            "[[  74  395  419]\n",
            " [  29 2127  260]\n",
            " [  15  258 1031]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 20  92 113]\n",
            " [  4 537  68]\n",
            " [  3  71 253]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:19<00:00,  1.82it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.686 valid_loss:0.696\n",
            "\ttrain_acc:71.14% valid_acc:69.34%\n",
            "\ttrain_f1:0.666 valid_f1:0.652\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 101  406  384]\n",
            " [  33 2150  234]\n",
            " [  25  248 1027]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 26  85 114]\n",
            " [  9 534  66]\n",
            " [  9  73 245]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.72it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.679 valid_loss:0.692\n",
            "\ttrain_acc:71.27% valid_acc:69.42%\n",
            "\ttrain_f1:0.678 valid_f1:0.661\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 142  358  387]\n",
            " [  57 2116  247]\n",
            " [  55  220 1026]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 34  81 110]\n",
            " [ 19 526  64]\n",
            " [ 14  67 246]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.72it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.670 valid_loss:0.685\n",
            "\ttrain_acc:71.88% valid_acc:69.51%\n",
            "\ttrain_f1:0.685 valid_f1:0.661\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 155  374  360]\n",
            " [  55 2135  225]\n",
            " [  53  229 1022]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 36  88 101]\n",
            " [ 19 531  59]\n",
            " [ 12  75 240]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.66it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.660 valid_loss:0.685\n",
            "\ttrain_acc:72.44% valid_acc:70.37%\n",
            "\ttrain_f1:0.695 valid_f1:0.672\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 182  363  342]\n",
            " [  68 2146  209]\n",
            " [  64  224 1010]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 41  93  91]\n",
            " [ 21 538  50]\n",
            " [ 13  76 238]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.69it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.650 valid_loss:0.672\n",
            "\ttrain_acc:73.09% valid_acc:70.37%\n",
            "\ttrain_f1:0.707 valid_f1:0.673\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 220  332  336]\n",
            " [  82 2141  196]\n",
            " [  80  214 1007]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 40  80 105]\n",
            " [ 17 527  65]\n",
            " [ 14  63 250]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.74it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.654 valid_loss:0.693\n",
            "\ttrain_acc:73.00% valid_acc:69.51%\n",
            "\ttrain_f1:0.707 valid_f1:0.675\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 221  336  332]\n",
            " [  79 2127  214]\n",
            " [  80  203 1016]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 54  72  99]\n",
            " [ 30 519  60]\n",
            " [ 22  71 234]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.74it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.645 valid_loss:0.678\n",
            "\ttrain_acc:73.31% valid_acc:69.77%\n",
            "\ttrain_f1:0.713 valid_f1:0.676\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 233  298  350]\n",
            " [ 104 2104  213]\n",
            " [  80  185 1041]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 56  86  83]\n",
            " [ 26 532  51]\n",
            " [ 31  74 222]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.64it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.637 valid_loss:0.671\n",
            "\ttrain_acc:73.87% valid_acc:70.63%\n",
            "\ttrain_f1:0.719 valid_f1:0.684\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 256  325  305]\n",
            " [  90 2144  186]\n",
            " [ 100  198 1004]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 54  79  92]\n",
            " [ 25 528  56]\n",
            " [ 20  69 238]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 0.4), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        l_feature, g_feature, label = data\n",
        "        l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(l_feature, g_feature)\n",
        "        loss = loss_fn(pred_logits, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds,labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "            loss = loss_fn(pred_logits, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds,  labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n",
        "        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4, 0.9)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.4, 0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.52      0.24      0.33       225\n",
            "    Positive       0.78      0.86      0.82       609\n",
            "    Negative       0.62      0.72      0.67       327\n",
            "\n",
            "    accuracy                           0.70      1161\n",
            "   macro avg       0.64      0.61      0.61      1161\n",
            "weighted avg       0.68      0.70      0.68      1161\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpha = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4641\n",
            "valid samples:1161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.67it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.067 valid_loss:1.025\n",
            "\ttrain_acc:46.44% valid_acc:52.71%\n",
            "\ttrain_f1:0.413 valid_f1:0.367\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  588  295]\n",
            " [   1 1673  751]\n",
            " [   0  833  467]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 224   1]\n",
            " [  0 609   0]\n",
            " [  0 324   3]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.72it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.006 valid_loss:0.970\n",
            "\ttrain_acc:52.56% valid_acc:52.54%\n",
            "\ttrain_f1:0.366 valid_f1:0.363\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  889    0]\n",
            " [   0 2410    4]\n",
            " [   0 1293   12]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 326   1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:19<00:00,  1.86it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.961 valid_loss:0.919\n",
            "\ttrain_acc:52.71% valid_acc:52.89%\n",
            "\ttrain_f1:0.368 valid_f1:0.371\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  887    1]\n",
            " [   0 2412    4]\n",
            " [   0 1287   17]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 221   4]\n",
            " [  0 609   0]\n",
            " [  0 322   5]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.58it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.892 valid_loss:0.845\n",
            "\ttrain_acc:58.12% valid_acc:63.05%\n",
            "\ttrain_f1:0.486 valid_f1:0.560\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  721  170]\n",
            " [   0 2312  107]\n",
            " [   0  932  366]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 116 109]\n",
            " [  0 538  71]\n",
            " [  0 133 194]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.60it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.830 valid_loss:0.780\n",
            "\ttrain_acc:63.76% valid_acc:64.08%\n",
            "\ttrain_f1:0.571 valid_f1:0.574\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  428  462]\n",
            " [   0 2073  344]\n",
            " [   0  436  865]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  94 131]\n",
            " [  0 527  82]\n",
            " [  0 110 217]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.49it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.792 valid_loss:0.772\n",
            "\ttrain_acc:65.06% valid_acc:66.24%\n",
            "\ttrain_f1:0.586 valid_f1:0.600\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  380  507]\n",
            " [   0 2034  386]\n",
            " [   0  337  964]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  66 159]\n",
            " [  0 511  98]\n",
            " [  0  69 258]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.46it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.772 valid_loss:0.742\n",
            "\ttrain_acc:66.08% valid_acc:67.18%\n",
            "\ttrain_f1:0.595 valid_f1:0.607\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  374  514]\n",
            " [   0 2046  373]\n",
            " [   0  302  999]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  1  83 141]\n",
            " [  0 521  88]\n",
            " [  0  69 258]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.47it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.755 valid_loss:0.746\n",
            "\ttrain_acc:66.91% valid_acc:67.44%\n",
            "\ttrain_f1:0.603 valid_f1:0.603\n",
            "\ttrain_confusion_matrix:\n",
            "[[   5  377  507]\n",
            " [   0 2064  354]\n",
            " [   0  287 1014]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  3 116 106]\n",
            " [  0 564  45]\n",
            " [  0 111 216]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.42it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.740 valid_loss:0.719\n",
            "\ttrain_acc:68.36% valid_acc:68.30%\n",
            "\ttrain_f1:0.621 valid_f1:0.617\n",
            "\ttrain_confusion_matrix:\n",
            "[[  22  390  478]\n",
            " [   4 2107  304]\n",
            " [   2  280 1021]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  3  97 125]\n",
            " [  3 535  71]\n",
            " [  1  71 255]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.19it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.725 valid_loss:0.717\n",
            "\ttrain_acc:69.16% valid_acc:68.91%\n",
            "\ttrain_f1:0.631 valid_f1:0.628\n",
            "\ttrain_confusion_matrix:\n",
            "[[  32  394  461]\n",
            " [  10 2125  283]\n",
            " [   3  270 1030]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  7  89 129]\n",
            " [  1 532  76]\n",
            " [  1  65 261]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.55it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.714 valid_loss:0.715\n",
            "\ttrain_acc:69.42% valid_acc:68.48%\n",
            "\ttrain_f1:0.637 valid_f1:0.629\n",
            "\ttrain_confusion_matrix:\n",
            "[[  48  386  458]\n",
            " [   8 2123  283]\n",
            " [  11  263 1028]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 11  92 122]\n",
            " [  5 529  75]\n",
            " [  4  68 255]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.32it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.699 valid_loss:0.702\n",
            "\ttrain_acc:70.51% valid_acc:69.16%\n",
            "\ttrain_f1:0.654 valid_f1:0.638\n",
            "\ttrain_confusion_matrix:\n",
            "[[  70  373  441]\n",
            " [  16 2136  270]\n",
            " [  14  245 1043]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 15 103 107]\n",
            " [  6 541  62]\n",
            " [  7  73 247]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.39it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.689 valid_loss:0.703\n",
            "\ttrain_acc:70.92% valid_acc:69.16%\n",
            "\ttrain_f1:0.665 valid_f1:0.643\n",
            "\ttrain_confusion_matrix:\n",
            "[[  98  353  438]\n",
            " [  29 2126  264]\n",
            " [  23  233 1044]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 21 109  95]\n",
            " [  8 550  51]\n",
            " [ 13  82 232]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.35it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.677 valid_loss:0.689\n",
            "\ttrain_acc:71.85% valid_acc:70.37%\n",
            "\ttrain_f1:0.681 valid_f1:0.669\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 136  358  392]\n",
            " [  40 2147  227]\n",
            " [  30  250 1028]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 36  86 103]\n",
            " [ 11 535  63]\n",
            " [ 16  65 246]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.50it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.667 valid_loss:0.679\n",
            "\ttrain_acc:72.20% valid_acc:70.46%\n",
            "\ttrain_f1:0.691 valid_f1:0.669\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 170  336  382]\n",
            " [  58 2138  225]\n",
            " [  61  219 1019]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 32  79 114]\n",
            " [ 11 528  70]\n",
            " [ 14  55 258]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.39it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.654 valid_loss:0.682\n",
            "\ttrain_acc:72.74% valid_acc:70.03%\n",
            "\ttrain_f1:0.701 valid_f1:0.680\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 199  316  370]\n",
            " [  67 2127  228]\n",
            " [  62  213 1026]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 53  80  92]\n",
            " [ 27 522  60]\n",
            " [ 33  56 238]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.12it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.648 valid_loss:0.688\n",
            "\ttrain_acc:73.09% valid_acc:69.16%\n",
            "\ttrain_f1:0.709 valid_f1:0.667\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 231  310  350]\n",
            " [  88 2118  213]\n",
            " [  85  194 1019]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 46  89  90]\n",
            " [ 24 528  57]\n",
            " [ 34  64 229]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.32it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.638 valid_loss:0.678\n",
            "\ttrain_acc:73.81% valid_acc:70.28%\n",
            "\ttrain_f1:0.719 valid_f1:0.681\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 253  299  337]\n",
            " [  95 2128  193]\n",
            " [  93  190 1020]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 54  89  82]\n",
            " [ 27 536  46]\n",
            " [ 33  68 226]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.37it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.628 valid_loss:0.669\n",
            "\ttrain_acc:74.46% valid_acc:70.28%\n",
            "\ttrain_f1:0.727 valid_f1:0.681\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 275  298  318]\n",
            " [  94 2144  177]\n",
            " [ 111  179 1012]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 53  81  91]\n",
            " [ 28 530  51]\n",
            " [ 30  64 233]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.06it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.617 valid_loss:0.679\n",
            "\ttrain_acc:74.61% valid_acc:69.68%\n",
            "\ttrain_f1:0.730 valid_f1:0.677\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 282  281  324]\n",
            " [  95 2145  177]\n",
            " [ 119  174 1011]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 53  73  99]\n",
            " [ 26 513  70]\n",
            " [ 27  57 243]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 0.6), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        l_feature, g_feature, label = data\n",
        "        l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(l_feature, g_feature)\n",
        "        loss = loss_fn(pred_logits, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds,labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "            loss = loss_fn(pred_logits, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds,  labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n",
        "        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4, 0.9)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.4, 0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.49      0.23      0.31       225\n",
            "    Positive       0.78      0.87      0.82       609\n",
            "    Negative       0.63      0.72      0.67       327\n",
            "\n",
            "    accuracy                           0.70      1161\n",
            "   macro avg       0.63      0.61      0.60      1161\n",
            "weighted avg       0.68      0.70      0.68      1161\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpha = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4641\n",
            "valid samples:1161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.08it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.064 valid_loss:1.026\n",
            "\ttrain_acc:49.57% valid_acc:52.54%\n",
            "\ttrain_f1:0.428 valid_f1:0.364\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  644  243]\n",
            " [   1 1903  516]\n",
            " [   0  920  381]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 608   1]\n",
            " [  0 325   2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.45it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.001 valid_loss:0.964\n",
            "\ttrain_acc:52.58% valid_acc:52.63%\n",
            "\ttrain_f1:0.364 valid_f1:0.365\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  891    0]\n",
            " [   0 2417    2]\n",
            " [   0 1292    6]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 325   2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.951 valid_loss:0.904\n",
            "\ttrain_acc:52.95% valid_acc:53.57%\n",
            "\ttrain_f1:0.374 valid_f1:0.391\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  887    2]\n",
            " [   0 2411    4]\n",
            " [   0 1275   29]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 217   8]\n",
            " [  0 605   4]\n",
            " [  0 310  17]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:22<00:00,  1.63it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.880 valid_loss:0.839\n",
            "\ttrain_acc:60.26% valid_acc:63.39%\n",
            "\ttrain_f1:0.519 valid_f1:0.561\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  663  226]\n",
            " [   0 2267  150]\n",
            " [   0  792  510]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 128  97]\n",
            " [  0 550  59]\n",
            " [  0 141 186]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.76it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.824 valid_loss:0.781\n",
            "\ttrain_acc:63.98% valid_acc:65.55%\n",
            "\ttrain_f1:0.572 valid_f1:0.593\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  450  439]\n",
            " [   0 2087  331]\n",
            " [   0  440  861]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  75 150]\n",
            " [  0 505 104]\n",
            " [  0  71 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.70it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.788 valid_loss:0.738\n",
            "\ttrain_acc:65.76% valid_acc:67.53%\n",
            "\ttrain_f1:0.592 valid_f1:0.605\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  370  518]\n",
            " [   0 2033  386]\n",
            " [   0  304  997]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  99 126]\n",
            " [  0 539  70]\n",
            " [  0  82 245]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.64it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.765 valid_loss:0.723\n",
            "\ttrain_acc:66.80% valid_acc:67.79%\n",
            "\ttrain_f1:0.601 valid_f1:0.609\n",
            "\ttrain_confusion_matrix:\n",
            "[[   2  396  492]\n",
            " [   0 2073  342]\n",
            " [   0  300 1003]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  94 131]\n",
            " [  0 531  78]\n",
            " [  0  71 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.72it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.749 valid_loss:0.713\n",
            "\ttrain_acc:67.71% valid_acc:68.56%\n",
            "\ttrain_f1:0.609 valid_f1:0.617\n",
            "\ttrain_confusion_matrix:\n",
            "[[   4  406  476]\n",
            " [   0 2106  312]\n",
            " [   0  294 1010]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  1  93 131]\n",
            " [  0 538  71]\n",
            " [  0  70 257]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.76it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.732 valid_loss:0.700\n",
            "\ttrain_acc:68.40% valid_acc:69.08%\n",
            "\ttrain_f1:0.619 valid_f1:0.627\n",
            "\ttrain_confusion_matrix:\n",
            "[[  13  390  482]\n",
            " [   2 2106  312]\n",
            " [   1  269 1033]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  5  88 132]\n",
            " [  0 532  77]\n",
            " [  1  61 265]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.74it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.721 valid_loss:0.696\n",
            "\ttrain_acc:69.08% valid_acc:69.51%\n",
            "\ttrain_f1:0.629 valid_f1:0.635\n",
            "\ttrain_confusion_matrix:\n",
            "[[  30  386  476]\n",
            " [   1 2118  291]\n",
            " [   3  268 1035]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 12 109 104]\n",
            " [  0 549  60]\n",
            " [  2  79 246]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.75it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.709 valid_loss:0.694\n",
            "\ttrain_acc:70.03% valid_acc:69.51%\n",
            "\ttrain_f1:0.644 valid_f1:0.638\n",
            "\ttrain_confusion_matrix:\n",
            "[[  51  390  447]\n",
            " [  11 2160  251]\n",
            " [  15  267 1016]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 14 109 102]\n",
            " [  1 552  56]\n",
            " [  4  82 241]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.75it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.702 valid_loss:0.682\n",
            "\ttrain_acc:70.23% valid_acc:70.80%\n",
            "\ttrain_f1:0.652 valid_f1:0.664\n",
            "\ttrain_confusion_matrix:\n",
            "[[  73  389  426]\n",
            " [  19 2140  259]\n",
            " [  30  249 1023]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 24  80 121]\n",
            " [  5 528  76]\n",
            " [  7  50 270]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.74it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.687 valid_loss:0.678\n",
            "\ttrain_acc:70.99% valid_acc:70.63%\n",
            "\ttrain_f1:0.666 valid_f1:0.663\n",
            "\ttrain_confusion_matrix:\n",
            "[[  98  366  425]\n",
            " [  31 2131  256]\n",
            " [  35  224 1042]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 25  84 116]\n",
            " [  7 527  75]\n",
            " [  7  52 268]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.04it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.679 valid_loss:0.667\n",
            "\ttrain_acc:71.88% valid_acc:70.89%\n",
            "\ttrain_f1:0.682 valid_f1:0.672\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 139  353  399]\n",
            " [  45 2142  233]\n",
            " [  48  218 1031]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 33  84 108]\n",
            " [ 13 534  62]\n",
            " [ 12  59 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.54it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.668 valid_loss:0.663\n",
            "\ttrain_acc:72.70% valid_acc:70.89%\n",
            "\ttrain_f1:0.695 valid_f1:0.675\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 168  338  385]\n",
            " [  52 2145  217]\n",
            " [  60  206 1037]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 35  85 105]\n",
            " [ 14 533  62]\n",
            " [ 18  54 255]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.19it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.658 valid_loss:0.666\n",
            "\ttrain_acc:72.55% valid_acc:70.71%\n",
            "\ttrain_f1:0.695 valid_f1:0.679\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 169  341  376]\n",
            " [  67 2145  205]\n",
            " [  65  211 1029]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 42  78 105]\n",
            " [ 17 526  66]\n",
            " [ 19  55 253]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.44it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.649 valid_loss:0.662\n",
            "\ttrain_acc:73.07% valid_acc:71.06%\n",
            "\ttrain_f1:0.706 valid_f1:0.679\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 211  323  356]\n",
            " [  79 2136  201]\n",
            " [  85  197 1020]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 38  74 113]\n",
            " [ 14 524  71]\n",
            " [ 14  50 263]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.44it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.643 valid_loss:0.657\n",
            "\ttrain_acc:73.48% valid_acc:70.97%\n",
            "\ttrain_f1:0.713 valid_f1:0.679\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 228  314  348]\n",
            " [  85 2127  202]\n",
            " [  88  185 1031]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 39  80 106]\n",
            " [ 16 530  63]\n",
            " [ 18  54 255]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.15it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.633 valid_loss:0.651\n",
            "\ttrain_acc:74.18% valid_acc:70.03%\n",
            "\ttrain_f1:0.721 valid_f1:0.675\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 241  313  332]\n",
            " [  85 2134  204]\n",
            " [  87  169 1043]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 44  73 108]\n",
            " [ 25 520  64]\n",
            " [ 24  54 249]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.53it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.624 valid_loss:0.646\n",
            "\ttrain_acc:74.52% valid_acc:71.15%\n",
            "\ttrain_f1:0.726 valid_f1:0.685\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 251  301  335]\n",
            " [  82 2147  187]\n",
            " [ 101  168 1036]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 45  77 103]\n",
            " [ 16 530  63]\n",
            " [ 23  53 251]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 0.8), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        l_feature, g_feature, label = data\n",
        "        l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(l_feature, g_feature)\n",
        "        loss = loss_fn(pred_logits, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds,labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "            loss = loss_fn(pred_logits, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds,  labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n",
        "        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4, 0.9)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.4, 0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.49      0.19      0.27       225\n",
            "    Positive       0.80      0.87      0.83       609\n",
            "    Negative       0.60      0.76      0.67       327\n",
            "\n",
            "    accuracy                           0.70      1161\n",
            "   macro avg       0.63      0.60      0.59      1161\n",
            "weighted avg       0.68      0.70      0.68      1161\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpha = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4641\n",
            "valid samples:1161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.11it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.071 valid_loss:1.031\n",
            "\ttrain_acc:48.09% valid_acc:52.54%\n",
            "\ttrain_f1:0.377 valid_f1:0.363\n",
            "\ttrain_confusion_matrix:\n",
            "[[  88  782   20]\n",
            " [ 266 2100   47]\n",
            " [ 119 1158   28]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 326   1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:09<00:00,  3.61it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.011 valid_loss:0.974\n",
            "\ttrain_acc:52.50% valid_acc:52.54%\n",
            "\ttrain_f1:0.363 valid_f1:0.363\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  894    0]\n",
            " [   0 2411    0]\n",
            " [   0 1295    8]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 225   0]\n",
            " [  0 609   0]\n",
            " [  0 326   1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.17it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.968 valid_loss:0.926\n",
            "\ttrain_acc:52.80% valid_acc:52.71%\n",
            "\ttrain_f1:0.369 valid_f1:0.368\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  887    0]\n",
            " [   0 2418    3]\n",
            " [   0 1285   15]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 224   1]\n",
            " [  0 608   1]\n",
            " [  0 323   4]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.05it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.911 valid_loss:0.868\n",
            "\ttrain_acc:56.73% valid_acc:62.19%\n",
            "\ttrain_f1:0.456 valid_f1:0.539\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  806   85]\n",
            " [   0 2367   48]\n",
            " [   0 1055  247]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 157  68]\n",
            " [  0 578  31]\n",
            " [  0 183 144]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.25it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.848 valid_loss:0.808\n",
            "\ttrain_acc:62.57% valid_acc:64.25%\n",
            "\ttrain_f1:0.557 valid_f1:0.580\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  489  399]\n",
            " [   0 2101  315]\n",
            " [   0  522  782]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  86 139]\n",
            " [  0 500 109]\n",
            " [  0  81 246]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.73it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.806 valid_loss:0.771\n",
            "\ttrain_acc:64.63% valid_acc:65.03%\n",
            "\ttrain_f1:0.579 valid_f1:0.589\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  412  478]\n",
            " [   0 2070  343]\n",
            " [   0  397  908]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  74 151]\n",
            " [  0 499 110]\n",
            " [  0  71 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:24<00:00,  1.50it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.781 valid_loss:0.751\n",
            "\ttrain_acc:65.89% valid_acc:66.06%\n",
            "\ttrain_f1:0.594 valid_f1:0.591\n",
            "\ttrain_confusion_matrix:\n",
            "[[   4  386  498]\n",
            " [   0 2037  379]\n",
            " [   0  309  995]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  1 116 108]\n",
            " [  0 539  70]\n",
            " [  1  99 227]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:25<00:00,  1.42it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.763 valid_loss:0.731\n",
            "\ttrain_acc:67.17% valid_acc:67.61%\n",
            "\ttrain_f1:0.607 valid_f1:0.609\n",
            "\ttrain_confusion_matrix:\n",
            "[[  14  427  449]\n",
            " [   1 2087  325]\n",
            " [   3  308  994]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  1 104 120]\n",
            " [  1 527  81]\n",
            " [  2  68 257]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:23<00:00,  1.56it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.744 valid_loss:0.733\n",
            "\ttrain_acc:68.25% valid_acc:67.96%\n",
            "\ttrain_f1:0.620 valid_f1:0.612\n",
            "\ttrain_confusion_matrix:\n",
            "[[  25  405  457]\n",
            " [   2 2101  313]\n",
            " [   3  283 1019]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  4 125  96]\n",
            " [  4 554  51]\n",
            " [  2  94 231]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:23<00:00,  1.56it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.732 valid_loss:0.728\n",
            "\ttrain_acc:69.21% valid_acc:68.22%\n",
            "\ttrain_f1:0.635 valid_f1:0.621\n",
            "\ttrain_confusion_matrix:\n",
            "[[  47  411  430]\n",
            " [  12 2117  286]\n",
            " [   9  271 1025]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 11 119  95]\n",
            " [  4 556  49]\n",
            " [  3  99 225]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:21<00:00,  1.68it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.715 valid_loss:0.709\n",
            "\ttrain_acc:69.97% valid_acc:69.51%\n",
            "\ttrain_f1:0.647 valid_f1:0.647\n",
            "\ttrain_confusion_matrix:\n",
            "[[  67  410  409]\n",
            " [  16 2149  255]\n",
            " [  15  279 1008]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 20 104 101]\n",
            " [  7 537  65]\n",
            " [  9  68 250]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.75it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.704 valid_loss:0.704\n",
            "\ttrain_acc:70.86% valid_acc:70.97%\n",
            "\ttrain_f1:0.666 valid_f1:0.666\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 106  385  395]\n",
            " [  34 2136  246]\n",
            " [  34  249 1023]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 28 107  90]\n",
            " [  4 551  54]\n",
            " [ 13  69 245]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.76it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.691 valid_loss:0.703\n",
            "\ttrain_acc:71.35% valid_acc:69.42%\n",
            "\ttrain_f1:0.677 valid_f1:0.663\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 144  377  369]\n",
            " [  46 2141  232]\n",
            " [  42  254 1003]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 35  77 113]\n",
            " [ 12 513  84]\n",
            " [ 16  53 258]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.73it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.681 valid_loss:0.695\n",
            "\ttrain_acc:71.81% valid_acc:71.23%\n",
            "\ttrain_f1:0.687 valid_f1:0.678\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 168  354  365]\n",
            " [  55 2109  253]\n",
            " [  55  217 1032]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 39  98  88]\n",
            " [  9 549  51]\n",
            " [ 22  66 239]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:20<00:00,  1.75it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.673 valid_loss:0.692\n",
            "\ttrain_acc:72.48% valid_acc:70.63%\n",
            "\ttrain_f1:0.698 valid_f1:0.684\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 198  336  353]\n",
            " [  71 2120  230]\n",
            " [  58  220 1022]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 51  81  93]\n",
            " [ 21 525  63]\n",
            " [ 28  55 244]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:15<00:00,  2.29it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.659 valid_loss:0.687\n",
            "\ttrain_acc:73.11% valid_acc:70.63%\n",
            "\ttrain_f1:0.709 valid_f1:0.685\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 229  328  329]\n",
            " [  94 2129  195]\n",
            " [  86  207 1011]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 53  79  93]\n",
            " [ 22 525  62]\n",
            " [ 30  55 242]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.54it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.654 valid_loss:0.677\n",
            "\ttrain_acc:73.20% valid_acc:71.06%\n",
            "\ttrain_f1:0.713 valid_f1:0.684\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 254  309  327]\n",
            " [ 100 2122  196]\n",
            " [  90  213  997]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 48  80  97]\n",
            " [  8 532  69]\n",
            " [ 24  58 245]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:09<00:00,  3.62it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.644 valid_loss:0.684\n",
            "\ttrain_acc:73.57% valid_acc:71.49%\n",
            "\ttrain_f1:0.716 valid_f1:0.694\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 251  323  311]\n",
            " [  91 2136  192]\n",
            " [  83  218 1003]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 57  77  91]\n",
            " [ 18 527  64]\n",
            " [ 27  54 246]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:11<00:00,  3.23it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.636 valid_loss:0.669\n",
            "\ttrain_acc:74.13% valid_acc:71.15%\n",
            "\ttrain_f1:0.725 valid_f1:0.685\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 281  300  306]\n",
            " [ 112 2122  185]\n",
            " [  97  192 1013]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 49  83  93]\n",
            " [ 12 535  62]\n",
            " [ 23  62 242]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 36/36 [00:10<00:00,  3.38it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.628 valid_loss:0.676\n",
            "\ttrain_acc:74.22% valid_acc:71.40%\n",
            "\ttrain_f1:0.725 valid_f1:0.687\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 267  307  314]\n",
            " [ 106 2131  183]\n",
            " [  97  181 1022]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 48  85  92]\n",
            " [ 16 539  54]\n",
            " [ 25  60 242]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 1), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        l_feature, g_feature, label = data\n",
        "        l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(l_feature, g_feature)\n",
        "        loss = loss_fn(pred_logits, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds,labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "            loss = loss_fn(pred_logits, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds,  labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n",
        "        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4, 0.9)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.4, 0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/3c/71b8pg6d7j5dht_5h_2n4n_c0000gn/T/ipykernel_14530/3235636334.py:164: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.nn.functional.log_softmax(out)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.57      0.21      0.31       225\n",
            "    Positive       0.79      0.88      0.83       609\n",
            "    Negative       0.61      0.75      0.67       327\n",
            "\n",
            "    accuracy                           0.71      1161\n",
            "   macro avg       0.66      0.61      0.60      1161\n",
            "weighted avg       0.70      0.71      0.69      1161\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task2_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
