{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVlBRwsjo3A9",
        "outputId": "c73353d2-d0e0-46ab-cb7b-742f72aa0104"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext\n",
        "#!pip install transformers\n",
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "#!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0eHpAwJZTqff"
      },
      "outputs": [],
      "source": [
        "DATA_DIR =  './data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f_ihgOgKQQ5e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.optim import AdamW\n",
        "from fasttext import load_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MIElcOeLQVR0"
      },
      "outputs": [],
      "source": [
        "VALID_SIZE = .2\n",
        "\n",
        "\n",
        "# generate word_index list\n",
        "def build_vocab(data_dir, plain=[]):\n",
        "    \"\"\"plain is a empty str file which will record all text from official dataset\"\"\"\n",
        "    for fn in os.listdir(data_dir):\n",
        "        if fn.endswith('.xml'):\n",
        "            with open(data_dir + fn) as f:\n",
        "                dom = ET.parse(f)\n",
        "                root = dom.getroot()\n",
        "                for sent in root.iter(\"sentence\"):\n",
        "                    text = sent.find('text').text.lower()\n",
        "                    token = word_tokenize(text)\n",
        "                    plain = plain + token\n",
        "    vocab = sorted(set(plain))\n",
        "    with open(os.path.join(data_dir, \"plain.txt\"), \"w+\", encoding=\"utf8\") as f:\n",
        "        for v in vocab:\n",
        "            f.write(f\"{v}\\n\")\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(vocab):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "dict_polarity = {'non-aspect':0, 'positive':1,'neutral':2, 'negative':3}\n",
        "def create_train_data_restaurant(fn, word_idx, sent_len=83):\n",
        "    dom = ET.parse(fn)\n",
        "    root = dom.getroot()\n",
        "    train_X = np.zeros((len(root), sent_len), np.int16)\n",
        "    mask = np.zeros_like(train_X)\n",
        "\n",
        "    train_y = np.zeros((len(root), sent_len), np.int16)\n",
        "    train_y_polarity = np.zeros((len(root), sent_len), np.int16)\n",
        "    take = np.ones(len(root), dtype=bool)\n",
        "\n",
        "    dom = ET.parse(fn)\n",
        "    root = dom.getroot()\n",
        "    # iterate the sentence\n",
        "    for sx, sent in enumerate(root.iter(\"sentence\")):\n",
        "        # TODO temporary to compare this and transformers\n",
        "        if not [_ for _ in sent.iter(\"aspectTerm\")]:\n",
        "            take[sx] = False\n",
        "            continue\n",
        "        text = sent.find('text').text.lower()\n",
        "        # tokenize the current sentence\n",
        "        token = word_tokenize(text)\n",
        "\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(token):\n",
        "                train_X[sx, wx] = word_idx[word]\n",
        "                mask[sx, wx] = 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "        for ox, apin in enumerate(sent.iter('aspectTerms')):\n",
        "            for ax, opin in enumerate(apin.iter('aspectTerm')):\n",
        "                target, polarity, start, end = opin.attrib['term'], opin.attrib['polarity'], int(\n",
        "                    opin.attrib['from']), int(opin.attrib['to'])\n",
        "\n",
        "                if polarity == 'conflict':\n",
        "                    continue\n",
        "\n",
        "                # find word index (instead of str index) if start,end is not (0,0)\n",
        "                if end != 0:\n",
        "                    if start != 0:\n",
        "                        start = len(word_tokenize(text[:start]))\n",
        "                    end = len(word_tokenize(text[:end])) - 1\n",
        "                    # for training only identify aspect word, but not polarity\n",
        "                    train_y[sx, start] = 1\n",
        "                    train_y_polarity[sx, start] = dict_polarity[polarity]\n",
        "                    if end > start:\n",
        "                        # train_y[sx, start + 1:end] = 2\n",
        "                        train_y[sx, start + 1:end] = 1\n",
        "                        train_y_polarity[sx, start + 1:end] = dict_polarity[polarity]\n",
        "\n",
        "    return (train_X[take], mask[take]), train_y[take], train_y_polarity[take]\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, mask, label):\n",
        "    label.masked_fill_(~mask, -100)\n",
        "    pred = pred.view(-1, 4)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label, weight = torch.tensor([2, 0.3,0.3,0.3]))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, mask, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        mask = torch.cat(mask, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    pred_tags = pred_tags[mask]\n",
        "    true_tags = true_tags[mask]\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1, 2, 3], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "\n",
        "    return acc, f1, cm\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, domain_emb, num_classes=5, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
        "        self.gen_embedding.weight = torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
        "        self.domain_embedding = torch.nn.Embedding(domain_emb.shape[0], domain_emb.shape[1])\n",
        "        self.domain_embedding.weight = torch.nn.Parameter(torch.from_numpy(domain_emb), requires_grad=False)\n",
        "        self.conv1 = torch.nn.Conv1d(gen_emb.shape[1] + domain_emb.shape[1], 128, 5, padding=2)\n",
        "        self.conv2 = torch.nn.Conv1d(gen_emb.shape[1] + domain_emb.shape[1], 128, 3, padding=1)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv1d(256, 256, 5, padding=2)\n",
        "        self.conv4 = torch.nn.Conv1d(256, 256, 5, padding=2)\n",
        "        self.conv5 = torch.nn.Conv1d(256, 256, 5, padding=2)\n",
        "\n",
        "        self.lstm = nn.LSTM(256, hidden_size=128, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.linear_ae = torch.nn.Linear(256, 2)\n",
        "\n",
        "        #aspect sentiment analysis\n",
        "        self.embed = nn.Embedding.from_pretrained(torch.tensor(gen_emb, dtype=torch.float))\n",
        "        self.lstm_l = nn.LSTM(gen_emb.shape[1], hidden_size=128, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.lstm_r = nn.LSTM(gen_emb.shape[1],hidden_size=128, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.dense = nn.Linear(128*2, 3)\n",
        "\n",
        "\n",
        "    def forward(self, x_train):\n",
        "    \n",
        "        x_emb = torch.cat((self.gen_embedding(x_train), self.domain_embedding(x_train)), dim=2)\n",
        "        x_emb = self.dropout(x_emb).transpose(1, 2)\n",
        "\n",
        "        x_conv = torch.nn.functional.relu(torch.cat((self.conv1(x_emb.float()), self.conv2(x_emb.float())), dim=1))\n",
        "        x_conv = self.dropout(x_conv)\n",
        "\n",
        "        x_conv = torch.nn.functional.relu(self.conv3(x_conv))\n",
        "        x_conv = self.dropout(x_conv)\n",
        "\n",
        "        x_conv = torch.nn.functional.relu(self.conv4(x_conv))\n",
        "        x_conv = self.dropout(x_conv)\n",
        "\n",
        "        x_conv = torch.nn.functional.relu(self.conv5(x_conv))\n",
        "        x_conv = x_conv.transpose(1, 2)\n",
        "\n",
        "        x_lstm, (hidden, cell) = self.lstm(x_conv)\n",
        "\n",
        "        x_logit = self.linear_ae(x_lstm)\n",
        "\n",
        "        n1 = len(x_train)\n",
        "        n2 = len(x_train[0])\n",
        "\n",
        "        # for each sentence, convert a word to a vector of [0, 0, 0, 0] which corresponding to [non-aspect, positive, neutral, negative]\n",
        "        # then perform td-lstm\n",
        "        # example: sentence = 'the food is amazing but ambience is bad in the restaurant'\n",
        "        # we have two aspects (food, ambience)\n",
        "        # hence, for food, will split the sentence into 'the food' + 'food is amazing but ambience is bad in the restaurant'\n",
        "        # for ambience, will split the sentence into 'the food is amazing but ambience' + 'ambience is bad in the restaurent'\n",
        "        # then perform lstm + softmax will obtain a vector of size 3 for each aspect\n",
        "        # hence, update the aspect vector to [0, resulted vector of size 3]\n",
        "\n",
        "        output = torch.tensor([[[0]*4]*n2]*n1).float()\n",
        "        output.requires_grad = True\n",
        "\n",
        "        #sentiment analysis\n",
        "        pred_aspect = x_logit.max(-1)[1]\n",
        "\n",
        "        for j, pred in enumerate(pred_aspect):\n",
        "            i = 0\n",
        "            aspect = False\n",
        "            start = 0\n",
        "            n = len(pred)\n",
        "            pred = pred.tolist()\n",
        "            count_aspect = 0\n",
        "            index_lst = []\n",
        "            left_right = []\n",
        "            x_train_word = x_train[j]\n",
        "    \n",
        "            while i < n:\n",
        "    \n",
        "                if aspect == True and pred[i] == 0:\n",
        "                  \n",
        "                    count_aspect = count_aspect + 1\n",
        "                    index_lst.append([start, i-1])\n",
        "                    aspect = False\n",
        "                    #print(x_train_word, 'x_train+word')\n",
        "                    #print(x_train_word[start:])\n",
        "                    right_context = x_train_word[start:].flip(dims=(0,))\n",
        "                    #print(right_context)\n",
        "                    #print(right_context[right_context.nonzero().squeeze().detach()])\n",
        "                    left_right.append([x_train_word[:i], right_context[right_context.nonzero().squeeze().detach()]])\n",
        "\n",
        "                if aspect == False and pred[i] == 1:\n",
        "                    start = i\n",
        "                    aspect = True\n",
        "\n",
        "                i = i + 1\n",
        "\n",
        "            for m in range(count_aspect):\n",
        "                inputs = left_right[m]\n",
        "                index = index_lst[m]\n",
        "                x_l, x_r = inputs[0], inputs[1]\n",
        "\n",
        "                if x_l.dim() == 0 or len(x_l) == 0:\n",
        "                    x_l = torch.tensor([0])\n",
        "                elif len(x_l) ==1:\n",
        "                    x_l = torch.tensor([x_l])\n",
        "                \n",
        "                if x_r.dim() == 0 or len(x_r) == 0:\n",
        "                    x_r = torch.tensor([0])\n",
        "                elif len(x_r) ==1:\n",
        "                    x_r = torch.tensor([x_r])\n",
        "                \n",
        "                x_l, x_r = self.embed(x_l), self.embed(x_r)\n",
        "                _, (h_n_l, _) = self.lstm_l(x_l)\n",
        "                _, (h_n_r, _) = self.lstm_r(x_r)\n",
        "                h_n = torch.cat((h_n_l[0], h_n_r[0]), dim=-1)\n",
        "                out = self.dense(h_n)\n",
        "                with torch.no_grad():\n",
        "                    output[j][index[0]:index[1]+1]= torch.cat((torch.tensor([-10]),out),0)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "word_indx = build_vocab(DATA_DIR)\n",
        "fn = DATA_DIR + 'restaurant_emb.vec'\n",
        "res_domain_embedding = gen_np_embedding(fn, word_indx, dim=100, emb=True)\n",
        "\n",
        "    \n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "fn = DATA_DIR + 'Restaurants_Train_v2.xml'\n",
        "(X_train_res, mask_res), y_train_res , y_train_pol = create_train_data_restaurant(fn, word_indx, sent_len=100)\n",
        "X, mask, y , y_pol = X_train_res, mask_res, y_train_res, y_train_pol\n",
        "   \n",
        "X_train, X_valid, mask_train, mask_valid, y_train, y_valid , y_pol_train, y_pol_valid= train_test_split(X, mask, y, y_pol, test_size=VALID_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(X_train[:3])\n",
        "#print(mask_train[:3])\n",
        "print(y_train[:5])\n",
        "print(' ')\n",
        "print(y_pol_train[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:1616\n",
            "valid samples:405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:4.419 valid_loss:4.495\n",
            "\ttrain_acc:61.24% valid_acc:61.02%\n",
            "\ttrain_f1:0.683 valid_f1:0.683\n",
            "\ttrain_confusion_matrix:\n",
            "[[15881  1498   419  5443]\n",
            " [ 1402   149    97   362]\n",
            " [  389    36    13   119]\n",
            " [  426    36    11   135]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4151  342   96 1548]\n",
            " [ 306   32   16   92]\n",
            " [ 101    7    1   27]\n",
            " [ 151   14    8   55]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.02s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:4.440 valid_loss:4.609\n",
            "\ttrain_acc:61.27% valid_acc:60.26%\n",
            "\ttrain_f1:0.685 valid_f1:0.680\n",
            "\ttrain_confusion_matrix:\n",
            "[[15910  1373   398  5657]\n",
            " [ 1362   152    97   408]\n",
            " [  374    37    23   129]\n",
            " [  374    44    19   162]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4078  380  144 1535]\n",
            " [ 296   45   21   84]\n",
            " [  89    8    5   34]\n",
            " [ 140   15   15   58]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.04s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:4.468 valid_loss:4.438\n",
            "\ttrain_acc:60.80% valid_acc:61.54%\n",
            "\ttrain_f1:0.681 valid_f1:0.689\n",
            "\ttrain_confusion_matrix:\n",
            "[[15717  1366   411  5667]\n",
            " [ 1380   131   108   369]\n",
            " [  376    25    15   140]\n",
            " [  417    41    16   138]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4187  357  120 1473]\n",
            " [ 286   37   27   96]\n",
            " [  95   11    0   30]\n",
            " [ 147   12   18   51]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.02s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:4.392 valid_loss:4.311\n",
            "\ttrain_acc:61.55% valid_acc:62.72%\n",
            "\ttrain_f1:0.687 valid_f1:0.695\n",
            "\ttrain_confusion_matrix:\n",
            "[[16078  1307   394  5629]\n",
            " [ 1350   134    99   437]\n",
            " [  387    43    14   114]\n",
            " [  416    34    14   143]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4268  380   89 1400]\n",
            " [ 311   37   15   83]\n",
            " [  94   11    3   28]\n",
            " [ 165    9    5   49]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.04s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:4.368 valid_loss:4.364\n",
            "\ttrain_acc:61.86% valid_acc:62.34%\n",
            "\ttrain_f1:0.689 valid_f1:0.695\n",
            "\ttrain_confusion_matrix:\n",
            "[[16059  1302   372  5566]\n",
            " [ 1384   134    98   394]\n",
            " [  365    33    15   131]\n",
            " [  396    34    13   155]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4234  379  110 1414]\n",
            " [ 281   46   30   89]\n",
            " [  87   14    1   34]\n",
            " [ 156   13    9   50]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:4.398 valid_loss:4.567\n",
            "\ttrain_acc:61.61% valid_acc:60.40%\n",
            "\ttrain_f1:0.688 valid_f1:0.679\n",
            "\ttrain_confusion_matrix:\n",
            "[[16006  1396   391  5525]\n",
            " [ 1344   151   130   385]\n",
            " [  360    44    25   115]\n",
            " [  421    39    18   134]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4105  386   82 1564]\n",
            " [ 309   36    9   92]\n",
            " [  90    8    6   32]\n",
            " [ 159   12    8   49]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.01s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:4.467 valid_loss:4.577\n",
            "\ttrain_acc:60.84% valid_acc:60.52%\n",
            "\ttrain_f1:0.682 valid_f1:0.680\n",
            "\ttrain_confusion_matrix:\n",
            "[[15777  1397   407  5661]\n",
            " [ 1362   154   119   392]\n",
            " [  367    36    16   136]\n",
            " [  418    38    16   133]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4098  370  114 1555]\n",
            " [ 298   40   21   87]\n",
            " [  95   11    4   26]\n",
            " [ 147   14    5   62]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:4.401 valid_loss:4.391\n",
            "\ttrain_acc:61.48% valid_acc:61.95%\n",
            "\ttrain_f1:0.687 valid_f1:0.690\n",
            "\ttrain_confusion_matrix:\n",
            "[[15950  1328   426  5559]\n",
            " [ 1372   146   106   387]\n",
            " [  372    46    26   109]\n",
            " [  415    38    25   131]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4217  411  108 1401]\n",
            " [ 300   31   27   88]\n",
            " [  98   10    5   23]\n",
            " [ 152   11   14   51]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:4.447 valid_loss:4.413\n",
            "\ttrain_acc:61.22% valid_acc:61.83%\n",
            "\ttrain_f1:0.685 valid_f1:0.689\n",
            "\ttrain_confusion_matrix:\n",
            "[[15908  1347   401  5686]\n",
            " [ 1330   161   117   418]\n",
            " [  387    36    18   121]\n",
            " [  401    31    13   151]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4203  343  106 1485]\n",
            " [ 301   38   27   80]\n",
            " [  98    5    1   32]\n",
            " [ 158    8    9   53]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.04s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:4.468 valid_loss:4.357\n",
            "\ttrain_acc:60.90% valid_acc:62.31%\n",
            "\ttrain_f1:0.683 valid_f1:0.693\n",
            "\ttrain_confusion_matrix:\n",
            "[[15772  1355   373  5733]\n",
            " [ 1329   152    99   410]\n",
            " [  385    47    17   116]\n",
            " [  418    39    19   136]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4239  319  108 1471]\n",
            " [ 316   33   22   75]\n",
            " [  82    8    3   43]\n",
            " [ 147   16   11   54]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.04s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:4.411 valid_loss:4.471\n",
            "\ttrain_acc:61.41% valid_acc:61.28%\n",
            "\ttrain_f1:0.686 valid_f1:0.686\n",
            "\ttrain_confusion_matrix:\n",
            "[[15939  1305   384  5656]\n",
            " [ 1379   134    93   395]\n",
            " [  362    49    22   127]\n",
            " [  401    42    19   155]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4166  372   75 1524]\n",
            " [ 312   35   25   74]\n",
            " [  88   12    4   32]\n",
            " [ 150   16   10   52]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.04s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:4.417 valid_loss:4.300\n",
            "\ttrain_acc:61.46% valid_acc:62.62%\n",
            "\ttrain_f1:0.687 valid_f1:0.694\n",
            "\ttrain_confusion_matrix:\n",
            "[[16012  1416   383  5587]\n",
            " [ 1350   155    95   402]\n",
            " [  378    35    20   113]\n",
            " [  427    34    16   138]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4276  339   86 1436]\n",
            " [ 313   26   25   82]\n",
            " [  95   10    2   29]\n",
            " [ 162    9   11   46]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:4.417 valid_loss:4.368\n",
            "\ttrain_acc:61.39% valid_acc:62.31%\n",
            "\ttrain_f1:0.686 valid_f1:0.693\n",
            "\ttrain_confusion_matrix:\n",
            "[[15935  1374   397  5593]\n",
            " [ 1375   156    98   388]\n",
            " [  368    41    16   131]\n",
            " [  398    38    18   141]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4232  310  138 1457]\n",
            " [ 314   33   13   86]\n",
            " [  84    8    6   38]\n",
            " [ 148    8   14   58]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.02s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:4.368 valid_loss:4.389\n",
            "\ttrain_acc:61.81% valid_acc:62.17%\n",
            "\ttrain_f1:0.688 valid_f1:0.694\n",
            "\ttrain_confusion_matrix:\n",
            "[[16052  1354   363  5517]\n",
            " [ 1377   137   104   400]\n",
            " [  370    47    15   135]\n",
            " [  399    32     9   151]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4218  323  107 1489]\n",
            " [ 298   38   20   90]\n",
            " [  84   10   10   32]\n",
            " [ 142   18   15   53]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:4.413 valid_loss:4.402\n",
            "\ttrain_acc:61.57% valid_acc:61.97%\n",
            "\ttrain_f1:0.688 valid_f1:0.692\n",
            "\ttrain_confusion_matrix:\n",
            "[[15964  1380   372  5616]\n",
            " [ 1357   161    91   398]\n",
            " [  363    35    31   124]\n",
            " [  399    36    11   160]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4210  337  111 1479]\n",
            " [ 298   38   21   89]\n",
            " [  84    8    1   43]\n",
            " [ 147   15   10   56]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.01s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:4.343 valid_loss:4.208\n",
            "\ttrain_acc:62.11% valid_acc:63.81%\n",
            "\ttrain_f1:0.691 valid_f1:0.704\n",
            "\ttrain_confusion_matrix:\n",
            "[[16140  1349   426  5401]\n",
            " [ 1357   135   104   409]\n",
            " [  369    29    27   121]\n",
            " [  413    37    17   141]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4334  322  104 1377]\n",
            " [ 303   39   24   80]\n",
            " [  92    7    5   32]\n",
            " [ 153   13    7   55]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.02s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:4.423 valid_loss:4.424\n",
            "\ttrain_acc:61.13% valid_acc:61.87%\n",
            "\ttrain_f1:0.683 valid_f1:0.691\n",
            "\ttrain_confusion_matrix:\n",
            "[[15883  1334   381  5642]\n",
            " [ 1390   106    93   404]\n",
            " [  378    53    10   123]\n",
            " [  394    47    19   131]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4196  309   98 1534]\n",
            " [ 300   48    9   89]\n",
            " [  87   11    4   34]\n",
            " [ 165   10    3   50]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:4.478 valid_loss:4.307\n",
            "\ttrain_acc:60.81% valid_acc:63.01%\n",
            "\ttrain_f1:0.683 valid_f1:0.698\n",
            "\ttrain_confusion_matrix:\n",
            "[[15815  1302   418  5807]\n",
            " [ 1341   160   100   423]\n",
            " [  370    49    22   121]\n",
            " [  405    45    20   140]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4271  326   95 1445]\n",
            " [ 304   40   15   87]\n",
            " [  97    6    6   27]\n",
            " [ 146   13    9   60]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:4.410 valid_loss:4.372\n",
            "\ttrain_acc:61.47% valid_acc:62.21%\n",
            "\ttrain_f1:0.687 valid_f1:0.691\n",
            "\ttrain_confusion_matrix:\n",
            "[[15996  1398   388  5565]\n",
            " [ 1355   169   102   394]\n",
            " [  373    39    20   126]\n",
            " [  425    47    13   127]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4229  370  111 1427]\n",
            " [ 311   33   15   87]\n",
            " [  97    8    1   30]\n",
            " [ 151    8   10   59]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:12<00:00,  1.02s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:4.386 valid_loss:4.327\n",
            "\ttrain_acc:61.74% valid_acc:62.75%\n",
            "\ttrain_f1:0.687 valid_f1:0.697\n",
            "\ttrain_confusion_matrix:\n",
            "[[16005  1410   370  5491]\n",
            " [ 1413   163    84   348]\n",
            " [  395    45    16   107]\n",
            " [  410    39     9   149]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[4258  363  112 1404]\n",
            " [ 303   41   19   83]\n",
            " [  99    7    6   24]\n",
            " [ 139   21   14   54]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_ASPECT_TAGS = 2\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(mask_train), torch.Tensor(y_pol_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_valid), torch.Tensor(mask_valid), torch.Tensor(y_pol_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding, res_domain_embedding, num_classes=5), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        feature, mask, label = data\n",
        "        feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(feature)\n",
        "\n",
        "        loss = loss_fn(pred_logits.float(), mask, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        masks.append(mask)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds, masks, labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "            loss = loss_fn(pred_logits, mask, label)\n",
        "            \n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            masks.append(mask)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds, masks, labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task2_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
