{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVlBRwsjo3A9",
        "outputId": "c73353d2-d0e0-46ab-cb7b-742f72aa0104"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext\n",
        "#!pip install transformers\n",
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "#!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Pp-VjL_5Xw",
        "outputId": "a043786f-12ea-4b95-f6bb-4f7c9288537a"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\"\n",
        "VALID_SIZE = .2\n",
        "MODEL_PATH = \"model_task2.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "f_ihgOgKQQ5e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.optim import AdamW\n",
        "from fasttext import load_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing, model_selection\n",
        "from torch import LongTensor\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Dataset/data/restaurants_laptop_train_with_pos_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of aspect tags: 2\n",
            "num of polarity tags: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.polarity = df.polarity.replace(-1,2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
        "\n",
        "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
        "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
        "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
        "\n",
        "polarity_unique_values = df.polarity.unique()\n",
        "\n",
        "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
        "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
        "\n",
        "np.where(encoder.classes_ == \"AT\")[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "idx = 0\n",
        "print(sentences[idx])\n",
        "print(aspect_tags[idx])\n",
        "print(polarity_tags[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "2448bddb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_new_aspect_cluster(left, right, aspect_term, polarity, sentence):\n",
        "\n",
        "    if len(polarity) == 0:\n",
        "        polarity = 0\n",
        "    else:\n",
        "        polarity = int(sum(polarity)/len(polarity))\n",
        "   \n",
        "    left.extend(aspect_term)\n",
        "    left.extend(right)\n",
        "    return {\n",
        "        \"local_context\":left,\n",
        "        \"global_context\":sentence,\n",
        "        \"aspect_term\":aspect_term,\n",
        "        \"polarity\":polarity,\n",
        "    }\n",
        "\n",
        "def chop(sentence, aspect_tag, polarity_tag):\n",
        "    ret_aspect_clusters = []\n",
        "#     ret_aspect_clusters = {\n",
        "#         \"context\":list(),\n",
        "#         \"aspect_term\":list(),\n",
        "#         \"polarity\":list(),\n",
        "#     }\n",
        "    left = []\n",
        "    right = []\n",
        "    aspect_term = []\n",
        "    polarity = []\n",
        "    doing_left = True\n",
        "    doing_right = False\n",
        "    doing_aspect = False\n",
        "    for i in range(len(sentence)):\n",
        "        # check if the current token is an aspect term\n",
        "        if aspect_tag[i] == 0:\n",
        "            if doing_left:\n",
        "                doing_aspect = True\n",
        "                doing_left = False\n",
        "            elif doing_right:\n",
        "                doing_right = False\n",
        "                doing_aspect = True\n",
        "                # Now, need to save the previous aspect term cluster\n",
        "                ret_aspect_clusters.append(get_new_aspect_cluster(\n",
        "                    left, right, aspect_term, polarity, sentence))\n",
        "                left = right\n",
        "                right = []\n",
        "                aspect_term = []\n",
        "                polarity = []\n",
        "            aspect_term.append(sentence[i])\n",
        "            polarity.append(polarity_tag[i])\n",
        "        else:\n",
        "            if doing_left:\n",
        "                left.append(sentence[i])\n",
        "            elif doing_right:\n",
        "                right.append(sentence[i])\n",
        "            else:\n",
        "                doing_aspect = False\n",
        "                doing_right = True\n",
        "                right.append(sentence[i])\n",
        "                \n",
        "    ret_aspect_clusters.append(get_new_aspect_cluster(\n",
        "        left, right, aspect_term, polarity, sentence))\n",
        "    \n",
        "    return ret_aspect_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "bb3ba0d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_aspect_clusters = []\n",
        "for i in range(len(sentences)):\n",
        "    all_aspect_clusters.extend(chop(sentences[i], aspect_tags[i], polarity_tags[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'local_context': ['I',\n",
              "  'charge',\n",
              "  'it',\n",
              "  'at',\n",
              "  'night',\n",
              "  'and',\n",
              "  'skip',\n",
              "  'taking',\n",
              "  'the',\n",
              "  'cord',\n",
              "  'with',\n",
              "  'me',\n",
              "  'because',\n",
              "  'of',\n",
              "  'the',\n",
              "  'good'],\n",
              " 'global_context': ['I',\n",
              "  'charge',\n",
              "  'it',\n",
              "  'at',\n",
              "  'night',\n",
              "  'and',\n",
              "  'skip',\n",
              "  'taking',\n",
              "  'the',\n",
              "  'cord',\n",
              "  'with',\n",
              "  'me',\n",
              "  'because',\n",
              "  'of',\n",
              "  'the',\n",
              "  'good',\n",
              "  'battery',\n",
              "  'life'],\n",
              " 'aspect_term': ['cord'],\n",
              " 'polarity': 0}"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_aspect_clusters[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "MIElcOeLQVR0"
      },
      "outputs": [],
      "source": [
        "# generate word_index list\n",
        "def build_vocab(lst):\n",
        "    result = []\n",
        "    for i in lst:\n",
        "        result.extend(i[0]+i[1])\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(sorted(set(result))):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "def create_train_data_restaurant(all_aspect_clusters,  word_idx, sent_len=83):\n",
        "\n",
        "    train_X_local = np.zeros((len(all_aspect_clusters), sent_len), np.int16)\n",
        "    train_X_global = np.zeros((len(all_aspect_clusters), sent_len), np.int16)\n",
        "\n",
        "    train_y = np.zeros(len(all_aspect_clusters), np.int16)\n",
        "\n",
        "    # iterate the asoect\n",
        "    for sx, sent in enumerate(all_aspect_clusters):\n",
        "        train_y[sx] = sent['polarity']\n",
        "        global_sentence = sent['global_context']\n",
        "        local_sentence = sent['local_context']\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(global_sentence):\n",
        "                train_X_global[sx, wx] = word_idx[word]\n",
        "\n",
        "            for wx, word in enumerate(local_sentence):\n",
        "                train_X_local[sx, wx] = word_idx[word]\n",
        "\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    return train_X_local, train_X_global, train_y\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, label, num_label):\n",
        "    pred = pred.view(-1,num_label)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1, 2], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "    return acc, f1, cm\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, num_classes=3, alpha = 0.6):\n",
        "        super(Model, self).__init__()\n",
        "  \n",
        "        self.embed = nn.Embedding.from_pretrained(torch.tensor(gen_emb, dtype=torch.float))\n",
        "        self.lstm_l = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=False, batch_first=True)\n",
        "        self.lstm_r = nn.LSTM(gen_emb.shape[1],hidden_size=150, num_layers=1, bidirectional=False, batch_first=True)\n",
        "\n",
        "        self.dense = nn.Linear(150*2, num_classes)\n",
        "\n",
        "        self.lstm = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dense_1 = torch.nn.Linear(gen_emb.shape[1], num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "    def forward(self, x_train_local, x_train_global):\n",
        "\n",
        "        #left_seq_lengths = torch.tensor([0]*len(x_train_left))\n",
        "        #right_seq_lengths = torch.tensor([0]*len(x_train_right))\n",
        "\n",
        "        '''\n",
        "        # increate length to set to min one to avoid 0 length for pack padded sequence\n",
        "        for i, seq in enumerate(x_train_left):\n",
        "            if len(seq) == 0:\n",
        "                left_seq_lengths[i] = 1\n",
        "            else:\n",
        "                non_zero_seq = seq[seq.nonzero().squeeze().detach()]\n",
        "                if non_zero_seq.dim() == 0:\n",
        "                    left_seq_lengths[i] = 1\n",
        "                else:\n",
        "                    left_seq_lengths[i] = len(non_zero_seq)\n",
        "\n",
        "        for i, seq in enumerate(x_train_right):\n",
        "            if len(seq) == 0:\n",
        "                right_seq_lengths[i] = 1\n",
        "            else:\n",
        "                non_zero_seq = seq[seq.nonzero().squeeze().detach()]\n",
        "                if non_zero_seq.dim() == 0:\n",
        "                    right_seq_lengths[i] = 1\n",
        "                else:\n",
        "                    right_seq_lengths[i] = len(non_zero_seq)\n",
        "        \n",
        "\n",
        "        x_l = self.embed(x_train_left)\n",
        "        x_r = self.embed(x_train_right)\n",
        "\n",
        "        x_emb_p_l = torch.nn.utils.rnn.pack_padded_sequence(x_l, left_seq_lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        _, (ht, _) = self.lstm_l(x_emb_p_l)\n",
        "\n",
        "        x_emb_p_r = torch.nn.utils.rnn.pack_padded_sequence(x_r, right_seq_lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        _, (ht_r, _) = self.lstm_l(x_emb_p_r)\n",
        "\n",
        "        h_n = torch.cat((ht[0], ht_r[0]), dim=-1)\n",
        "        #output1 = self.dense(h_n)\n",
        "\n",
        "        '''\n",
        "        x_local = self.embed(x_train_local)\n",
        "        _, (h_n, _) = self.lstm(x_local.float())\n",
        "\n",
        "        h_n = torch.cat([h_n[-2,:,:], h_n[-1,:,:]], dim=1)\n",
        "\n",
        "        x_global = self.embed(x_train_global)\n",
        "        _, (h_n_g,_) = self.lstm(x_global.float())\n",
        "\n",
        "        h_n_g = torch.cat([h_n_g[-2,:,:], h_n_g[-1,:,:]], dim=1)\n",
        "\n",
        "        avg_pool = torch.div(torch.add(h_n * (1 - self.alpha), h_n_g * self.alpha), 2)\n",
        "        out = self.dropout(avg_pool)\n",
        "\n",
        "        out = self.dense(out)\n",
        "\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_indx = build_vocab(left_right)\n",
        "    \n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "local_context, global_context, y = create_train_data_restaurant(all_aspect_clusters ,word_indx, sent_len=83)\n",
        "\n",
        "X_l_train, X_l_valid, X_g_train, X_g_valid,  y_train, y_valid = train_test_split(local_context, global_context, y, test_size=VALID_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:4586\n",
            "valid samples:1147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.07it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.069 valid_loss:1.051\n",
            "\ttrain_acc:52.68% valid_acc:52.40%\n",
            "\ttrain_f1:0.369 valid_f1:0.360\n",
            "\ttrain_confusion_matrix:\n",
            "[[   3  834    3]\n",
            " [  25 2356    3]\n",
            " [   8 1247    1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 197   0]\n",
            " [  0 601   0]\n",
            " [  0 349   0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.019 valid_loss:1.009\n",
            "\ttrain_acc:53.33% valid_acc:52.40%\n",
            "\ttrain_f1:0.371 valid_f1:0.360\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  824    0]\n",
            " [   0 2389    0]\n",
            " [   0 1267    0]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 197   0]\n",
            " [  0 601   0]\n",
            " [  0 349   0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.06it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.982 valid_loss:0.979\n",
            "\ttrain_acc:53.39% valid_acc:52.40%\n",
            "\ttrain_f1:0.372 valid_f1:0.360\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  830    0]\n",
            " [   0 2392    0]\n",
            " [   0 1258    0]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 197   0]\n",
            " [  0 601   0]\n",
            " [  0 349   0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.04it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.932 valid_loss:0.901\n",
            "\ttrain_acc:53.57% valid_acc:55.62%\n",
            "\ttrain_f1:0.380 valid_f1:0.442\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  820   10]\n",
            " [   0 2380    8]\n",
            " [   0 1242   20]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 178  19]\n",
            " [  0 586  15]\n",
            " [  0 297  52]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.866 valid_loss:0.845\n",
            "\ttrain_acc:59.69% valid_acc:61.81%\n",
            "\ttrain_f1:0.508 valid_f1:0.551\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  631  204]\n",
            " [   0 2277  120]\n",
            " [   0  851  397]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 111  86]\n",
            " [  0 534  67]\n",
            " [  0 174 175]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.831 valid_loss:0.821\n",
            "\ttrain_acc:64.29% valid_acc:66.09%\n",
            "\ttrain_f1:0.576 valid_f1:0.601\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  415  418]\n",
            " [   0 2079  307]\n",
            " [   0  460  801]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  81 116]\n",
            " [  0 508  93]\n",
            " [  0  99 250]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.807 valid_loss:0.800\n",
            "\ttrain_acc:65.42% valid_acc:67.22%\n",
            "\ttrain_f1:0.587 valid_f1:0.612\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  421  416]\n",
            " [   0 2087  305]\n",
            " [   0  407  844]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  79 118]\n",
            " [  0 514  87]\n",
            " [  0  92 257]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.788 valid_loss:0.778\n",
            "\ttrain_acc:66.45% valid_acc:67.83%\n",
            "\ttrain_f1:0.601 valid_f1:0.615\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  339  500]\n",
            " [   0 2020  363]\n",
            " [   0  301  957]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  95 102]\n",
            " [  0 526  75]\n",
            " [  0  97 252]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.16it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.770 valid_loss:0.758\n",
            "\ttrain_acc:66.94% valid_acc:69.14%\n",
            "\ttrain_f1:0.605 valid_f1:0.631\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  351  484]\n",
            " [   0 2040  346]\n",
            " [   0  300  959]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  73 124]\n",
            " [  0 514  87]\n",
            " [  0  70 279]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.18it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.752 valid_loss:0.755\n",
            "\ttrain_acc:67.83% valid_acc:68.79%\n",
            "\ttrain_f1:0.613 valid_f1:0.629\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  343  489]\n",
            " [   0 2050  338]\n",
            " [   0  271  989]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  66 131]\n",
            " [  0 502  99]\n",
            " [  0  62 287]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.740 valid_loss:0.743\n",
            "\ttrain_acc:68.39% valid_acc:68.79%\n",
            "\ttrain_f1:0.619 valid_f1:0.624\n",
            "\ttrain_confusion_matrix:\n",
            "[[   1  343  485]\n",
            " [   0 2056  338]\n",
            " [   0  250 1007]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  95 102]\n",
            " [  0 533  68]\n",
            " [  0  93 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.733 valid_loss:0.729\n",
            "\ttrain_acc:68.55% valid_acc:69.66%\n",
            "\ttrain_f1:0.620 valid_f1:0.635\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  340  496]\n",
            " [   0 2046  332]\n",
            " [   0  241 1025]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0  76 121]\n",
            " [  0 516  85]\n",
            " [  0  66 283]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.13it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.723 valid_loss:0.720\n",
            "\ttrain_acc:68.95% valid_acc:69.92%\n",
            "\ttrain_f1:0.623 valid_f1:0.637\n",
            "\ttrain_confusion_matrix:\n",
            "[[   2  378  456]\n",
            " [   3 2074  307]\n",
            " [   0  247 1013]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  2  97  98]\n",
            " [  0 536  65]\n",
            " [  2  83 264]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.02it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.707 valid_loss:0.708\n",
            "\ttrain_acc:69.87% valid_acc:70.71%\n",
            "\ttrain_f1:0.633 valid_f1:0.647\n",
            "\ttrain_confusion_matrix:\n",
            "[[   5  368  459]\n",
            " [   6 2095  285]\n",
            " [   0  232 1030]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  3  87 107]\n",
            " [  2 528  71]\n",
            " [  2  67 280]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.08it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.695 valid_loss:0.709\n",
            "\ttrain_acc:70.54% valid_acc:70.79%\n",
            "\ttrain_f1:0.643 valid_f1:0.657\n",
            "\ttrain_confusion_matrix:\n",
            "[[  16  364  450]\n",
            " [  11 2104  278]\n",
            " [   8  209 1040]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 14 107  76]\n",
            " [  5 555  41]\n",
            " [  5 101 243]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.692 valid_loss:0.718\n",
            "\ttrain_acc:70.51% valid_acc:70.10%\n",
            "\ttrain_f1:0.647 valid_f1:0.655\n",
            "\ttrain_confusion_matrix:\n",
            "[[  32  383  420]\n",
            " [  32 2112  243]\n",
            " [   9  234 1015]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 11  71 115]\n",
            " [  4 503  94]\n",
            " [  6  53 290]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.14it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.684 valid_loss:0.687\n",
            "\ttrain_acc:71.54% valid_acc:71.32%\n",
            "\ttrain_f1:0.668 valid_f1:0.674\n",
            "\ttrain_confusion_matrix:\n",
            "[[  73  345  416]\n",
            " [  31 2090  261]\n",
            " [  18  204 1042]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 23  95  79]\n",
            " [ 16 537  48]\n",
            " [  6  85 258]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.13it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.674 valid_loss:0.681\n",
            "\ttrain_acc:71.65% valid_acc:71.40%\n",
            "\ttrain_f1:0.672 valid_f1:0.678\n",
            "\ttrain_confusion_matrix:\n",
            "[[  80  353  398]\n",
            " [  43 2112  232]\n",
            " [  31  213 1018]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 25  93  79]\n",
            " [ 18 536  47]\n",
            " [ 14  77 258]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:11<00:00,  3.14it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.656 valid_loss:0.689\n",
            "\ttrain_acc:72.66% valid_acc:72.19%\n",
            "\ttrain_f1:0.692 valid_f1:0.695\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 127  333  368]\n",
            " [  55 2123  217]\n",
            " [  55  197 1005]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 36  79  82]\n",
            " [ 26 522  53]\n",
            " [ 16  63 270]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:12<00:00,  2.91it/s]\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.646 valid_loss:0.680\n",
            "\ttrain_acc:73.21% valid_acc:72.80%\n",
            "\ttrain_f1:0.699 valid_f1:0.694\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 138  314  379]\n",
            " [  53 2106  228]\n",
            " [  48  178 1036]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 31  91  75]\n",
            " [ 15 542  44]\n",
            " [ 12  75 262]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_l_train), torch.Tensor(X_g_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_l_valid),  torch.Tensor(X_g_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3, alpha = 0.7), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        l_feature, g_feature, label = data\n",
        "        l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(l_feature, g_feature)\n",
        "        loss = loss_fn(pred_logits, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds,labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "            loss = loss_fn(pred_logits, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds,  labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n",
        "        \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.4, 0.9)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.4, 0.9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.49      0.15      0.23       197\n",
            "    Positive       0.76      0.90      0.83       601\n",
            "    Negative       0.69      0.75      0.72       349\n",
            "\n",
            "    accuracy                           0.72      1147\n",
            "   macro avg       0.65      0.60      0.59      1147\n",
            "weighted avg       0.69      0.72      0.69      1147\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "\n",
        "            l_feature, g_feature, label = data\n",
        "            l_feature, g_feature, label = l_feature.long(), g_feature.long(), label.long()\n",
        "            pred_logits = model(l_feature, g_feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task2_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
