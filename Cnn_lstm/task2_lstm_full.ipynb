{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Pp-VjL_5Xw",
        "outputId": "a043786f-12ea-4b95-f6bb-4f7c9288537a"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\"\n",
        "VALID_SIZE = .2\n",
        "MODEL_PATH = \"model_task2_full.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VVlBRwsjo3A9"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext\n",
        "#!pip install transformers\n",
        "#import nltk\n",
        "#nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bAicdvsynjtH"
      },
      "outputs": [],
      "source": [
        "from ast import FloorDiv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.optim import AdamW\n",
        "from fasttext import load_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Dataset/data/restaurants_laptop_train_with_pos.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "      <th>aspect_tag</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>s_1</td>\n",
              "      <td>I</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s_1</td>\n",
              "      <td>charge</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s_1</td>\n",
              "      <td>it</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s_1</td>\n",
              "      <td>at</td>\n",
              "      <td>ADP</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s_1</td>\n",
              "      <td>night</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num    text   pos aspect_tag  polarity\n",
              "0  s_1       I  PRON        NAT         0\n",
              "1  s_1  charge  VERB        NAT         0\n",
              "2  s_1      it  PRON        NAT         0\n",
              "3  s_1      at   ADP        NAT         0\n",
              "4  s_1   night  NOUN        NAT         0"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of aspect tags: 2\n",
            "num of polarity tags: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# replace all -1 to 2 since pytorch cannot handle negative\n",
        "# so, 2 now means negative polarity\n",
        "df.polarity = df.polarity.replace(-1,2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
        "\n",
        "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
        "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
        "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
        "\n",
        "polarity_unique_values = df.polarity.unique()\n",
        "\n",
        "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
        "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
        "\n",
        "np.where(encoder.classes_ == \"AT\")[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3432\n",
            "3432\n",
            "3432\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences))\n",
        "print(len(aspect_tags))\n",
        "print(len(polarity_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84\n"
          ]
        }
      ],
      "source": [
        "print(max(map(lambda x: len(x), sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dkojY_dde3K-"
      },
      "outputs": [],
      "source": [
        "# generate word_index list\n",
        "def build_vocab(df):\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(sorted(set(df.text.values))):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "def create_train_data_restaurant(sentences, word_idx, pol_tags, sent_len=85):\n",
        "    train_X = np.zeros((len(sentences), sent_len), np.int16)\n",
        "    mask = np.zeros_like(train_X)\n",
        "\n",
        "    train_y = np.zeros((len(sentences), sent_len), np.int16)\n",
        "\n",
        "    # iterate the sentence\n",
        "    for sx, sent in enumerate(sentences):\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(sent):\n",
        "                train_X[sx, wx] = word_idx[word]\n",
        "                if aspect_tags[sx][wx] == 0:\n",
        "                    mask[sx, wx] = 1\n",
        "                elif aspect_tags[sx][wx] == 1:\n",
        "                    mask[sx, wx] = 0\n",
        "                train_y[sx, wx] = pol_tags[sx][wx]\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    return (train_X, mask), train_y\n",
        "\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, mask, label, num_tag):\n",
        "    label.masked_fill_(~mask, -100)\n",
        "    pred = pred.view(-1, num_tag)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, mask, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        mask = torch.cat(mask, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    pred_tags = pred_tags[mask]\n",
        "    true_tags = true_tags[mask]\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "\n",
        "    return acc, f1, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnbH1kXllslz",
        "outputId": "e54a1149-6949-4d20-e7eb-05dc01f35f7b"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, num_classes=3):\n",
        "        super(Model, self).__init__()\n",
        "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
        "        self.gen_embedding.weight = torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
        "        self.lstm = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dense = torch.nn.Linear(gen_emb.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x_train):\n",
        "        x_emb = self.gen_embedding(x_train)\n",
        "\n",
        "        output, (h_n, _) = self.lstm(x_emb.float())\n",
        "        out = self.dense(output)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_indx = build_vocab(df)\n",
        "\n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)\n",
        "\n",
        "\n",
        "(X, mask), y = create_train_data_restaurant(sentences, word_indx, polarity_tags, sent_len=85)\n",
        "\n",
        "X_train, X_valid, mask_train, mask_valid, y_train, y_valid = train_test_split(X, mask, y, test_size=VALID_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:2745\n",
            "valid samples:687\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(mask_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_valid), torch.Tensor(mask_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.062 valid_loss:1.038\n",
            "\ttrain_acc:50.64% valid_acc:50.12%\n",
            "\ttrain_f1:0.505 valid_f1:0.469\n",
            "\ttrain_confusion_matrix:\n",
            "[[  36 1104  141]\n",
            " [ 125 3121  407]\n",
            " [  53 1512  272]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 362   3]\n",
            " [  0 856   6]\n",
            " [  0 486   5]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.002 valid_loss:1.008\n",
            "\ttrain_acc:54.12% valid_acc:50.29%\n",
            "\ttrain_f1:0.520 valid_f1:0.470\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1283    0]\n",
            " [   0 3664    0]\n",
            " [   0 1826    4]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 365   0]\n",
            " [  0 862   0]\n",
            " [  0 489   2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.969 valid_loss:0.994\n",
            "\ttrain_acc:54.13% valid_acc:50.58%\n",
            "\ttrain_f1:0.520 valid_f1:0.471\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1281    1]\n",
            " [   0 3661    0]\n",
            " [   0 1827    8]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 363   2]\n",
            " [  0 861   1]\n",
            " [  0 483   8]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.951 valid_loss:0.983\n",
            "\ttrain_acc:54.43% valid_acc:51.92%\n",
            "\ttrain_f1:0.520 valid_f1:0.477\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1278   10]\n",
            " [   0 3644    7]\n",
            " [   0 1793   44]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 352  13]\n",
            " [  0 858   4]\n",
            " [  0 457  34]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.929 valid_loss:0.964\n",
            "\ttrain_acc:57.55% valid_acc:55.65%\n",
            "\ttrain_f1:0.536 valid_f1:0.493\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1148  133]\n",
            " [   0 3585   75]\n",
            " [   0 1521  315]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 312  53]\n",
            " [  0 832  30]\n",
            " [  0 367 124]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.899 valid_loss:0.945\n",
            "\ttrain_acc:60.61% valid_acc:57.63%\n",
            "\ttrain_f1:0.553 valid_f1:0.502\n",
            "\ttrain_confusion_matrix:\n",
            "[[   1 1015  266]\n",
            " [   1 3532  129]\n",
            " [   0 1257  573]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 289  76]\n",
            " [  0 818  44]\n",
            " [  0 319 172]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.858 valid_loss:0.918\n",
            "\ttrain_acc:62.66% valid_acc:59.14%\n",
            "\ttrain_f1:0.570 valid_f1:0.511\n",
            "\ttrain_confusion_matrix:\n",
            "[[   8  895  367]\n",
            " [   1 3479  186]\n",
            " [   1 1079  757]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  2 244 119]\n",
            " [  1 762  99]\n",
            " [  0 239 252]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.825 valid_loss:0.900\n",
            "\ttrain_acc:64.02% valid_acc:60.13%\n",
            "\ttrain_f1:0.576 valid_f1:0.531\n",
            "\ttrain_confusion_matrix:\n",
            "[[   9  746  511]\n",
            " [   1 3236  388]\n",
            " [   3  773 1065]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 12 210 143]\n",
            " [  0 725 137]\n",
            " [  2 193 296]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.780 valid_loss:0.889\n",
            "\ttrain_acc:66.11% valid_acc:62.28%\n",
            "\ttrain_f1:0.611 valid_f1:0.558\n",
            "\ttrain_confusion_matrix:\n",
            "[[  63  647  564]\n",
            " [   6 3257  384]\n",
            " [  12  679 1152]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 25 232 108]\n",
            " [  1 766  95]\n",
            " [  6 206 279]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.752 valid_loss:0.859\n",
            "\ttrain_acc:67.79% valid_acc:63.15%\n",
            "\ttrain_f1:0.641 valid_f1:0.576\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 135  619  534]\n",
            " [  25 3297  351]\n",
            " [  35  627 1179]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 38 216 111]\n",
            " [ 11 746 105]\n",
            " [ 11 179 301]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.730 valid_loss:0.830\n",
            "\ttrain_acc:69.40% valid_acc:64.20%\n",
            "\ttrain_f1:0.672 valid_f1:0.604\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 205  543  530]\n",
            " [  56 3285  344]\n",
            " [  67  533 1212]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 57 194 114]\n",
            " [ 20 736 106]\n",
            " [ 28 153 310]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.703 valid_loss:0.834\n",
            "\ttrain_acc:69.92% valid_acc:63.80%\n",
            "\ttrain_f1:0.687 valid_f1:0.596\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 265  562  453]\n",
            " [  71 3335  281]\n",
            " [ 121  554 1147]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 54 223  88]\n",
            " [ 21 761  80]\n",
            " [ 26 184 281]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.685 valid_loss:0.817\n",
            "\ttrain_acc:71.63% valid_acc:64.73%\n",
            "\ttrain_f1:0.711 valid_f1:0.614\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 329  472  470]\n",
            " [  79 3271  312]\n",
            " [ 133  457 1256]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 67 200  98]\n",
            " [ 26 745  91]\n",
            " [ 32 159 300]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.671 valid_loss:0.801\n",
            "\ttrain_acc:72.19% valid_acc:65.60%\n",
            "\ttrain_f1:0.718 valid_f1:0.623\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 359  466  456]\n",
            " [  90 3266  308]\n",
            " [ 125  438 1264]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 71 194 100]\n",
            " [ 29 746  87]\n",
            " [ 38 143 310]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.655 valid_loss:0.785\n",
            "\ttrain_acc:73.09% valid_acc:66.65%\n",
            "\ttrain_f1:0.733 valid_f1:0.643\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 406  425  444]\n",
            " [ 103 3277  281]\n",
            " [ 148  421 1266]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 89 168 108]\n",
            " [ 38 727  97]\n",
            " [ 37 125 329]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.641 valid_loss:0.794\n",
            "\ttrain_acc:73.59% valid_acc:66.53%\n",
            "\ttrain_f1:0.739 valid_f1:0.630\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 442  407  426]\n",
            " [ 142 3252  250]\n",
            " [ 172  390 1286]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 75 203  87]\n",
            " [ 27 760  75]\n",
            " [ 30 153 308]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.626 valid_loss:0.773\n",
            "\ttrain_acc:74.37% valid_acc:67.81%\n",
            "\ttrain_f1:0.741 valid_f1:0.664\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 407  417  447]\n",
            " [  99 3292  253]\n",
            " [ 126  388 1320]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[118 164  83]\n",
            " [ 56 729  77]\n",
            " [ 44 129 318]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.615 valid_loss:0.773\n",
            "\ttrain_acc:74.80% valid_acc:67.17%\n",
            "\ttrain_f1:0.754 valid_f1:0.651\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 501  371  420]\n",
            " [ 142 3238  259]\n",
            " [ 156  359 1328]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[101 171  93]\n",
            " [ 51 732  79]\n",
            " [ 40 130 321]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.598 valid_loss:0.767\n",
            "\ttrain_acc:75.88% valid_acc:67.87%\n",
            "\ttrain_f1:0.763 valid_f1:0.666\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 501  367  420]\n",
            " [ 122 3297  243]\n",
            " [ 131  349 1337]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[122 147  96]\n",
            " [ 62 706  94]\n",
            " [ 45 108 338]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.589 valid_loss:0.774\n",
            "\ttrain_acc:75.81% valid_acc:67.93%\n",
            "\ttrain_f1:0.771 valid_f1:0.657\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 567  330  383]\n",
            " [ 150 3257  265]\n",
            " [ 185  328 1318]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 98 146 121]\n",
            " [ 46 711 105]\n",
            " [ 31 102 358]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        feature, mask, label = data\n",
        "        feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(feature)\n",
        "        loss = loss_fn(pred_logits, mask, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        masks.append(mask)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds, masks, labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "            loss = loss_fn(pred_logits, mask, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            masks.append(mask)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds, masks, labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Pp-VjL_5Xw",
        "outputId": "a043786f-12ea-4b95-f6bb-4f7c9288537a"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\"\n",
        "VALID_SIZE = .2\n",
        "MODEL_PATH = \"model_task2_full_clean.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VVlBRwsjo3A9"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext\n",
        "#!pip install transformers\n",
        "#import nltk\n",
        "#nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bAicdvsynjtH"
      },
      "outputs": [],
      "source": [
        "from ast import FloorDiv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.optim import AdamW\n",
        "from fasttext import load_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Dataset/data/restaurants_laptop_train_with_pos_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "      <th>aspect_tag</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>s_1</td>\n",
              "      <td>I</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s_1</td>\n",
              "      <td>charge</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s_1</td>\n",
              "      <td>it</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s_1</td>\n",
              "      <td>at</td>\n",
              "      <td>ADP</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s_1</td>\n",
              "      <td>night</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num    text   pos aspect_tag  polarity\n",
              "0  s_1       I  PRON        NAT         0\n",
              "1  s_1  charge  VERB        NAT         0\n",
              "2  s_1      it  PRON        NAT         0\n",
              "3  s_1      at   ADP        NAT         0\n",
              "4  s_1   night  NOUN        NAT         0"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of aspect tags: 2\n",
            "num of polarity tags: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# replace all -1 to 2 since pytorch cannot handle negative\n",
        "# so, 2 now means negative polarity\n",
        "df.polarity = df.polarity.replace(-1,2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
        "\n",
        "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
        "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
        "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
        "\n",
        "polarity_unique_values = df.polarity.unique()\n",
        "\n",
        "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
        "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
        "\n",
        "np.where(encoder.classes_ == \"AT\")[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3432\n",
            "3432\n",
            "3432\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences))\n",
        "print(len(aspect_tags))\n",
        "print(len(polarity_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80\n"
          ]
        }
      ],
      "source": [
        "print(max(map(lambda x: len(x), sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "dkojY_dde3K-"
      },
      "outputs": [],
      "source": [
        "# generate word_index list\n",
        "def build_vocab(df):\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(sorted(set(df.text.values))):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "def create_train_data_restaurant(sentences, word_idx, pol_tags, sent_len=85):\n",
        "    train_X = np.zeros((len(sentences), sent_len), np.int16)\n",
        "    mask = np.zeros_like(train_X)\n",
        "\n",
        "    train_y = np.zeros((len(sentences), sent_len), np.int16)\n",
        "\n",
        "    # iterate the sentence\n",
        "    for sx, sent in enumerate(sentences):\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(sent):\n",
        "                train_X[sx, wx] = word_idx[word]\n",
        "                if aspect_tags[sx][wx] == 0:\n",
        "                    mask[sx, wx] = 1\n",
        "                elif aspect_tags[sx][wx] == 1:\n",
        "                    mask[sx, wx] = 0\n",
        "                train_y[sx, wx] = pol_tags[sx][wx]\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    return (train_X, mask), train_y\n",
        "\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, mask, label, num_tag):\n",
        "    label.masked_fill_(~mask, -100)\n",
        "    pred = pred.view(-1, num_tag)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, mask, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        mask = torch.cat(mask, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    pred_tags = pred_tags[mask]\n",
        "    true_tags = true_tags[mask]\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "\n",
        "    return acc, f1, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnbH1kXllslz",
        "outputId": "e54a1149-6949-4d20-e7eb-05dc01f35f7b"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, num_classes=3):\n",
        "        super(Model, self).__init__()\n",
        "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
        "        self.gen_embedding.weight = torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
        "        self.lstm = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dense = torch.nn.Linear(gen_emb.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x_train):\n",
        "        x_emb = self.gen_embedding(x_train)\n",
        "\n",
        "        output, (h_n, _) = self.lstm(x_emb.float())\n",
        "        out = self.dense(output)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_indx = build_vocab(df)\n",
        "\n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)\n",
        "\n",
        "\n",
        "(X, mask), y = create_train_data_restaurant(sentences, word_indx, polarity_tags, sent_len=83)\n",
        "\n",
        "X_train, X_valid, mask_train, mask_valid, y_train, y_valid = train_test_split(X, mask, y, test_size=VALID_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:2745\n",
            "valid samples:687\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(mask_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_valid), torch.Tensor(mask_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.34it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.064 valid_loss:1.039\n",
            "\ttrain_acc:49.63% valid_acc:50.24%\n",
            "\ttrain_f1:0.526 valid_f1:0.459\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 128 1009  108]\n",
            " [ 361 3031  206]\n",
            " [ 155 1537  167]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 384   2]\n",
            " [  0 838  11]\n",
            " [  0 439   6]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:0.999 valid_loss:1.009\n",
            "\ttrain_acc:54.42% valid_acc:50.42%\n",
            "\ttrain_f1:0.526 valid_f1:0.460\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1219    9]\n",
            " [   1 3627    9]\n",
            " [   0 1826   31]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 385   1]\n",
            " [  0 842   7]\n",
            " [  0 440   5]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.966 valid_loss:0.999\n",
            "\ttrain_acc:54.11% valid_acc:50.71%\n",
            "\ttrain_f1:0.522 valid_f1:0.460\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1224   10]\n",
            " [   0 3603    7]\n",
            " [   0 1842   32]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 385   1]\n",
            " [  0 839  10]\n",
            " [  0 432  13]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:04<00:00,  5.22it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.943 valid_loss:0.988\n",
            "\ttrain_acc:55.41% valid_acc:52.50%\n",
            "\ttrain_f1:0.528 valid_f1:0.470\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1197   53]\n",
            " [   0 3606   21]\n",
            " [   0 1725  117]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 357  29]\n",
            " [  0 831  18]\n",
            " [  0 394  51]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.921 valid_loss:0.972\n",
            "\ttrain_acc:58.30% valid_acc:55.65%\n",
            "\ttrain_f1:0.545 valid_f1:0.484\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  982  250]\n",
            " [   0 3468  149]\n",
            " [   0 1419  447]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 311  75]\n",
            " [  0 795  54]\n",
            " [  0 305 140]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.893 valid_loss:0.953\n",
            "\ttrain_acc:60.61% valid_acc:57.80%\n",
            "\ttrain_f1:0.560 valid_f1:0.495\n",
            "\ttrain_confusion_matrix:\n",
            "[[   1  849  387]\n",
            " [   0 3388  237]\n",
            " [   0 1171  679]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 288  98]\n",
            " [  0 786  63]\n",
            " [  0 260 185]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.44it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.855 valid_loss:0.928\n",
            "\ttrain_acc:63.21% valid_acc:60.36%\n",
            "\ttrain_f1:0.577 valid_f1:0.512\n",
            "\ttrain_confusion_matrix:\n",
            "[[  17  762  462]\n",
            " [   0 3275  348]\n",
            " [   0  896  948]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  2 260 124]\n",
            " [  0 771  78]\n",
            " [  0 204 241]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.816 valid_loss:0.905\n",
            "\ttrain_acc:64.96% valid_acc:61.85%\n",
            "\ttrain_f1:0.595 valid_f1:0.521\n",
            "\ttrain_confusion_matrix:\n",
            "[[  35  686  500]\n",
            " [   1 3226  381]\n",
            " [   4  774 1088]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  5 271 110]\n",
            " [  0 778  71]\n",
            " [  1 188 256]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:04<00:00,  5.17it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.777 valid_loss:0.859\n",
            "\ttrain_acc:66.44% valid_acc:63.27%\n",
            "\ttrain_f1:0.616 valid_f1:0.548\n",
            "\ttrain_confusion_matrix:\n",
            "[[  66  623  551]\n",
            " [   8 3236  394]\n",
            " [  11  675 1177]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 16 231 139]\n",
            " [  1 755  93]\n",
            " [  4 149 292]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:04<00:00,  4.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.752 valid_loss:0.831\n",
            "\ttrain_acc:68.05% valid_acc:63.69%\n",
            "\ttrain_f1:0.639 valid_f1:0.566\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 115  615  518]\n",
            " [  26 3253  354]\n",
            " [  23  611 1205]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 27 214 145]\n",
            " [  4 743 102]\n",
            " [ 11 134 300]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.729 valid_loss:0.814\n",
            "\ttrain_acc:69.14% valid_acc:64.11%\n",
            "\ttrain_f1:0.662 valid_f1:0.591\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 161  550  498]\n",
            " [  53 3226  335]\n",
            " [  51  577 1237]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 47 204 135]\n",
            " [  6 739 104]\n",
            " [ 19 135 291]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.713 valid_loss:0.810\n",
            "\ttrain_acc:69.85% valid_acc:64.11%\n",
            "\ttrain_f1:0.673 valid_f1:0.594\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 206  531  508]\n",
            " [  58 3194  373]\n",
            " [  62  495 1297]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 50 225 111]\n",
            " [ 10 770  69]\n",
            " [ 28 160 257]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.687 valid_loss:0.803\n",
            "\ttrain_acc:70.78% valid_acc:64.35%\n",
            "\ttrain_f1:0.692 valid_f1:0.602\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 258  534  435]\n",
            " [  76 3231  310]\n",
            " [ 123  478 1249]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 57 221 108]\n",
            " [ 13 763  73]\n",
            " [ 32 152 261]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.62it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.673 valid_loss:0.792\n",
            "\ttrain_acc:71.57% valid_acc:64.94%\n",
            "\ttrain_f1:0.703 valid_f1:0.608\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 291  470  472]\n",
            " [  98 3194  322]\n",
            " [ 123  428 1330]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 60 215 111]\n",
            " [ 11 761  77]\n",
            " [ 32 143 270]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.653 valid_loss:0.789\n",
            "\ttrain_acc:72.83% valid_acc:65.54%\n",
            "\ttrain_f1:0.714 valid_f1:0.623\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 302  486  439]\n",
            " [  81 3266  282]\n",
            " [ 101  432 1313]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 73 206 107]\n",
            " [ 17 755  77]\n",
            " [ 39 133 273]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.638 valid_loss:0.805\n",
            "\ttrain_acc:73.40% valid_acc:64.70%\n",
            "\ttrain_f1:0.730 valid_f1:0.617\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 379  425  419]\n",
            " [ 130 3200  294]\n",
            " [ 149  370 1352]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 71 224  91]\n",
            " [ 15 773  61]\n",
            " [ 50 152 243]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.628 valid_loss:0.781\n",
            "\ttrain_acc:73.90% valid_acc:65.65%\n",
            "\ttrain_f1:0.732 valid_f1:0.640\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 375  434  427]\n",
            " [ 120 3214  260]\n",
            " [ 139  363 1347]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 96 214  76]\n",
            " [ 25 767  57]\n",
            " [ 58 147 240]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.623 valid_loss:0.764\n",
            "\ttrain_acc:73.98% valid_acc:67.56%\n",
            "\ttrain_f1:0.740 valid_f1:0.646\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 412  422  395]\n",
            " [ 123 3250  246]\n",
            " [ 152  405 1294]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 89 184 113]\n",
            " [ 18 734  97]\n",
            " [ 34  99 312]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.606 valid_loss:0.758\n",
            "\ttrain_acc:75.27% valid_acc:67.44%\n",
            "\ttrain_f1:0.752 valid_f1:0.657\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 433  367  431]\n",
            " [ 121 3205  273]\n",
            " [ 150  316 1408]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[105 179 102]\n",
            " [ 24 730  95]\n",
            " [ 46 101 298]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.590 valid_loss:0.785\n",
            "\ttrain_acc:76.14% valid_acc:67.74%\n",
            "\ttrain_f1:0.759 valid_f1:0.668\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 439  369  429]\n",
            " [ 119 3261  244]\n",
            " [ 132  309 1413]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[115 196  75]\n",
            " [ 19 771  59]\n",
            " [ 61 132 252]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        feature, mask, label = data\n",
        "        feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(feature)\n",
        "        loss = loss_fn(pred_logits, mask, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        masks.append(mask)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds, masks, labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "            loss = loss_fn(pred_logits, mask, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            masks.append(mask)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds, masks, labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3, 1.0)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.3, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2_full_clean.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.60      0.27      0.37       386\n",
            "    Positive       0.72      0.86      0.79       849\n",
            "    Negative       0.60      0.67      0.63       445\n",
            "\n",
            "    accuracy                           0.67      1680\n",
            "   macro avg       0.64      0.60      0.60      1680\n",
            "weighted avg       0.66      0.67      0.65      1680\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            pred_tags = pred_tags[mask]\n",
        "            label = label[mask]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "cnn_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
