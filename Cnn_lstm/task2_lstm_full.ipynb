{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Pp-VjL_5Xw",
        "outputId": "a043786f-12ea-4b95-f6bb-4f7c9288537a"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\"\n",
        "VALID_SIZE = .2\n",
        "MODEL_PATH = \"model_task2_full.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VVlBRwsjo3A9"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext\n",
        "#!pip install transformers\n",
        "#import nltk\n",
        "#nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bAicdvsynjtH"
      },
      "outputs": [],
      "source": [
        "from ast import FloorDiv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.optim import AdamW\n",
        "from fasttext import load_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Dataset/data/restaurants_laptop_train_with_pos_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "      <th>aspect_tag</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>s_1</td>\n",
              "      <td>I</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s_1</td>\n",
              "      <td>charge</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s_1</td>\n",
              "      <td>it</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s_1</td>\n",
              "      <td>at</td>\n",
              "      <td>ADP</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s_1</td>\n",
              "      <td>night</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num    text   pos aspect_tag  polarity\n",
              "0  s_1       I  PRON        NAT         0\n",
              "1  s_1  charge  VERB        NAT         0\n",
              "2  s_1      it  PRON        NAT         0\n",
              "3  s_1      at   ADP        NAT         0\n",
              "4  s_1   night  NOUN        NAT         0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of aspect tags: 2\n",
            "num of polarity tags: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# replace all -1 to 2 since pytorch cannot handle negative\n",
        "# so, 2 now means negative polarity\n",
        "df.polarity = df.polarity.replace(-1,2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
        "\n",
        "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
        "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
        "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
        "\n",
        "polarity_unique_values = df.polarity.unique()\n",
        "\n",
        "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
        "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
        "\n",
        "np.where(encoder.classes_ == \"AT\")[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3432\n",
            "3432\n",
            "3432\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences))\n",
        "print(len(aspect_tags))\n",
        "print(len(polarity_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80\n"
          ]
        }
      ],
      "source": [
        "print(max(map(lambda x: len(x), sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "dkojY_dde3K-"
      },
      "outputs": [],
      "source": [
        "# generate word_index list\n",
        "def build_vocab(df):\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(sorted(set(df.text.values))):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "def create_train_data_restaurant(sentences, word_idx, pol_tags, sent_len=83):\n",
        "    train_X = np.zeros((len(sentences), sent_len), np.int16)\n",
        "    mask = np.zeros_like(train_X)\n",
        "\n",
        "    train_y = np.zeros((len(sentences), sent_len), np.int16)\n",
        "\n",
        "    # iterate the sentence\n",
        "    for sx, sent in enumerate(sentences):\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(sent):\n",
        "                train_X[sx, wx] = word_idx[word]\n",
        "                mask[sx, wx] = 1\n",
        "                train_y[sx, wx] = pol_tags[sx][wx]\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    return (train_X, mask), train_y\n",
        "\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, mask, label, num_tag):\n",
        "    label.masked_fill_(~mask, -100)\n",
        "    pred = pred.view(-1, num_tag)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, mask, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        mask = torch.cat(mask, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    pred_tags = pred_tags[mask]\n",
        "    true_tags = true_tags[mask]\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "\n",
        "    return acc, f1, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnbH1kXllslz",
        "outputId": "e54a1149-6949-4d20-e7eb-05dc01f35f7b"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, num_classes=3):\n",
        "        super(Model, self).__init__()\n",
        "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
        "        self.gen_embedding.weight = torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
        "        self.lstm = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dense = torch.nn.Linear(gen_emb.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x_train):\n",
        "        x_emb = self.gen_embedding(x_train)\n",
        "\n",
        "        output, (h_n, _) = self.lstm(x_emb.float())\n",
        "        out = self.dense(output)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_indx = build_vocab(df)\n",
        "\n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)\n",
        "\n",
        "\n",
        "(X, mask), y = create_train_data_restaurant(sentences, word_indx, polarity_tags, sent_len=83)\n",
        "\n",
        "X_train, X_valid, mask_train, mask_valid, y_train, y_valid = train_test_split(X, mask, y, test_size=VALID_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:2745\n",
            "valid samples:687\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(mask_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_valid), torch.Tensor(mask_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:06<00:00,  3.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.016 valid_loss:0.883\n",
            "\ttrain_acc:67.81% valid_acc:87.58%\n",
            "\ttrain_f1:0.754 valid_f1:0.857\n",
            "\ttrain_confusion_matrix:\n",
            "[[28732  1616  7666]\n",
            " [ 2417   277   870]\n",
            " [ 1304   107   439]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9746   15   19]\n",
            " [ 881    4    9]\n",
            " [ 459    0    4]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:07<00:00,  2.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:0.764 valid_loss:0.629\n",
            "\ttrain_acc:87.42% valid_acc:87.79%\n",
            "\ttrain_f1:0.854 valid_f1:0.857\n",
            "\ttrain_confusion_matrix:\n",
            "[[37935    22    68]\n",
            " [ 3525    12    11]\n",
            " [ 1830     8     6]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9773    2    5]\n",
            " [ 890    3    1]\n",
            " [ 462    0    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:09<00:00,  2.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.525 valid_loss:0.438\n",
            "\ttrain_acc:87.42% valid_acc:87.82%\n",
            "\ttrain_f1:0.853 valid_f1:0.857\n",
            "\ttrain_confusion_matrix:\n",
            "[[37939     4    27]\n",
            " [ 3578     5     2]\n",
            " [ 1845     4     3]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9778    0    2]\n",
            " [ 893    1    0]\n",
            " [ 462    0    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:09<00:00,  2.32it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.424 valid_loss:0.418\n",
            "\ttrain_acc:87.51% valid_acc:87.82%\n",
            "\ttrain_f1:0.854 valid_f1:0.857\n",
            "\ttrain_confusion_matrix:\n",
            "[[37932     2    12]\n",
            " [ 3551     3     0]\n",
            " [ 1846     1     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9778    0    2]\n",
            " [ 893    1    0]\n",
            " [ 462    0    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:08<00:00,  2.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.407 valid_loss:0.403\n",
            "\ttrain_acc:87.49% valid_acc:87.76%\n",
            "\ttrain_f1:0.853 valid_f1:0.857\n",
            "\ttrain_confusion_matrix:\n",
            "[[37921     1     9]\n",
            " [ 3581     3     0]\n",
            " [ 1830     1     0]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9771    7    2]\n",
            " [ 892    2    0]\n",
            " [ 462    0    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:08<00:00,  2.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.396 valid_loss:0.392\n",
            "\ttrain_acc:87.51% valid_acc:87.80%\n",
            "\ttrain_f1:0.854 valid_f1:0.858\n",
            "\ttrain_confusion_matrix:\n",
            "[[37925     5     5]\n",
            " [ 3559    17     0]\n",
            " [ 1847     1     0]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9771    9    0]\n",
            " [ 888    6    0]\n",
            " [ 461    1    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:08<00:00,  2.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.384 valid_loss:0.382\n",
            "\ttrain_acc:87.67% valid_acc:87.88%\n",
            "\ttrain_f1:0.857 valid_f1:0.861\n",
            "\ttrain_confusion_matrix:\n",
            "[[38064    13     1]\n",
            " [ 3494    52     0]\n",
            " [ 1849     3     0]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9767   13    0]\n",
            " [ 875   19    0]\n",
            " [ 459    3    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:08<00:00,  2.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.373 valid_loss:0.372\n",
            "\ttrain_acc:87.81% valid_acc:87.98%\n",
            "\ttrain_f1:0.862 valid_f1:0.865\n",
            "\ttrain_confusion_matrix:\n",
            "[[38088    34     1]\n",
            " [ 3431   150     0]\n",
            " [ 1828    15     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9754   26    0]\n",
            " [ 851   43    0]\n",
            " [ 454    8    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:08<00:00,  2.38it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.362 valid_loss:0.362\n",
            "\ttrain_acc:88.03% valid_acc:88.14%\n",
            "\ttrain_f1:0.869 valid_f1:0.870\n",
            "\ttrain_confusion_matrix:\n",
            "[[37950    78     1]\n",
            " [ 3286   295     0]\n",
            " [ 1790    46     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9744   36    0]\n",
            " [ 823   71    0]\n",
            " [ 444   18    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:08<00:00,  2.44it/s]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.351 valid_loss:0.352\n",
            "\ttrain_acc:88.29% valid_acc:88.39%\n",
            "\ttrain_f1:0.875 valid_f1:0.877\n",
            "\ttrain_confusion_matrix:\n",
            "[[37963   120     1]\n",
            " [ 3129   424     0]\n",
            " [ 1775    64     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9734   46    0]\n",
            " [ 785  109    0]\n",
            " [ 437   25    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:04<00:00,  5.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.343 valid_loss:0.342\n",
            "\ttrain_acc:88.59% valid_acc:88.61%\n",
            "\ttrain_f1:0.883 valid_f1:0.883\n",
            "\ttrain_confusion_matrix:\n",
            "[[37879   168     1]\n",
            " [ 2950   624     0]\n",
            " [ 1749    92     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9722   58    0]\n",
            " [ 749  145    0]\n",
            " [ 429   33    1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.332 valid_loss:0.332\n",
            "\ttrain_acc:88.79% valid_acc:88.71%\n",
            "\ttrain_f1:0.888 valid_f1:0.887\n",
            "\ttrain_confusion_matrix:\n",
            "[[37807   222     0]\n",
            " [ 2803   769     0]\n",
            " [ 1721   123     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9702   78    0]\n",
            " [ 716  178    0]\n",
            " [ 427   36    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.323 valid_loss:0.322\n",
            "\ttrain_acc:88.94% valid_acc:88.79%\n",
            "\ttrain_f1:0.892 valid_f1:0.890\n",
            "\ttrain_confusion_matrix:\n",
            "[[37639   274     0]\n",
            " [ 2680   910     0]\n",
            " [ 1673   166     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9684   96    0]\n",
            " [ 689  205    0]\n",
            " [ 423   40    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.312 valid_loss:0.313\n",
            "\ttrain_acc:89.14% valid_acc:88.84%\n",
            "\ttrain_f1:0.897 valid_f1:0.892\n",
            "\ttrain_confusion_matrix:\n",
            "[[37700   363     0]\n",
            " [ 2521  1066     0]\n",
            " [ 1628   213     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9671  109    0]\n",
            " [ 671  223    0]\n",
            " [ 421   42    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  6.25it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.303 valid_loss:0.303\n",
            "\ttrain_acc:89.20% valid_acc:88.99%\n",
            "\ttrain_f1:0.899 valid_f1:0.896\n",
            "\ttrain_confusion_matrix:\n",
            "[[37548   381     1]\n",
            " [ 2449  1125     1]\n",
            " [ 1621   228     1]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9650  129    1]\n",
            " [ 633  261    0]\n",
            " [ 415   48    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  6.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.292 valid_loss:0.295\n",
            "\ttrain_acc:89.43% valid_acc:89.05%\n",
            "\ttrain_f1:0.903 valid_f1:0.897\n",
            "\ttrain_confusion_matrix:\n",
            "[[37597   411     3]\n",
            " [ 2336  1239     2]\n",
            " [ 1595   242     4]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9652  126    2]\n",
            " [ 629  265    0]\n",
            " [ 413   50    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  6.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.283 valid_loss:0.285\n",
            "\ttrain_acc:89.56% valid_acc:89.31%\n",
            "\ttrain_f1:0.905 valid_f1:0.902\n",
            "\ttrain_confusion_matrix:\n",
            "[[37661   410     7]\n",
            " [ 2285  1282     4]\n",
            " [ 1583   250    10]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9641  132    7]\n",
            " [ 590  304    0]\n",
            " [ 403   58    2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  6.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.275 valid_loss:0.277\n",
            "\ttrain_acc:89.76% valid_acc:89.55%\n",
            "\ttrain_f1:0.909 valid_f1:0.906\n",
            "\ttrain_confusion_matrix:\n",
            "[[37524   460    16]\n",
            " [ 2136  1435     8]\n",
            " [ 1553   272    19]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9638  134    8]\n",
            " [ 565  329    0]\n",
            " [ 396   61    6]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.266 valid_loss:0.271\n",
            "\ttrain_acc:90.02% valid_acc:89.69%\n",
            "\ttrain_f1:0.912 valid_f1:0.907\n",
            "\ttrain_confusion_matrix:\n",
            "[[37524   442    23]\n",
            " [ 2065  1500     9]\n",
            " [ 1532   259    37]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9635  137    8]\n",
            " [ 550  344    0]\n",
            " [ 394   59   10]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.261 valid_loss:0.265\n",
            "\ttrain_acc:90.20% valid_acc:89.99%\n",
            "\ttrain_f1:0.915 valid_f1:0.911\n",
            "\ttrain_confusion_matrix:\n",
            "[[37476   480    25]\n",
            " [ 1954  1608    16]\n",
            " [ 1497   280    63]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[9637  129   14]\n",
            " [ 528  360    6]\n",
            " [ 378   60   25]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"aspact_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"aspact_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        feature, mask, label = data\n",
        "        feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(feature)\n",
        "        loss = loss_fn(pred_logits, mask, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        masks.append(mask)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds, masks, labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "            loss = loss_fn(pred_logits, mask, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            masks.append(mask)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds, masks, labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['aspact_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['aspact_valid_acc'].append(avg_test_acc.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.85, 1.0)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history['aspact_train_acc'], label='train accuracy')\n",
        "plt.plot(history['aspact_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.85, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2_full.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.91      0.99      0.95      9780\n",
            "    Positive       0.66      0.40      0.50       894\n",
            "    Negative       0.56      0.05      0.10       463\n",
            "\n",
            "    accuracy                           0.90     11137\n",
            "   macro avg       0.71      0.48      0.52     11137\n",
            "weighted avg       0.88      0.90      0.88     11137\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            pred_tags = pred_tags[mask]\n",
        "            label = label[mask]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "cnn_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
