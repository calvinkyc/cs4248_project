{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Pp-VjL_5Xw",
        "outputId": "a043786f-12ea-4b95-f6bb-4f7c9288537a"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\"\n",
        "VALID_SIZE = .2\n",
        "MODEL_PATH = \"model_task2_full.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VVlBRwsjo3A9"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext\n",
        "#!pip install transformers\n",
        "#import nltk\n",
        "#nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bAicdvsynjtH"
      },
      "outputs": [],
      "source": [
        "from ast import FloorDiv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.optim import AdamW\n",
        "from fasttext import load_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## No clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Dataset/data/restaurants_laptop_train_with_pos_task2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "      <th>aspect_tag</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>s_1</td>\n",
              "      <td>I</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s_1</td>\n",
              "      <td>charge</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s_1</td>\n",
              "      <td>it</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s_1</td>\n",
              "      <td>at</td>\n",
              "      <td>ADP</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s_1</td>\n",
              "      <td>night</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num    text   pos aspect_tag  polarity\n",
              "0  s_1       I  PRON        NAT         0\n",
              "1  s_1  charge  VERB        NAT         0\n",
              "2  s_1      it  PRON        NAT         0\n",
              "3  s_1      at   ADP        NAT         0\n",
              "4  s_1   night  NOUN        NAT         0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of aspect tags: 2\n",
            "num of polarity tags: 4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# replace all -1 to 2 since pytorch cannot handle negative\n",
        "# so, 2 now means negative polarity\n",
        "df.polarity = df.polarity.replace(-1,2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
        "\n",
        "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
        "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
        "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
        "\n",
        "polarity_unique_values = df.polarity.unique()\n",
        "\n",
        "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
        "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
        "\n",
        "np.where(encoder.classes_ == \"AT\")[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3501\n",
            "3501\n",
            "3501\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences))\n",
        "print(len(aspect_tags))\n",
        "print(len(polarity_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84\n"
          ]
        }
      ],
      "source": [
        "print(max(map(lambda x: len(x), sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dkojY_dde3K-"
      },
      "outputs": [],
      "source": [
        "# generate word_index list\n",
        "def build_vocab(df):\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(sorted(set(df.text.values))):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "def create_train_data_restaurant(sentences, word_idx, pol_tags, sent_len=85):\n",
        "    train_X = np.zeros((len(sentences), sent_len), np.int16)\n",
        "    mask = np.zeros_like(train_X)\n",
        "\n",
        "    train_y = np.zeros((len(sentences), sent_len), np.int16)\n",
        "\n",
        "    # iterate the sentence\n",
        "    for sx, sent in enumerate(sentences):\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(sent):\n",
        "                train_X[sx, wx] = word_idx[word]\n",
        "                if aspect_tags[sx][wx] == 0:\n",
        "                    mask[sx, wx] = 1\n",
        "                elif aspect_tags[sx][wx] == 1:\n",
        "                    mask[sx, wx] = 0\n",
        "                train_y[sx, wx] = pol_tags[sx][wx]\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    return (train_X, mask), train_y\n",
        "\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, mask, label, num_tag):\n",
        "    label.masked_fill_(~mask, -100)\n",
        "    pred = pred.view(-1, num_tag)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, mask, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        mask = torch.cat(mask, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    pred_tags = pred_tags[mask]\n",
        "    true_tags = true_tags[mask]\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "\n",
        "    return acc, f1, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnbH1kXllslz",
        "outputId": "e54a1149-6949-4d20-e7eb-05dc01f35f7b"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, num_classes=3):\n",
        "        super(Model, self).__init__()\n",
        "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
        "        self.gen_embedding.weight = torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
        "        self.lstm = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dense = torch.nn.Linear(gen_emb.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x_train):\n",
        "        x_emb = self.gen_embedding(x_train)\n",
        "\n",
        "        output, (h_n, _) = self.lstm(x_emb.float())\n",
        "        out = self.dense(output)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_indx = build_vocab(df)\n",
        "\n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)\n",
        "\n",
        "\n",
        "(X, mask), y = create_train_data_restaurant(sentences, word_indx, polarity_tags, sent_len=85)\n",
        "\n",
        "X_train, X_valid, mask_train, mask_valid, y_train, y_valid = train_test_split(X, mask, y, test_size=VALID_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:2800\n",
            "valid samples:701\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(mask_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_valid), torch.Tensor(mask_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.068 valid_loss:1.044\n",
            "\ttrain_acc:43.57% valid_acc:49.36%\n",
            "\ttrain_f1:0.406 valid_f1:0.456\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0  668  606]\n",
            " [   2 1923 1750]\n",
            " [   3  770 1010]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 310  31]\n",
            " [  0 752  35]\n",
            " [  0 450  53]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.006 valid_loss:1.017\n",
            "\ttrain_acc:54.45% valid_acc:48.74%\n",
            "\ttrain_f1:0.519 valid_f1:0.456\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1256   23]\n",
            " [   0 3571   68]\n",
            " [   1 1716   92]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 340   1]\n",
            " [  0 786   1]\n",
            " [  0 494   9]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:04<00:00,  5.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.966 valid_loss:1.006\n",
            "\ttrain_acc:55.11% valid_acc:48.62%\n",
            "\ttrain_f1:0.526 valid_f1:0.455\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1269    4]\n",
            " [   0 3652    7]\n",
            " [   1 1729   44]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 340   1]\n",
            " [  0 785   2]\n",
            " [  0 495   8]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.944 valid_loss:0.992\n",
            "\ttrain_acc:55.70% valid_acc:50.03%\n",
            "\ttrain_f1:0.529 valid_f1:0.461\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1253   26]\n",
            " [   0 3671   11]\n",
            " [   1 1687   74]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 324  17]\n",
            " [  0 779   8]\n",
            " [  0 466  37]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.56it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.926 valid_loss:0.973\n",
            "\ttrain_acc:57.28% valid_acc:52.54%\n",
            "\ttrain_f1:0.537 valid_f1:0.474\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1150  108]\n",
            " [   0 3581   37]\n",
            " [   1 1549  234]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 294  47]\n",
            " [  0 768  19]\n",
            " [  0 414  89]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.897 valid_loss:0.946\n",
            "\ttrain_acc:60.67% valid_acc:54.94%\n",
            "\ttrain_f1:0.557 valid_f1:0.485\n",
            "\ttrain_confusion_matrix:\n",
            "[[   1 1001  273]\n",
            " [   0 3544  150]\n",
            " [   0 1235  556]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 254  87]\n",
            " [  0 737  50]\n",
            " [  0 344 159]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:04<00:00,  5.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.864 valid_loss:0.910\n",
            "\ttrain_acc:62.03% valid_acc:56.10%\n",
            "\ttrain_f1:0.561 valid_f1:0.494\n",
            "\ttrain_confusion_matrix:\n",
            "[[   3  929  354]\n",
            " [   2 3425  209]\n",
            " [   0 1056  737]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  2 210 129]\n",
            " [  0 697  90]\n",
            " [  0 287 216]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.822 valid_loss:0.881\n",
            "\ttrain_acc:64.34% valid_acc:58.74%\n",
            "\ttrain_f1:0.580 valid_f1:0.535\n",
            "\ttrain_confusion_matrix:\n",
            "[[  17  833  435]\n",
            " [   6 3360  313]\n",
            " [   3  809  951]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 20 181 140]\n",
            " [  0 681 106]\n",
            " [  1 245 257]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.790 valid_loss:0.866\n",
            "\ttrain_acc:66.34% valid_acc:59.90%\n",
            "\ttrain_f1:0.606 valid_f1:0.561\n",
            "\ttrain_confusion_matrix:\n",
            "[[  57  743  479]\n",
            " [  11 3304  347]\n",
            " [  12  676 1108]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 34 173 134]\n",
            " [  6 688  93]\n",
            " [  4 244 255]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.756 valid_loss:0.839\n",
            "\ttrain_acc:67.23% valid_acc:62.29%\n",
            "\ttrain_f1:0.630 valid_f1:0.597\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 105  697  453]\n",
            " [  26 3327  316]\n",
            " [  31  673 1073]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 54 146 141]\n",
            " [ 14 674  99]\n",
            " [ 10 205 288]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.734 valid_loss:0.824\n",
            "\ttrain_acc:68.73% valid_acc:62.91%\n",
            "\ttrain_f1:0.658 valid_f1:0.615\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 178  595  486]\n",
            " [  47 3226  354]\n",
            " [  52  556 1190]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 68 139 134]\n",
            " [ 15 672 100]\n",
            " [ 17 200 286]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.712 valid_loss:0.809\n",
            "\ttrain_acc:69.74% valid_acc:64.75%\n",
            "\ttrain_f1:0.677 valid_f1:0.648\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 221  578  443]\n",
            " [  68 3272  301]\n",
            " [  95  534 1160]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 94 117 130]\n",
            " [ 20 660 107]\n",
            " [ 29 172 302]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.692 valid_loss:0.794\n",
            "\ttrain_acc:70.22% valid_acc:65.79%\n",
            "\ttrain_f1:0.685 valid_f1:0.664\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 260  579  447]\n",
            " [  70 3293  301]\n",
            " [ 103  506 1178]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[107 105 129]\n",
            " [ 24 655 108]\n",
            " [ 42 150 311]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.663 valid_loss:0.789\n",
            "\ttrain_acc:71.83% valid_acc:66.34%\n",
            "\ttrain_f1:0.707 valid_f1:0.672\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 320  532  430]\n",
            " [  94 3290  289]\n",
            " [ 127  425 1226]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[112 108 121]\n",
            " [ 26 671  90]\n",
            " [ 48 156 299]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.652 valid_loss:0.785\n",
            "\ttrain_acc:73.02% valid_acc:66.46%\n",
            "\ttrain_f1:0.726 valid_f1:0.677\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 402  502  382]\n",
            " [ 122 3282  266]\n",
            " [ 142  399 1222]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[122 104 115]\n",
            " [ 31 661  95]\n",
            " [ 56 146 301]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.627 valid_loss:0.777\n",
            "\ttrain_acc:73.82% valid_acc:66.89%\n",
            "\ttrain_f1:0.734 valid_f1:0.679\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 415  487  392]\n",
            " [ 108 3310  254]\n",
            " [ 146  378 1253]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[121  83 137]\n",
            " [ 26 623 138]\n",
            " [ 46 110 347]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.611 valid_loss:0.793\n",
            "\ttrain_acc:74.97% valid_acc:65.91%\n",
            "\ttrain_f1:0.751 valid_f1:0.668\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 468  428  374]\n",
            " [ 123 3276  256]\n",
            " [ 150  349 1289]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[113 118 110]\n",
            " [ 32 675  80]\n",
            " [ 63 153 287]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.600 valid_loss:0.788\n",
            "\ttrain_acc:75.26% valid_acc:65.67%\n",
            "\ttrain_f1:0.757 valid_f1:0.661\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 491  415  366]\n",
            " [ 128 3312  247]\n",
            " [ 159  352 1269]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[108 116 117]\n",
            " [ 28 655 104]\n",
            " [ 50 145 308]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.590 valid_loss:0.780\n",
            "\ttrain_acc:75.77% valid_acc:66.22%\n",
            "\ttrain_f1:0.759 valid_f1:0.686\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 490  416  362]\n",
            " [ 122 3268  249]\n",
            " [ 152  319 1309]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[144  97 100]\n",
            " [ 52 655  80]\n",
            " [ 89 133 281]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.574 valid_loss:0.786\n",
            "\ttrain_acc:77.12% valid_acc:66.58%\n",
            "\ttrain_f1:0.780 valid_f1:0.688\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 581  362  359]\n",
            " [ 128 3324  227]\n",
            " [ 172  295 1297]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[141 101  99]\n",
            " [ 49 668  70]\n",
            " [ 85 141 277]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        feature, mask, label = data\n",
        "        feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(feature)\n",
        "        loss = loss_fn(pred_logits, mask, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        masks.append(mask)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds, masks, labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "            loss = loss_fn(pred_logits, mask, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            masks.append(mask)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds, masks, labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3, 1.0)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.3, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2_full.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.63      0.35      0.45       341\n",
            "    Positive       0.76      0.79      0.78       787\n",
            "    Negative       0.56      0.69      0.62       503\n",
            "\n",
            "    accuracy                           0.67      1631\n",
            "   macro avg       0.65      0.61      0.62      1631\n",
            "weighted avg       0.67      0.67      0.66      1631\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            pred_tags = pred_tags[mask]\n",
        "            label = label[mask]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'model_task2_full.bin'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Pp-VjL_5Xw",
        "outputId": "a043786f-12ea-4b95-f6bb-4f7c9288537a"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data/\"\n",
        "VALID_SIZE = .2\n",
        "MODEL_PATH = \"model_task2_full_clean.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Dataset/data/restaurants_laptop_train_with_pos_task2_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "      <th>aspect_tag</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>s_1</td>\n",
              "      <td>I</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s_1</td>\n",
              "      <td>charge</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s_1</td>\n",
              "      <td>it</td>\n",
              "      <td>PRON</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s_1</td>\n",
              "      <td>at</td>\n",
              "      <td>ADP</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s_1</td>\n",
              "      <td>night</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num    text   pos aspect_tag  polarity\n",
              "0  s_1       I  PRON        NAT         0\n",
              "1  s_1  charge  VERB        NAT         0\n",
              "2  s_1      it  PRON        NAT         0\n",
              "3  s_1      at   ADP        NAT         0\n",
              "4  s_1   night  NOUN        NAT         0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of aspect tags: 2\n",
            "num of polarity tags: 4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# replace all -1 to 2 since pytorch cannot handle negative\n",
        "# so, 2 now means negative polarity\n",
        "df.polarity = df.polarity.replace(-1,2)\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "df.loc[:, \"aspect_tag\"] = encoder.fit_transform(df[\"aspect_tag\"])\n",
        "\n",
        "sentences = df.groupby(\"num\")[\"text\"].apply(list).values\n",
        "aspect_tags = df.groupby(\"num\")[\"aspect_tag\"].apply(list).values\n",
        "polarity_tags = df.groupby(\"num\")[\"polarity\"].apply(list).values\n",
        "\n",
        "polarity_unique_values = df.polarity.unique()\n",
        "\n",
        "print('num of aspect tags: {}'.format(len(encoder.classes_)))\n",
        "print('num of polarity tags: {}'.format(len(polarity_unique_values)))\n",
        "\n",
        "np.where(encoder.classes_ == \"AT\")[0].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3501\n",
            "3501\n",
            "3501\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences))\n",
        "print(len(aspect_tags))\n",
        "print(len(polarity_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80\n"
          ]
        }
      ],
      "source": [
        "print(max(map(lambda x: len(x), sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dkojY_dde3K-"
      },
      "outputs": [],
      "source": [
        "# generate word_index list\n",
        "def build_vocab(df):\n",
        "    word_idx = {}\n",
        "    for idx, word in enumerate(sorted(set(df.text.values))):\n",
        "        word_idx[word] = idx + 1\n",
        "    return word_idx\n",
        "\n",
        "def gen_np_embedding(fn, word_idx, dim=100, emb=False):\n",
        "    if emb:\n",
        "        model = load_model(fn + \".bin\")\n",
        "    embedding = np.zeros((len(word_idx) + 2, dim))\n",
        "\n",
        "    with open(fn, encoding=\"utf8\") as f:\n",
        "        for l in f:\n",
        "            # for each line, get the word and its vector\n",
        "            rec = l.rstrip().split(' ')\n",
        "            if len(rec) == 2:  # skip the first line.\n",
        "                continue\n",
        "                # if the word in word_idx, fill the embedding\n",
        "            if rec[0] in word_idx:\n",
        "                embedding[word_idx[rec[0]]] = np.array([float(r) for r in rec[1:]])\n",
        "    for w in word_idx:\n",
        "        if embedding[word_idx[w]].sum() == 0.:\n",
        "            if emb:\n",
        "                embedding[word_idx[w]] = model.get_word_vector(w)\n",
        "    return embedding\n",
        "\n",
        "def create_train_data_restaurant(sentences, word_idx, pol_tags, sent_len=85):\n",
        "    train_X = np.zeros((len(sentences), sent_len), np.int16)\n",
        "    mask = np.zeros_like(train_X)\n",
        "\n",
        "    train_y = np.zeros((len(sentences), sent_len), np.int16)\n",
        "\n",
        "    # iterate the sentence\n",
        "    for sx, sent in enumerate(sentences):\n",
        "        # write word index and tag in train_X\n",
        "        try:\n",
        "            for wx, word in enumerate(sent):\n",
        "                train_X[sx, wx] = word_idx[word]\n",
        "                if aspect_tags[sx][wx] == 0:\n",
        "                    mask[sx, wx] = 1\n",
        "                elif aspect_tags[sx][wx] == 1:\n",
        "                    mask[sx, wx] = 0\n",
        "                train_y[sx, wx] = pol_tags[sx][wx]\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "    return (train_X, mask), train_y\n",
        "\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    elif isinstance(data, dict):\n",
        "        for k, v in data.items():\n",
        "            data[k] = v.to(device)\n",
        "        return data\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "\n",
        "def loss_fn(pred, mask, label, num_tag):\n",
        "    label.masked_fill_(~mask, -100)\n",
        "    pred = pred.view(-1, num_tag)\n",
        "    label = label.view(-1)\n",
        "    loss = torch.nn.functional.cross_entropy(pred, label)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def cal_acc(pred_tags, mask, true_tags):\n",
        "    if isinstance(pred_tags, list):\n",
        "        pred_tags = torch.cat(pred_tags, 0)\n",
        "        mask = torch.cat(mask, 0)\n",
        "        true_tags = torch.cat(true_tags, 0)\n",
        "    pred_tags = pred_tags[mask]\n",
        "    true_tags = true_tags[mask]\n",
        "    acc = (pred_tags == true_tags).sum() / pred_tags.numel()\n",
        "    f1 = f1_score(true_tags.cpu().numpy(), pred_tags.cpu().numpy(), labels=[0, 1], average='weighted')\n",
        "    cm = confusion_matrix(true_tags.cpu().numpy(), pred_tags.cpu().numpy())\n",
        "\n",
        "    return acc, f1, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnbH1kXllslz",
        "outputId": "e54a1149-6949-4d20-e7eb-05dc01f35f7b"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, gen_emb, num_classes=3):\n",
        "        super(Model, self).__init__()\n",
        "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
        "        self.gen_embedding.weight = torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
        "        self.lstm = nn.LSTM(gen_emb.shape[1], hidden_size=150, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dense = torch.nn.Linear(gen_emb.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x_train):\n",
        "        x_emb = self.gen_embedding(x_train)\n",
        "\n",
        "        output, (h_n, _) = self.lstm(x_emb.float())\n",
        "        out = self.dense(output)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_indx = build_vocab(df)\n",
        "\n",
        "fn = DATA_DIR + 'glove.840B.300d.txt'\n",
        "general_embedding = gen_np_embedding(fn, word_indx, dim=300, emb=False)\n",
        "\n",
        "\n",
        "(X, mask), y = create_train_data_restaurant(sentences, word_indx, polarity_tags, sent_len=85)\n",
        "\n",
        "X_train, X_valid, mask_train, mask_valid, y_train, y_valid = train_test_split(X, mask, y, test_size=VALID_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train samples:2800\n",
            "valid samples:701\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "VALID_BATCH_SIZE = 1024\n",
        "\n",
        "NUM_POLARITY_TAGS = 3\n",
        "\n",
        "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(mask_train), torch.Tensor(y_train))\n",
        "print(f\"train samples:{len(dataset)}\")\n",
        "train_loader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "dataset_valid = TensorDataset(torch.Tensor(X_valid), torch.Tensor(mask_valid), torch.Tensor(y_valid))\n",
        "print(f\"valid samples:{len(dataset_valid)}\")\n",
        "test_loader = DataLoader(dataset_valid, batch_size=VALID_BATCH_SIZE)\n",
        "\n",
        "model = to_device(Model(general_embedding,  num_classes=3), device)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = AdamW(parameters, lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 0\n",
            "\ttrain_loss:1.074 valid_loss:1.048\n",
            "\ttrain_acc:43.81% valid_acc:49.34%\n",
            "\ttrain_f1:0.434 valid_f1:0.451\n",
            "\ttrain_confusion_matrix:\n",
            "[[  24  730  424]\n",
            " [  58 2100 1379]\n",
            " [  24 1048  732]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 394  17]\n",
            " [  0 852  23]\n",
            " [  0 452  11]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1\n",
            "\ttrain_loss:1.008 valid_loss:1.014\n",
            "\ttrain_acc:54.19% valid_acc:49.86%\n",
            "\ttrain_f1:0.526 valid_f1:0.453\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1164   15]\n",
            " [   0 3489   38]\n",
            " [   0 1763   36]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 411   0]\n",
            " [  0 871   4]\n",
            " [  0 462   1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 2\n",
            "\ttrain_loss:0.976 valid_loss:0.998\n",
            "\ttrain_acc:53.86% valid_acc:49.91%\n",
            "\ttrain_f1:0.521 valid_f1:0.453\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1186    9]\n",
            " [   0 3483    7]\n",
            " [   0 1801   23]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 409   2]\n",
            " [  0 871   4]\n",
            " [  0 461   2]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 3\n",
            "\ttrain_loss:0.951 valid_loss:0.984\n",
            "\ttrain_acc:54.99% valid_acc:51.06%\n",
            "\ttrain_f1:0.530 valid_f1:0.458\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1163   31]\n",
            " [   0 3526   23]\n",
            " [   0 1725   68]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 393  18]\n",
            " [  0 864  11]\n",
            " [  0 434  29]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.83it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 4\n",
            "\ttrain_loss:0.931 valid_loss:0.965\n",
            "\ttrain_acc:57.54% valid_acc:53.00%\n",
            "\ttrain_f1:0.545 valid_f1:0.468\n",
            "\ttrain_confusion_matrix:\n",
            "[[   0 1041  128]\n",
            " [   0 3471   63]\n",
            " [   0 1524  264]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 365  46]\n",
            " [  0 853  22]\n",
            " [  0 389  74]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 5\n",
            "\ttrain_loss:0.911 valid_loss:0.943\n",
            "\ttrain_acc:59.79% valid_acc:56.26%\n",
            "\ttrain_f1:0.556 valid_f1:0.484\n",
            "\ttrain_confusion_matrix:\n",
            "[[   5  926  271]\n",
            " [   0 3386  143]\n",
            " [   0 1284  510]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  0 326  85]\n",
            " [  0 837  38]\n",
            " [  0 316 147]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 6\n",
            "\ttrain_loss:0.876 valid_loss:0.910\n",
            "\ttrain_acc:62.25% valid_acc:57.63%\n",
            "\ttrain_f1:0.574 valid_f1:0.493\n",
            "\ttrain_confusion_matrix:\n",
            "[[  10  811  374]\n",
            " [   0 3345  218]\n",
            " [   0 1067  718]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[  1 293 117]\n",
            " [  0 810  65]\n",
            " [  0 266 197]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 7\n",
            "\ttrain_loss:0.845 valid_loss:0.887\n",
            "\ttrain_acc:63.78% valid_acc:59.29%\n",
            "\ttrain_f1:0.587 valid_f1:0.521\n",
            "\ttrain_confusion_matrix:\n",
            "[[  21  676  501]\n",
            " [   1 3216  323]\n",
            " [   0  874  945]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 15 263 133]\n",
            " [  2 794  79]\n",
            " [  0 235 228]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 8\n",
            "\ttrain_loss:0.809 valid_loss:0.864\n",
            "\ttrain_acc:65.44% valid_acc:60.03%\n",
            "\ttrain_f1:0.612 valid_f1:0.532\n",
            "\ttrain_confusion_matrix:\n",
            "[[  68  649  474]\n",
            " [  11 3204  303]\n",
            " [   8  810  998]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 22 256 133]\n",
            " [  3 782  90]\n",
            " [  1 216 246]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 9\n",
            "\ttrain_loss:0.775 valid_loss:0.830\n",
            "\ttrain_acc:66.85% valid_acc:62.61%\n",
            "\ttrain_f1:0.632 valid_f1:0.571\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 101  593  494]\n",
            " [  20 3178  337]\n",
            " [  20  702 1088]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 43 206 162]\n",
            " [  6 744 125]\n",
            " [  2 153 308]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 10\n",
            "\ttrain_loss:0.753 valid_loss:0.812\n",
            "\ttrain_acc:68.59% valid_acc:64.09%\n",
            "\ttrain_f1:0.651 valid_f1:0.603\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 135  577  469]\n",
            " [  44 3145  327]\n",
            " [  40  582 1173]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 69 195 147]\n",
            " [ 15 739 121]\n",
            " [  8 142 313]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11\n",
            "\ttrain_loss:0.732 valid_loss:0.798\n",
            "\ttrain_acc:69.45% valid_acc:64.15%\n",
            "\ttrain_f1:0.675 valid_f1:0.597\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 217  524  449]\n",
            " [  58 3085  339]\n",
            " [  67  541 1194]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 63 225 123]\n",
            " [  9 770  96]\n",
            " [  9 165 289]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 12\n",
            "\ttrain_loss:0.706 valid_loss:0.778\n",
            "\ttrain_acc:70.05% valid_acc:65.35%\n",
            "\ttrain_f1:0.681 valid_f1:0.627\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 213  515  450]\n",
            " [  66 3146  325]\n",
            " [  76  515 1194]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 88 197 126]\n",
            " [ 14 756 105]\n",
            " [ 22 142 299]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13\n",
            "\ttrain_loss:0.687 valid_loss:0.766\n",
            "\ttrain_acc:71.29% valid_acc:65.47%\n",
            "\ttrain_f1:0.701 valid_f1:0.627\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 293  494  403]\n",
            " [ 102 3112  280]\n",
            " [ 115  469 1221]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[ 87 208 116]\n",
            " [ 12 766  97]\n",
            " [ 28 143 292]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 14\n",
            "\ttrain_loss:0.668 valid_loss:0.748\n",
            "\ttrain_acc:72.32% valid_acc:66.67%\n",
            "\ttrain_f1:0.706 valid_f1:0.655\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 270  462  447]\n",
            " [  82 3130  308]\n",
            " [  78  428 1317]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[118 175 118]\n",
            " [ 32 747  96]\n",
            " [ 40 122 301]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15\n",
            "\ttrain_loss:0.653 valid_loss:0.752\n",
            "\ttrain_acc:73.00% valid_acc:66.55%\n",
            "\ttrain_f1:0.727 valid_f1:0.655\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 366  430  409]\n",
            " [ 106 3134  288]\n",
            " [ 147  388 1280]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[111 189 111]\n",
            " [ 19 784  72]\n",
            " [ 41 153 269]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16\n",
            "\ttrain_loss:0.640 valid_loss:0.736\n",
            "\ttrain_acc:73.63% valid_acc:67.18%\n",
            "\ttrain_f1:0.728 valid_f1:0.666\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 358  428  402]\n",
            " [ 107 3115  275]\n",
            " [ 118  389 1326]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[127 173 111]\n",
            " [ 33 764  78]\n",
            " [ 52 127 284]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17\n",
            "\ttrain_loss:0.623 valid_loss:0.745\n",
            "\ttrain_acc:74.32% valid_acc:67.64%\n",
            "\ttrain_f1:0.747 valid_f1:0.663\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 440  388  380]\n",
            " [ 129 3139  252]\n",
            " [ 183  349 1286]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[116 187 108]\n",
            " [ 25 784  66]\n",
            " [ 47 133 283]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.85it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18\n",
            "\ttrain_loss:0.609 valid_loss:0.730\n",
            "\ttrain_acc:74.96% valid_acc:67.81%\n",
            "\ttrain_f1:0.751 valid_f1:0.668\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 420  396  372]\n",
            " [ 115 3199  253]\n",
            " [ 147  355 1285]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[126 173 112]\n",
            " [ 38 765  72]\n",
            " [ 53 115 295]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:03<00:00,  5.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19\n",
            "\ttrain_loss:0.601 valid_loss:0.726\n",
            "\ttrain_acc:75.30% valid_acc:68.27%\n",
            "\ttrain_f1:0.755 valid_f1:0.671\n",
            "\ttrain_confusion_matrix:\n",
            "[[ 432  357  391]\n",
            " [ 128 3128  266]\n",
            " [ 162  309 1358]]\n",
            "\tvalid_confusion_matrix:\n",
            "[[125 174 112]\n",
            " [ 32 768  75]\n",
            " [ 51 111 301]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = {\n",
        "    \"train_loss\": list(),\n",
        "    \"polarity_train_acc\": list(),\n",
        "    \"valid_loss\": list(),\n",
        "    \"polarity_valid_acc\": list(),\n",
        "}\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_f1 = []\n",
        "    test_f1 = []\n",
        "\n",
        "    model.train()\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for data in tqdm(train_loader, total=len(train_loader)):\n",
        "        for i in range(len(data)):\n",
        "            data[i] = data[i].to(device)\n",
        "        feature, mask, label = data\n",
        "        feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(feature)\n",
        "        loss = loss_fn(pred_logits, mask, label, 3)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        pred_tags = pred_logits.max(-1)[1]\n",
        "        preds.append(pred_tags)\n",
        "        masks.append(mask)\n",
        "        labels.append(label)\n",
        "\n",
        "    avg_train_acc, avg_train_f1, train_cm = cal_acc(preds, masks, labels)\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "    preds = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "            loss = loss_fn(pred_logits, mask, label, 3)\n",
        "\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            preds.append(pred_tags)\n",
        "            masks.append(mask)\n",
        "            labels.append(label)\n",
        "\n",
        "    avg_test_acc, avg_test_f1, test_cm = cal_acc(preds, masks, labels)\n",
        "    avg_test_loss = sum(test_loss) / len(test_loss)\n",
        "\n",
        "    print(f\"\\nepoch {epoch}\")\n",
        "    print(\"\\ttrain_loss:{:.3f} valid_loss:{:.3f}\".format(avg_train_loss, avg_test_loss))\n",
        "    print(\"\\ttrain_acc:{:.2%} valid_acc:{:.2%}\".format(avg_train_acc, avg_test_acc))\n",
        "    print(\"\\ttrain_f1:{:.3f} valid_f1:{:.3f}\".format(avg_train_f1, avg_test_f1))\n",
        "    print(f\"\\ttrain_confusion_matrix:\\n{train_cm}\")\n",
        "    print(f\"\\tvalid_confusion_matrix:\\n{test_cm}\")\n",
        "\n",
        "    if avg_test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_loss = avg_test_loss    \n",
        "        \n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['polarity_train_acc'].append(avg_train_acc.cpu().numpy())\n",
        "    history['valid_loss'].append(avg_test_loss)\n",
        "    history['polarity_valid_acc'].append(avg_test_acc.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.3, 1.0)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1WUlEQVR4nO3deXxV1bnw8d+TkJCBzMwZmGRMIAxhEJWiOKCtWGsRsNbqtXLrdajX1nttb1/Lte37ttp6HYrtpZZWWyt6tVpUHKpCQa8og4KASJgTEiAhM0nI9Lx/7J1wCBkOkJ2T5Dzfzyefs4d1znlycrKevddea21RVYwxxgSvkEAHYIwxJrAsERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQs0RgejQReUNEvtXRZc8whtkiktvG/t+KyP/p6Pc1xl9i4whMVyMiFT6rUcAJoN5d/2dVfbbzozp7IjIb+LOqppzj6+wHvq2q73RAWMY06RXoAIxpTlX7NC63VfmJSC9VrevM2Lor+6xMW6xpyHQbjU0sIvLvInIY+IOIJIjIayJSICLF7nKKz3PWiMi33eWbReR9EfmlW3afiFx5lmWHichaESkXkXdEZKmI/Lmd+L8nIkdFJF9EbvHZ/kcR+am73Nf9HUpEpEhE1olIiIj8CUgDXhWRChH5N7f8PBHZ7pZfIyJjfV53v/tZbQWOi8h9IvJSs5geF5HHzubvYXoOSwSmuxkIJAJDgMU43+E/uOtpQBXw6zaePx34AugLPAT8XkTkLMr+BfgYSAKWAN/0I+44IBm4FVgqIgktlPsekAv0AwYAPwRUVb8JHASuVtU+qvqQiIwCngPuccuvwkkU4T6vtwj4MhAP/BmYKyLx4JwlAAuBZ9qJ3fRwlghMd9MA/FhVT6hqlaoeU9WXVLVSVcuBnwFfauP5B1T1d6paDzwNDMKpcP0uKyJpwFTgAVWtUdX3gZXtxF0LPKiqtaq6CqgARrdSbhAwxC27Tlu/kLcAeF1V/66qtcAvgUhgpk+Zx1U1x/2s8oG1wHx331ygUFU3tRO76eEsEZjupkBVqxtXRCRKRP5bRA6ISBlORRcvIqGtPP9w44KqVrqLfc6w7GCgyGcbQE47cR9r1kZf2cr7PgzsBt4Wkb0icn8brzkYOOATY4MbR3IbcT0N3Ogu3wj8qZ24TRCwRGC6m+ZHx9/DObKerqqxwCx3e2vNPR0hH0gUkSifbakd8cKqWq6q31PV4cA84F4RmdO4u1nxPJwmMQDcZqtU4JDvSzZ7zivABBHJAL4CdKseWMYblghMdxeDc12gREQSgR97/YaqegDYCCwRkXAROR+4uiNeW0S+IiLnuZV6KU632QZ39xFguE/xF4Avi8gcEQnDSYongP9tI/Zq4EXcaxyqerAj4jbdmyUC0909itMuXgisB97spPf9BnA+cAz4KfA8TiV8rkYC7+BcQ/gQeFJVV7v7/h/wI7eH0PdV9Quc5p0ncH7/q3EuJte08x5PA+OxZiHjsgFlxnQAEXke2Kmqnp+RnCv3YvdOYKCqlgU6HhN4dkZgzFkQkakiMsLt4z8XuAan/b1LE5EQ4F5ghSUB08izRCAiy93BM9ta2S/uYJbdIrJVRCZ7FYsxHhgIrMFpwnkcuF1VPwloRO0QkWigDLiMTriWYroPz5qGRGQWzj/JM6qa0cL+q4C7gKtwBu48pqrTPQnGGGNMqzw7I1DVtUBRG0WuwUkSqqrrcfp+D/IqHmOMMS0L5KRzyZw62CXX3ZbfvKCILMaZToDo6OgpY8aM6ZQAjTGmp9i0aVOhqvZraV+3mH1UVZcBywCysrJ048aNAY7IGGO6FxE50Nq+QPYaOsSpozFTOHVEpDHGmE4QyESwErjJ7T00Ayh1J8UyxhjTiTxrGhKR54DZQF9xbtP3YyAMQFV/izNl7lU4E2xVAre0/ErGGGO85FkiUNVF7exX4A6v3t+YYFBbW0tubi7V1dXtFzZBISIigpSUFMLCwvx+Tre4WGyMaVlubi4xMTEMHTqU1u+vY4KFqnLs2DFyc3MZNmyY38+zKSaM6caqq6tJSkqyJGAAEBGSkpLO+AzREoEx3ZwlAePrbL4PlgiMMSbIWSIwxpy1kpISnnzyybN67lVXXUVJSUnHBmTOiiUCY8xZaysR1NXVtbi90apVq4iPj/cgqnOjqjQ0NLRfsAexRGCMOWv3338/e/bsYeLEidx3332sWbOGiy66iHnz5jFu3DgAvvrVrzJlyhTS09NZtmxZ03OHDh1KYWEh+/fvZ+zYsdx2222kp6dz+eWXU1VVddp7vfrqq0yfPp1JkyZx6aWXcuTIEQAqKiq45ZZbGD9+PBMmTOCll14C4M0332Ty5MlkZmYyZ45z2+clS5bwy1/+suk1MzIy2L9/P/v372f06NHcdNNNZGRkkJOTw+23305WVhbp6en8+McnZ+3esGEDM2fOJDMzk2nTplFeXs6sWbP49NNPm8pceOGFbNmypeM+aI9Z91Fjeoj/fHU7O/I69l4z4wbH8uOr01vd//Of/5xt27Y1VYJr1qxh8+bNbNu2ran74vLly0lMTKSqqoqpU6dy3XXXkZSUdMrrZGdn89xzz/G73/2O66+/npdeeokbb7zxlDIXXngh69evR0R46qmneOihh/jVr37FT37yE+Li4vjss88AKC4upqCggNtuu421a9cybNgwioramgj5ZAxPP/00M2bMAOBnP/sZiYmJ1NfXM2fOHLZu3cqYMWNYsGABzz//PFOnTqWsrIzIyEhuvfVW/vjHP/Loo4+ya9cuqquryczM9PtzDjRLBMaYDjVt2rRT+rA//vjjvPzyywDk5OSQnZ19WiIYNmwYEydOBGDKlCns37//tNfNzc1lwYIF5OfnU1NT0/Qe77zzDitWrGgql5CQwKuvvsqsWbOayiQmJrYb95AhQ5qSAMALL7zAsmXLqKurIz8/nx07diAiDBo0iKlTpwIQGxsLwPz58/nJT37Cww8/zPLly7n55pvbfb+uxBKBMT1EW0funSk6Orppec2aNbzzzjt8+OGHREVFMXv27Bb7uPfu3btpOTQ0tMWmobvuuot7772XefPmsWbNGpYsWXLGsfXq1euU9n/fWHzj3rdvH7/85S/ZsGEDCQkJ3HzzzW32zY+KiuKyyy7jb3/7Gy+88AKbNm0649gCya4RGGPOWkxMDOXl5a3uLy0tJSEhgaioKHbu3Mn69evP+r1KS0tJTk4G4Omnn27aftlll7F06dKm9eLiYmbMmMHatWvZt28fQFPT0NChQ9m8eTMAmzdvbtrfXFlZGdHR0cTFxXHkyBHeeOMNAEaPHk1+fj4bNmwAoLy8vOmi+Le//W3uvvtupk6dSkJCwln/noFgicAYc9aSkpK44IILyMjI4L777jtt/9y5c6mrq2Ps2LHcf//9pzS9nKklS5Ywf/58pkyZQt++fZu2/+hHP6K4uJiMjAwyMzNZvXo1/fr1Y9myZXzta18jMzOTBQsWAHDddddRVFREeno6v/71rxk1alSL75WZmcmkSZMYM2YMN9xwAxdccAEA4eHhPP/889x1111kZmZy2WWXNZ0pTJkyhdjYWG65pfvNn+nZPYu9YjemMeakzz//nLFjxwY6DAPk5eUxe/Zsdu7cSUhIYI+xW/peiMgmVc1qqbydERhjzDl65plnmD59Oj/72c8CngTOhl0sNsaYc3TTTTdx0003BTqMs9b9UpcxxpgOZYnAGGOCnCUCY4wJcpYIjDEmyFkiMMZ0qj59+gBOd8uvf/3rLZaZPXs27XUTf/TRR6msrGxat2mtz54lAmNMQAwePJgXX3zxrJ/fPBF01WmtW9OVpru2RGCMOWv333//KdM7NE7zXFFRwZw5c5g8eTLjx4/nb3/722nP3b9/PxkZGQBUVVWxcOFCxo4dy7XXXnvKXEMtTQf9+OOPk5eXx8UXX8zFF18MnJzWGuCRRx4hIyODjIwMHn300ab3s+muW+bpOAIRmQs8BoQCT6nqz5vtHwIsB/oBRcCNqprrZUzG9Fhv3A+HP+vY1xw4Hq78eau7FyxYwD333MMdd9wBODN2vvXWW0RERPDyyy8TGxtLYWEhM2bMYN68ea3eT/c3v/kNUVFRfP7552zdupXJkyc37WtpOui7776bRx55hNWrV58y3QTApk2b+MMf/sBHH32EqjJ9+nS+9KUvkZCQYNNdt8KzMwIRCQWWAlcC44BFIjKuWbFfAs+o6gTgQeD/eRWPMabjTZo0iaNHj5KXl8eWLVtISEggNTUVVeWHP/whEyZM4NJLL+XQoUNNR9YtWbt2bVOFPGHCBCZMmNC074UXXmDy5MlMmjSJ7du3s2PHjjZjev/997n22muJjo6mT58+fO1rX2PdunWA/9NdX3HFFYwfP56HH36Y7du3A850140JD5zprtevX98h0103//2++OKL06a77tWrF/Pnz+e1116jtra2Q6e79vKMYBqwW1X3AojICuAawPevOA64111eDbziYTzG9GxtHLl7af78+bz44oscPny4aXK3Z599loKCAjZt2kRYWBhDhw5tcxrn1pzpdNDtsemuW+blNYJkIMdnPdfd5msL8DV3+VogRkSSmpVBRBaLyEYR2VhQUOBJsMaYs7NgwQJWrFjBiy++yPz58wFnyuj+/fsTFhbG6tWrOXDgQJuvMWvWLP7yl78AsG3bNrZu3Qq0Ph00tD4F9kUXXcQrr7xCZWUlx48f5+WXX+aiiy7y+/cJxumuA32x+PvAl0TkE+BLwCGgvnkhVV2mqlmqmtWvX7/OjtEY04b09HTKy8tJTk5m0KBBAHzjG99g48aNjB8/nmeeeYYxY8a0+Rq33347FRUVjB07lgceeIApU6YArU8HDbB48WLmzp3bdLG40eTJk7n55puZNm0a06dP59vf/jaTJk3y+/cJxumuPZuGWkTOB5ao6hXu+g8AVLXF6wAi0gfYqaopbb2uTUNtzEk2DXXw8We66640DfUGYKSIDBORcGAhsLJZYH1FpDGGH+D0IDLGGNMCr6a79iwRqGodcCfwFvA58IKqbheRB0VknltsNvCFiOwCBgA/8yoeY4zp7m666SZycnKarsV0FE/HEajqKmBVs20P+Cy/CJz90EJjDKraav98E3zOprk/0BeLjTHnICIigmPHjp3VP7/peVSVY8eOERERcUbPszuUGdONpaSkkJubi3WrNo0iIiJISWmzz81pLBEY042FhYU1jWo15mxZ05AxxgQ5SwTGGBPkLBEYY0yQs0RgjDFBzhKBMcYEOUsExhgT5CwRGGNMkLNEYIwxQc4SgTHGBDlLBMYYE+QsERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQs0RgjDFBzhKBMcYEOUsExhgT5CwRGGNMkPM0EYjIXBH5QkR2i8j9LexPE5HVIvKJiGwVkau8jMcYY8zpPEsEIhIKLAWuBMYBi0RkXLNiPwJeUNVJwELgSa/iMcYY0zIvzwimAbtVda+q1gArgGualVEg1l2OA/I8jMcYY0wLvEwEyUCOz3quu83XEuBGEckFVgF3tfRCIrJYRDaKyMaCggIvYjXGmKAV6IvFi4A/qmoKcBXwJxE5LSZVXaaqWaqa1a9fv04P0hhjejIvE8EhINVnPcXd5utW4AUAVf0QiAD6ehiTMcaYZrxMBBuAkSIyTETCcS4Gr2xW5iAwB0BExuIkAmv7McaYTuRZIlDVOuBO4C3gc5zeQdtF5EERmecW+x5wm4hsAZ4DblZV9SomY4wxp+vl5Yur6iqci8C+2x7wWd4BXOBlDMYYY9oW6IvFxhhjAswSgTHGBDlLBMYYE+QsERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQ83RAmTHGmLbVNyjl1bWUVrX+U1ZVS1lVHQunpXLRyI6feNMSgTHGdLCGBuVo+QlyiyvJLa4it7iSQyXVFB+vObWCr66lvLquzdcKDw0hNjKMuMhelFTWehKvJQJjjDlD9Q3K0fLqpko+t6jKWS6p5FBxFXkl1dTUN5zynKTocBKjw4mLDGNQXARjBsa4FXyzn6gwYiNOrkeEhSAinv4+lgiMMaYZVaWkspYDRZUcLKrk4LHjHCxqPLqvIr+0itr6U+fH7BfTm5SESManxHPl+EhSEiJJjo8kJSGK5PhIIsNDA/TbtM8SgTEmKNXWN5BXUuVU9EWVHDzmPB44VklOUSXlJ05tsukX05vUhEgmpsbzlQmDSEmIIiXBqfAHx0cSEdZ1K/r2WCIwxvRIDQ1KYcUJcoqrOFRSxaFip9LPKarkQNFx8kqqqW84eVQf3iuE1IRI0hKjmDYskdTEKIYkRpGWFEVqQlSXPqI/V5YIjDHdUm19A4dLq5sq+dziKg6VVDatt9ROnxgdTmpiFJNSE7gm06nk0xKjGJIUxYCYCEJCvG2L76osERhjuqS6+gbyS6vJKXaO4nOKGnvfOBX94bJqGprdxqpfTG+S4yNJT47jivSBTjt9QiTJ8VEkJ0TSp7dVeS2xT8UYExCqSnFlbVNzjXMxttJdryKvpIo6n5o+NEQYGBtBckIkM4YnuRW8ezE2IZJBcRHdup0+kCwRGGM8VVlTx468Mnbkl3HgWGVTxZ9TVMnxmvpTyiZFh5OSGEWme0E2LTGK1ESn+WZQXAS9Qm0yBC9YIjDGdJiqmnp25JfyWW4pWw+Vsu1QKbuPVjQ14USEhZCa4FTsM4YnkZoY5VygdS/IRlvTTUDYp26MOStOpV/GtkOlbM11Kv3so+VNlX7fPuGMT45jbvpAMpLjyEiOY1BchOeDo8yZs0RgjGlXTV0D2/NK+eyUSr+iqftl3z7hZCTHcUX6ADKS4xifEsfAWKv0u4t2E4GIXA28rqoN7ZU1xvQMVTX1fHKwmI/2FfHxviI+ySmmutapApKiwxmfEsdl45xKf4JV+t2eP2cEC4BHReQlYLmq7vT3xUVkLvAYEAo8pao/b7b/v4CL3dUooL+qxvv7+saYjlFaVcumA0VNFf9nuaXUNSghAmMHxbJoWhrThiaSmRpvzTs9ULuJQFVvFJFYYBHwRxFR4A/Ac6pa3trzRCQUWApcBuQCG0Rkparu8Hntf/Upfxcw6ax/E2OM346WV7NhXzEb9juV/87DZahCWKgwISWe22YNZ9qwRKYMSSA2IizQ4RqP+XWNQFXLRORFIBK4B7gWuE9EHlfVJ1p52jRgt6ruBRCRFcA1wI5Wyi8CfnwGsRtj2lFX38CR8hPklVSxv/A4mw4U8/G+IvYWHgcgMiyUKUMSuGfOKKYNS2RSWrz1xQ9C/lwjmAfcApwHPANMU9WjIhKFU6m3lgiSgRyf9VxgeivvMQQYBrznf+jGBLfGGTLzSp3pFPJKnEFYeaUnl480G30bG9GLacMSWTA1lWnDEslIjiPM+uYHPX/OCK4D/ktV1/puVNVKEbm1g+JYCLyoqvUt7RSRxcBigLS0tA56S2O6vpq6Bg4cO86uIxXsKaggr8SZQM2p6Kupqj31XyY8NITB8REMiotk5oi+JMdHMDg+kkHxzijc4X2jg3Y+HdM6fxLBEiC/cUVEIoEBqrpfVd9t43mHgFSf9RR3W0sWAne09kKqugxYBpCVlaWtlTOmu6qpa2D/sePsOlJO9pEKso86j/sKj58yzUK/mN4Mjo9k1IAYZo/uz+D4SJLdin9wfCRJ0eFW0Zsz5k8i+B9gps96vbttajvP2wCMFJFhOAlgIXBD80IiMgZIAD70J2BjurMTdfXsKzzuVvYVZB8pJ/toBft9KvwQgbTEKEYOiOGycQMYNSCG8/r34bz+faz93njCn0TQS1VrGldUtUZEwtt7kqrWicidwFs43UeXq+p2EXkQ2KiqK92iC4EVqmpH+qbHUVU+O1TKa1vzeW/nUfYVHm8ahBUiMDQpmvP692Fu+kBGDnAq+xH9rMI3ncufRFAgIvMaK24RuQYo9OfFVXUVsKrZtgearS/xL1RjugdVZUd+Ga9tzef1rfkcLKqkV4gw87y+XJkxkPP692HUgBiG9Y22Ct846mvheCEcPwoVBXC8wF0+6i4XONtnfR/Sv9rhb+9PIvgO8KyI/BoQnJ5AN3V4JMZ0c18cLue1rXm8vjWfvYXHCQ0RZo5I4o6LR3BF+kDio9o9kTbdiSrUVTs/tdUnl09ZPwF1Vc5jbSVUHnMr+mYVflVxy+/RKxL69IPofhCXAuF9PPlV/BlQtgeYISJ93PUKTyIxphvafbSC17fm89rWPLKPVhAiMGN4ErdeNIy56QNJ6tM70CGa9qhCdYlzRF5xtIWj8oKTR+W1lScr+voTZ/d+vWOdir1Pf+g3GoZd5Kw3bovuD9F9neXwPtAJo7j9GlAmIl8G0oGIxqHlqvqgh3EZ02XtLzzO65/l8+qWPHYeLkcEpg5J5MFr0pmbMZD+MRGBDtGAU8FXFkHpQSjJgdJcqDjiNrP4NLkcL4D6mhZeQCAqya2c+0HyZAiPdo7Se/WGMPfxTNYjEyGs630//BlQ9luceYAuBp4Cvg587HFcxnQZqsquIxWs/uIor23NY9uhMgAmp8XzwFfGcdX4QQyM63r/3D1eQ4NTsZfmQMnBk48lOe5yDtQeP/U5IWFuxd7XOfIekH5y2Xd7n/5OEggJjms4/pwRzFTVCSKyVVX/U0R+BbzhdWDGBFJB+Qk+2F3IuuxC1mUXcLTcaQbITInjP64ay1UTBpEcHxngKLs4VSjcBQfXOz/5W0AbILQXhIY7PyE+y6Fh7o+7HBJ26nYJgfL8kxV9ae7pR/KRCRCXCknnwYhLnOX4VPcxzdlvE+adxp9EUO0+VorIYOAYMMi7kIzpfNW19Ww6UMza7ALW7SpkR75z1B8fFcYF5/Vl1si+XDiyn1X+bak7AXmfwsEPIecjp/KvKnL2RSZCSpbTRFJf51TgDbVOb5naSuexvvbU7fU1J8vW14DWQ58BTqU+KBPGXn2ygm+s8HvHBPQj6K78SQSvikg88DCwGVDgd14GZYzXGpt71mUXsDa7kI/3HaO6toGwUGFyWgL3XTGai0b2JX1wHKE2UrdllUWQ8zHkuEf8hzafvICaOAJGXwVp0yHtfOcI/VyPxFXtaN4jbSYCEQkB3lXVEuAlEXkNiFDV0s4IzpiO1Njcsza7gPezC5uae0b0i2bh1DRmjerL9GFJdt9cgIZ6n6PyWuco/UQ5HNrkHPEfXA8F7q1JQnrBoIkw7TZImwGp05029o5mScAzbX7jVbVBRJbi3idAVU8AZ9lnypjOd/BYJW9uz+fNbYfZfLAEgISm5p5+XDiyL4N7cnPP8UK3jf5Dp42+tvJk5e7bHFNfAw2+zTBt3JCwdxykToPxX3eO9gdPhvCozvudTIfz59DnXRG5DvirTQNhuoPsI+W8ue0wb2w73NTWn5Ecy/cuG8Xs0f1JHxzbMydmU4Vje04eseesh2O7nX2hvWHQBOdiaWsXY0+7eNvsom5YJAycAP3HBk1vmmDhTyL4Z+BeoE5EqnFGF6uqxnoamTF+UlW255XxxjbnyH9PgdNlcMqQBH705bFckT6Q1MQeeMRaV+Mc5ftenK10Z3+JTHSaaSZ90z1qn+hcqDWmBf6MLLbL8KbLaWhQNh8s5s1th3lz+2Fyi6sIDRFmDE/k5plDuTx9IANie0DfflWnvV4boKbi1Db6Q5ucUa4AicNh5OVO5Z92PvQdaW3qxm/+DCib1dL25jeqMcZrtfUNfLS3iDe35/PW9iMUlJ8gPDSEC0f25e45I7l07AASo7vYfD4nymHvGsj+u1N511U5A6G0wekO2VDvPrrr2uCzrR6nk14zEup0n8y61emVkzoDYgZ09m9mehB/mobu81mOwLkX8SbgEk8iMsZHaVUta3cV8N7Oo6z+4igllbVEhoVy8Zh+XJE+kEvG9CemK91cXRUKvoDdf4fst+HAh06Pm96xMOQCiIhzBkaFhDgVekioz2OIuy/01H2N5XtFOAkgeYoz1YExHcSfpqGrfddFJBV41KuATHBTVfYUHOe9nUd4b+dRNuwvpr5BSYgK45LR/bkiYyCzRvYjMrwLXaysOQ771jkVf/bfnbltAPqPg/P/xWmySZ3uXJA1pgs6mw7TucDYjg7EBK+augY+3lfEu27lf+BYJQBjBsbwnS8N55IxA5iYGt+1BnYd2+NW/G/D/g+cgVRh0TB8Nlx0L4y8zJk22JhuwJ9rBE9wsqEyBJiIM8LYmLNWUH6CNV8c5b2dR1mXXUjFiTrCe4VwwYgkvn3RcC4Z079rTefQUA97VztH/NlvQ9FeZ3vfUc5AqvMuhSEzrWeO6Zb8OSPY6LNcBzynqh94FI/poRrv2vXu507lvyW3BFUYENubqzMHM2dMf2ael0RUeBcb1dtQD9v+CmsfciZQ6xUJw2bBjH9xKv/EYYGO0Jhz5s9/3YtAtarWA4hIqIhEqWqlt6GZnkBVeffzoyxds5tPDpYgApkp8dx76SguGdufcYNika7YzbExAfzjF3AsG/qNhet+D2O+7AysMqYH8WtkMXAp0HhnskjgbWCmV0GZ7q++QXn9s3yeXL2bnYfLSUmI5MFr0rkyYxD9Yrpw80nzBNB/HMx/GsbOc3ruGNMD+ZMIInxvT6mqFSLSA4dpmo5QU9fAy5/k8ps1e9h/rJLz+vfhkeszuTpzMGGhXbgibaiHbS/BPx5yE0A6XP8MjLnaEoDp8fxJBMdFZLKqbgYQkSlAlbdhme6msqaOFR/n8Lt1e8kvrWZ8chy/vXEyl48b2LXn9bEEYIxfieAe4H9EJA9nnqGBwAJ/XlxE5gKPAaHAU6r68xbKXA8swemZtEVVb/ArctMllFbV8uf1B/j9+/soOl7DtGGJ/OK6CVw0sm/XbPtvVF/nJIC1DzkTsw3IgOv/BGO+YgnABB1/BpRtEJExwGh30xeqWtve80QkFFgKXIYz9mCDiKxU1R0+ZUYCPwAuUNViEfFgEnPjhcKKEyx/fx9/+vAA5SfqmD26H3dcfB5ThyYGOrS2WQIw5jT+jCO4A3hWVbe56wkiskhVn2znqdOA3aq6133eCuAaYIdPmduApapaDKCqR8/idzCdKK+kimVr97Jiw0FO1DVwVcYgbp89gozkuECH1rqGBig7BPvXwbpfnUwAC/4Mo79sCcAEPX+ahm5T1aWNK+6R+21Ae4kgGcjxWc8FpjcrMwpARD7AaT5aoqpv+hGT6WTZR8p5at0+/vpJLqrw1UnJ3D57BCP69Ql0aI6GBufG5kV7nFG/RXvg2F7nsWjfyVsoDhhvCcCYZvxJBKEiIo03pXGbfDpqisdewEhgNpACrBWR8e6tMZuIyGJgMUBaWloHvbVpT0OD8o/sApa/v4912YX07hXComlpLJ41nJSEAHQcU4Xyw80q+z3OKN+ifc7Mno1CezuDvRJHONM9JI6AfmOcOX8sARhzCn8SwZvA8yLy3+76PwNv+PG8Q0Cqz3qKu81XLvCRe81hn4jswkkMG3wLqeoyYBlAVlaW3SXNY8dP1PHS5lz++MF+9hYep39Mb75/+SgWTUsjqU8njwGoLoVdb8HnK2HPamdO/kah4ZAw1KnkR1zizMmfNMJZj022Ct8YP/mTCP4d52j8O+76VpyeQ+3ZAIwUkWE4CWAh0LxH0CvAIuAPItIXp6lorx+vbTyQU1TJMx/uZ8WGHMqr68hMieOxhRO5MmMQ4b06sVI9Xgg7X4fPX3Xm8m+ohZhBMH4+DEg/WeHHpdotE43pAP70GmoQkY+AEcD1QF/gJT+eVycidwJv4bT/L1fV7SLyILBRVVe6+y4XkR1APXCfqh47+1/HnClVZcP+Ypa/v4+3dxxGRLgyYyC3XDCMyWnxndcFtPQQ7HzNqfwPfODcoCVhKMy43RnVmzzFjvCN8Yi0dj96ERmFc7S+CCgEnge+r6pDOi+802VlZenGjRvbL2jadKKunte25LP8g31szysjLjKMG6an8c0ZQxjcWbN+HtvjVPyfr3RuuwjOnD7j5sHYq52ePV15LIIx3YiIbFLVrJb2tXVGsBNYB3xFVXe7L/SvHsRnOlFB+Qme/egAf15/kMKKE4zs34f/e+14rp2U7P3NXlTh6A6n8t+xEo5ud7YPngRzfuxU/n1HehuDMeY0bSWCr+G0668WkTeBFTgji003tOtIOf/9j728uiWPmvoGLhnTn1suGMqF53k8Ari61Llxy941zu0bi/YC4txgfe7PnYFc8antvYoxxkOtJgJVfQV4RUSicQaC3QP0F5HfAC+r6tudEqE5JzsPl/HEu7tZtS2fyLBQFk1L5VszhzLcq/7/dTWQu8Gp+PeucZp8tB7Copx79s6825nKuY8NIjemq/DnYvFx4C/AX0QkAZiP05PIEkEXtiOvjMffzebN7Yfp07sXd8w+j1svHEZCdEcNAXGpwpHtJyv+Ax9AbaVzw/XkKc5tG4fPhpSpdvcuY7qoM7odlDsVRFOfftP1bDtUyuPvZvP2jiPE9O7F3Zecxz9dOIz4qA5MACU5Jyv+ff+A4wXO9qSRMPEbMOJi5+g/Mr7j3tMY45kudl9Ac7Y+yy3lsXd38c7nR4mN6MU9l47klguGERcZ1jFvULQXPnzSuW/vsd3Otuj+MPxi54h/+JfsZu3GdFOWCLq5T3NKePzdbN7beZS4yDC+d9kovnXBUGIjOigB1NfC/z7h3LELce7Xm3WrU/n3H2vdO43pASwRdFObDxbz2DvZ/GNXAfFRYdx3xWhuOn8IMR2VAAByN8LKu51unmPnwZUPQeygjnt9Y0yXYImgm9l0oIhH38lmXXYhidHh/PvcMXzz/CH06d2Bf8rqMnjvJ/Dx75ypHRb+xenpY4zpkSwRdHF19Q3sOlLBJznFrPosnw92HyMpOpwfXDmGG2cMIbojEwA4c/y8/n1nSudpi+GSH0FEbMe+hzGmS7FE0MUcLavmk5wSPjlYwicHi9maW0pVbT0AA2Mj+NGXx3LD9DSiwjv4T1eWB2/8mzPqd0AGLPgTpLQ4Gt0Y08NYIvCTqlJWXUdUeChhoR0z+Vl1bT3b88r45GAxn+SU8OnBEg6VOHPqh4UK4wbHsWBqKpPS4pmUmkBqYmTHjwJuaICNv4d3/tOZ5fPSJXD+nRDagdcajDFdmiUCPz3z4QF+vNKZGycqPJTYiDBiI3sRGxFGXGQYsZFhxEb0ch+dfXFNy85jvSpbc08e7e/IL6O23pn0Lzk+kolp8dxywVAmpSWQPjiWiDCP5/45sgNe/S7kfux0A/3KI84Uz8aYoGKJwA9VNfU88V42E1LiuHTsAMqqaimrrqWsqo6y6lqOlFez62g5ZVV1lFfX0tDOrXMiw0KZkBLHrRcOd4/24+kfG9E5vwxAbRWsfRg+eAwi4uDaZTDheusKakyQskTgh2c/OkBhRQ2/uXEKU4cmtlm2oUE5XlNHWXUdZVW1lFbVuomjjoYGJSM5jlED+tCrg5qXztjef8Br9zgDxDJvgMt/CtFJgYnFGNMlWCJoR3VtPf+9di8zRyS1mwQAQkKEmIgwYiLCSO6sef39UbTPOQv49Fmn+eemvzmDwowxQc8SQTue/eggBeUn+PWiSYEO5cydqHBu+vLJs3DgfQjpBRd9D2bdB2FdKEkZYwLKEkEbqmvr+e0/9jBjeCLTh3eT5hNVOPC/8OlfYPvLUHvcuZn7Jf8HMhfafEDGmNNYImjDcx87ZwOPL+wGZwMlObDlOafpp3g/hMfA+Ouc2UBTp9uFYGNMqywRtKLxbGD6sETOH9FFzwZqKp0bvn/yZ9i3FlBnUrjZP3Bu+xgeHegIjTHdgCWCVjy/IYcjZSf4rwUTAx3KqVQh52P49M+w7WWoKYf4IU7ln7kQEoYEOkJjTDdjiaAF1bX1PLlmN9OGJnJ+V7g2UF8HR7bBnnedtv9ju51bP477Kkz6BqTNhJAAdUc1xnR7lgha8MJG52zgkesnentj99ZUFDijfXM+dqaCztvs3P4RnDt/XfivMO4a6B3T+bEZY3ocTxOBiMwFHgNCgadU9efN9t8MPAwccjf9WlWf8jKm9pyoq+c3a/aQNSSBmZ1xbaC+1jnaz9ng3PQ992PnYi843T0HToDJNzn3/E2bYb1+jDEdzrNEICKhwFLgMiAX2CAiK1V1R7Oiz6vqnV7FcaZe2JhLfmk1D38905uzgYqj7pG+e7R/aDPUORPN0WcgpE517gCWOg0GZVp/f2OM57w8I5gG7FbVvQAisgK4BmieCLqME3X1/Oa9bC5KDeeCuELYux3KDztz81ccgcpj0FAPWu8+Npx8bNpW78zoqb773X1VJVB60HmzkDCnos+6xZnuOWWac7Rv3TyNMZ3My0SQDOT4rOcC01sod52IzAJ2Af+qqjnNC4jIYmAxQFpa2tlFowrVpU7FXnHYreAPn7JeU5jLuyeOEFlQA082e35YtDMnT0gvkFAICXUfQ0BCmm0LdcuFnLqt70iYvtip9AdlQlgnTjRnjDGtCPTF4leB51T1hIj8M/A0cEnzQqq6DFgGkJWV1c7cnq1Y9yvn9ovNhUVDzEAa+gxkffUQKqOymHfhZCRmEMQMPPljF2aNMT2Ul4ngEJDqs57CyYvCAKjqMZ/Vp4CHPItm+Gzo1dtph48Z6NyLN2ZAUwW/4qOD/HDXZ/xxwVRkdH/PwjDGmK7Gy0SwARgpIsNwEsBC4AbfAiIySFXz3dV5wOeeRZOS1eqtF2vqGli6ejeZqfF8aVQ/z0IwxpiuyLNEoKp1InIn8BZO99HlqrpdRB4ENqrqSuBuEZkH1AFFwM1exdOWv27O5VBJFT+9NiMw4waMMSaAPL1GoKqrgFXNtj3gs/wD4AdextCe2voGfr16N5kpccy2swFjTBAK+nkJ/ro5l9ziKr576Ug7GzDGBKWgTgSNZwMTUuK42C4QG2OCVFAngpc/OUROURV3X2JnA8aY4BW0iaCu3ukplJEcy5yxdjZgjAleQZsIXvk0jwPHKvnunFF2NmCMCWpBmQjq6ht44r1s0gfHcqmdDRhjglxQJoK/uWcDd8+xawPGGBN0iaDO7Sk0dlAsl48bEOhwjDEm4IIuEby6NY99hcf5rp0NGGMMEGSJoL5BeeLd3YwZGGNnA8YY4wqqRPDqljz2umcDISF2NmCMMRBEiaC+QXn8vWxGD4jhivSBgQ7HGGO6jKBJBK9tzWNvwXHutrMBY4w5RdAkgrjIMK7MGMiVGXY2YIwxvgJ9q8pOM3t0f2bbxHLGGHOaoDkjMMYY0zJLBMYYE+QsERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQ8zQRiMhcEflCRHaLyP1tlLtORFREsryMxxhjzOk8SwQiEgosBa4ExgGLRGRcC+VigO8CH3kVizHGmNZ5eUYwDditqntVtQZYAVzTQrmfAL8Aqj2MxRhjTCu8TATJQI7Peq67rYmITAZSVfX1tl5IRBaLyEYR2VhQUNDxkRpjTBAL2MViEQkBHgG+115ZVV2mqlmqmtWvXz/vgzPGmCDiZSI4BKT6rKe42xrFABnAGhHZD8wAVtoFY2OM6VxeJoINwEgRGSYi4cBCYGXjTlUtVdW+qjpUVYcC64F5qrrRw5iMMcY041kiUNU64E7gLeBz4AVV3S4iD4rIPK/e1xhjzJnx9H4EqroKWNVs2wOtlJ3tZSzGGGNaZiOLjTEmyFkiMMaYIGeJwBhjgpwlAmOMCXKWCIwxJshZIjDGmCBnicAYY4KcJQJjjAlylgiMMSbIWSIwxpggZ4nAGGOCnCUCY4wJcpYIjDEmyFkiMMaYIGeJwBhjgpwlAmOMCXKWCIwxJshZIjDGmCBnicAYY4KcJQJjjAlylgiMMSbIWSIwxpgg52kiEJG5IvKFiOwWkftb2P8dEflMRD4VkfdFZJyX8RhjjDmdZ4lAREKBpcCVwDhgUQsV/V9UdbyqTgQeAh7xKh5jjDEt8/KMYBqwW1X3qmoNsAK4xreAqpb5rEYD6mE8xhhjWtDLw9dOBnJ81nOB6c0LicgdwL1AOHBJSy8kIouBxe5qhYh8cZYx9QUKz/K5ncHiOzcW37nr6jFafGdvSGs7vEwEflHVpcBSEbkB+BHwrRbKLAOWnet7ichGVc0619fxisV3biy+c9fVY7T4vOFl09AhINVnPcXd1poVwFc9jMcYY0wLvEwEG4CRIjJMRMKBhcBK3wIiMtJn9ctAtofxGGOMaYFnTUOqWicidwJvAaHAclXdLiIPAhtVdSVwp4hcCtQCxbTQLNTBzrl5yWMW37mx+M5dV4/R4vOAqFpHHWOMCWY2stgYY4KcJQJjjAlyPTIR+DG1RW8Red7d/5GIDO3E2FJFZLWI7BCR7SLy3RbKzBaRUnfqjU9F5IHOis99//0+U39sbGG/iMjj7ue3VUQmd2Jso30+l09FpExE7mlWptM/PxFZLiJHRWSbz7ZEEfm7iGS7jwmtPPdbbplsEenw62StxPawiOx0/34vi0h8K89t87vgcYxLROSQz9/xqlae2+b/u4fxPe8T234R+bSV53bKZ3hOVLVH/eBcmN4DDMcZpLYFGNeszL8Av3WXFwLPd2J8g4DJ7nIMsKuF+GYDrwXwM9wP9G1j/1XAG4AAM4CPAvi3PgwMCfTnB8wCJgPbfLY9BNzvLt8P/KKF5yUCe93HBHc5oRNiuxzo5S7/oqXY/PkueBzjEuD7fnwH2vx/9yq+Zvt/BTwQyM/wXH564hlBu1NbuOtPu8svAnNERDojOFXNV9XN7nI58DnOKOzu5BrgGXWsB+JFZFAA4pgD7FHVAwF471Oo6lqgqNlm3+/Z07Q8TuYK4O+qWqSqxcDfgblex6aqb6tqnbu6HmecT8C08vn5w5//93PWVnxu3XE98FxHv29n6YmJoKWpLZpXtE1l3H+GUiCpU6Lz4TZJTQI+amH3+SKyRUTeEJH0zo0MBd4WkU3u9B7N+fMZd4aFtP7PF8jPr9EAVc13lw8DA1oo0xU+y3/COcNrSXvfBa/d6TZfLW+laa0rfH4XAUdUtbVxUIH+DNvVExNBtyAifYCXgHv01Mn3ADbjNHdkAk8Ar3RyeBeq6mScmWPvEJFZnfz+7XIHKc4D/qeF3YH+/E6jThtBl+urLSL/AdQBz7ZSJJDfhd8AI4CJQD5O80tXtIi2zwa6/P9TT0wE/kxt0VRGRHoBccCxTonOec8wnCTwrKr+tfl+VS1T1Qp3eRUQJiJ9Oys+VT3kPh4FXsY5/fZ1ptOHeOFKYLOqHmm+I9Cfn48jjU1m7uPRFsoE7LMUkZuBrwDfcBPVafz4LnhGVY+oar2qNgC/a+W9A/pddOuPrwHPt1YmkJ+hv3piImh3agt3vbF3xteB91r7R+hobnvi74HPVbXF+y+IyMDGaxYiMg3n79QpiUpEokUkpnEZ56LitmbFVgI3ub2HZgClPk0gnaXVo7BAfn7N+H7PvgX8rYUybwGXi0iC2/RxubvNUyIyF/g3YJ6qVrZSxp/vgpcx+l53uraV9/bn/91LlwI7VTW3pZ2B/gz9Fuir1V784PRq2YXTm+A/3G0P4nzpASJwmhR2Ax8Dwzsxtgtxmgi2Ap+6P1cB3wG+45a5E9iO0wNiPTCzE+Mb7r7vFjeGxs/PNz7BuenQHuAzIKuT/77ROBV7nM+2gH5+OEkpH2e6lFzgVpzrTu/izKH1DpDols0CnvJ57j+538XdwC2dFNtunLb1xu9gYy+6wcCqtr4Lnfj5/cn9fm3FqdwHNY/RXT/t/70z4nO3/7Hxe+dTNiCf4bn82BQTxhgT5Hpi05AxxpgzYInAGGOCnCUCY4wJcpYIjDEmyFkiMMaYIGeJwJhmRKReTp3htMNmtBSRob4zWBrTFXh2q0pjurEqVZ0Y6CCM6Sx2RmCMn9x55R9y55b/WETOc7cPFZH33MnR3hWRNHf7AHeu/y3uz0z3pUJF5Hfi3I/ibRGJDNgvZQyWCIxpSWSzpqEFPvtKVXU88GvgUXfbE8DTqjoBZ/K2x93tjwP/UGfyu8k4I0sBRgJLVTUdKAGu8/S3MaYdNrLYmGZEpEJV+7SwfT9wiarudScOPKyqSSJSiDP9Qa27PV9V+4pIAZCiqid8XmMozv0HRrrr/w6EqepPO+FXM6ZFdkZgzJnRVpbPxAmf5XrsWp0JMEsExpyZBT6PH7rL/4sz6yXAN4B17vK7wO0AIhIqInGdFaQxZ8KORIw5XWSzG5G/qaqNXUgTRGQrzlH9InfbXcAfROQ+oAC4xd3+XWCZiNyKc+R/O84MlsZ0KXaNwBg/udcIslS1MNCxGNORrGnIGGOCnJ0RGGNMkLMzAmOMCXKWCIwxJshZIjDGmCBnicAYY4KcJQJjjAly/x8ItnBPYZVH9gAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history['polarity_train_acc'], label='train accuracy')\n",
        "plt.plot(history['polarity_valid_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0.3, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model from: model_task2_full_clean.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Neutral       0.60      0.30      0.40       411\n",
            "    Positive       0.73      0.88      0.80       875\n",
            "    Negative       0.62      0.65      0.63       463\n",
            "\n",
            "    accuracy                           0.68      1749\n",
            "   macro avg       0.65      0.61      0.61      1749\n",
            "weighted avg       0.67      0.68      0.66      1749\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def get_classification_report(test_loader, model, model_path=None):\n",
        "    if model_path is not None: # load the saved model\n",
        "        print('Loading saved model from: {}'.format(model_path))\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    model = to_device(model, device)   \n",
        "    \n",
        "    model.eval()\n",
        "    final_pred_polarity_tags = []\n",
        "    final_true_polarity_tags = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, total=len(test_loader)):\n",
        "            for i in range(len(data)):\n",
        "                data[i] = data[i].to(device)\n",
        "            feature, mask, label = data\n",
        "            feature, mask, label = feature.long(), mask.bool(), label.long()\n",
        "            pred_logits = model(feature)\n",
        "\n",
        "            pred_tags = pred_logits.max(-1)[1]\n",
        "\n",
        "            pred_tags = pred_tags[mask]\n",
        "            label = label[mask]\n",
        "\n",
        "            final_pred_polarity_tags.extend(pred_tags)\n",
        "            final_true_polarity_tags.extend(label)\n",
        "\n",
        "    final_pred_polarity_tags = torch.stack(final_pred_polarity_tags).cpu()\n",
        "    final_true_polarity_tags = torch.stack(final_true_polarity_tags).cpu()\n",
        "        \n",
        "    print(classification_report(final_true_polarity_tags, final_pred_polarity_tags, \n",
        "                                target_names=[\"Neutral\", \"Positive\", \"Negative\"]))\n",
        "    \n",
        "get_classification_report(test_loader, model, model_path=MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'model_task2_full_clean.bin'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_PATH"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "cnn_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
